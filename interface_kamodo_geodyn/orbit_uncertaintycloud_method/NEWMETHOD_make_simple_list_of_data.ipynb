{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d384d4ae",
   "metadata": {},
   "source": [
    "# Developing New method for Using Kamodo with GEODYN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699b036a",
   "metadata": {},
   "source": [
    "*This new method should run the orbits of GEODYN through Kamodo in a faster way that doesn't sacrifice accuracy of the interpolation in Kamodo and doesn't require a trimming of other Kamodo functionality to accomodate large overhead.*\n",
    "\n",
    "1. Pre-run initialization of the orbit.\n",
    "   - \"initialize\" a run of GEODYN with MSIS2 that gives us a \"best guess\" for the orbit of the satellite.\n",
    "2. Construct box of estimated orbits with variation\n",
    "   - Before running GEODYN with TIEGCM, we will take the \"best guess\" orbit and perturbate the input coordinates outward for each timestep that GEODYN asks for.  This will construct a box of best guesses around our satellite that can then be plugged into Kamodo.  \n",
    "   - From here we just have a meshed index of possible density values from Kamodo for each timepoint and within some standard deviation of possible values along the orbit of the s/c.\n",
    "3. Get density in GEODYN\n",
    "   - now instead of calling the Kamodo model at each time step which has tons of overhead, we can call a relatively simple interpolation scheme in fortran at each timestep that will return the density value.  The orbit grid will be saved in a file that will be indexed by time according to what the MSIS model returned.\n",
    "   - We will need to build in functionality such that if GEODYN requests a value outside of the box we requested, then it stops the program and restarts the process with a slightly larger grid around the orbit.\n",
    "   \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab271db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T18:17:36.172086Z",
     "start_time": "2021-09-10T18:17:35.870796Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f60648",
   "metadata": {},
   "source": [
    "## Function for trilinear interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ddce7a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T18:17:36.182563Z",
     "start_time": "2021-09-10T18:17:36.174107Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def interpolate_point_in_cube(lon, lat, alt, uncertain_grid, timestep, delta_deg, delta_m):\n",
    "    '''\n",
    "    This function performs a manual calculation for trilinear interoplation.\n",
    "    Interpolates values on a cube to a desired coordinate.  \n",
    "    Currently, it is set up for Lon, Lat, Alt.\n",
    "    '''    \n",
    "    x  = lon\n",
    "    x0 = x - delta_deg\n",
    "    x1 = x + delta_deg\n",
    "\n",
    "    y  = lat\n",
    "    y0 = y - delta_deg\n",
    "    y1 = y + delta_deg\n",
    "\n",
    "    z  = alt\n",
    "    z0 = z - delta_m\n",
    "    z1 = z + delta_m\n",
    "\n",
    "    C000 = np.array(uncertain_grid[timestep]['values'][5])  # bottom, front, left\n",
    "    C100 = np.array(uncertain_grid[timestep]['values'][7])  # bottom, front, right\n",
    "    C001 = np.array(uncertain_grid[timestep]['values'][1])  # top,    front, left\n",
    "    C101 = np.array(uncertain_grid[timestep]['values'][3])  # top,    front, right\n",
    "    C010 = np.array(uncertain_grid[timestep]['values'][6])  # bottom, back,  left\n",
    "    C110 = np.array(uncertain_grid[timestep]['values'][8])  # bottom, back,  right\n",
    "    C011 = np.array(uncertain_grid[timestep]['values'][2])  # top,    back,  Left\n",
    "    C111 = np.array(uncertain_grid[timestep]['values'][4])  # top,    back,  right\n",
    "\n",
    "\n",
    "    ##===================================================================\n",
    "    ##        Manually INTERPOLATE-- Trilinear Interpolation Calculation\n",
    "    ##===================================================================\n",
    "\n",
    "    ### On a periodic and cubic lattice, let xd, yd, zd be the differences \n",
    "    ### between each of x, y, z and the smaller coordinate related.\n",
    "    #\n",
    "    ###  x0 indicates the lattice point below x \n",
    "    ###  x1 indicates the lattice point above x\n",
    "    xd =  (x-x0)/(x1-x0)\n",
    "    yd =  (y-y0)/(y1-y0)\n",
    "    zd =  (z-z0)/(z1-z0)\n",
    "    # print(xd,yd,zd)\n",
    "\n",
    "    ##### First we interpolate along x:   (push one of the X faces of cube towards the opposing face)\n",
    "    ###   C000 uis the function value (x0, y0, z0)\n",
    "    C00 = C000*(1-xd) + (C100*xd)\n",
    "    C01 = C001*(1-xd) + (C101*xd)\n",
    "    C10 = C010*(1-xd) + (C110*xd)\n",
    "    C11 = C011*(1-xd) + (C111*xd)\n",
    "\n",
    "    #### Next we interpolate along y:  (pushing the values that are now in middle of cube towards the center Y)\n",
    "    C0 = C00*(1-yd) + C10*yd\n",
    "    C1 = C01*(1-yd) + C11*yd\n",
    "\n",
    "    #### Finally we interpolate along Z   (walk through the line that remains)\n",
    "    C = C0*(1-zd) + C1*zd\n",
    "    \n",
    "    return(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde2d14",
   "metadata": {},
   "source": [
    "## Do a Pre-run with MSIS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb8bee2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T18:17:36.190159Z",
     "start_time": "2021-09-10T18:17:36.184213Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# import copy\n",
    "# import time\n",
    "# import sys  \n",
    "\n",
    "\n",
    "# sys.path.insert(0, '/data/geodyn_proj/pygeodyn/pygeodyn_develop/')\n",
    "# from PYGEODYN import Pygeodyn\n",
    "\n",
    "\n",
    "# ### Identify which arcs you want to run:\n",
    "# arcs_files = [ \n",
    "#             '2018.336',  # 1\n",
    "#              ]\n",
    "\n",
    "# #------ A dictionary containing the run parameters ------  \n",
    "# run_params = {} \n",
    "# run_params['arc']              =   arcs_files\n",
    "# run_params['satellite']        =  'icesat2'  \n",
    "# run_params['den_model']        =  'msis2'  \n",
    "# run_params['SpecialRun_name']  =  'PCE_kamodo_interface'  \n",
    "# run_params['verbose']          =  False\n",
    "\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# import pickle \n",
    "# sys.path.insert(0, '/data/geodyn_proj/pygeodyn/pygeodyn_develop/')\n",
    "# from PYGEODYN import Pygeodyn\n",
    "\n",
    "# for imodel,val_model in enumerate( ['msis2']):\n",
    "#     run_params1 = copy.deepcopy(run_params)\n",
    "#     run_params1['den_model']  =  val_model  \n",
    "#     run_params1['action']           =  'run'\n",
    "\n",
    "#     ### Load the data into an object\n",
    "#     Obj_Geodyn = Pygeodyn(run_params1)\n",
    "#     Obj_Geodyn.RUN_GEODYN()\n",
    "#     del Obj_Geodyn\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6f4120",
   "metadata": {},
   "source": [
    "## Read Density Values from Pre-Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20965ea3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T18:17:36.196285Z",
     "start_time": "2021-09-10T18:17:36.192238Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#### Need to bunzip the file we want to play with.\n",
    "\n",
    "# !bunzip2 /data/data_geodyn/results/icesat2/msis2/msis2_acceloffPCE_kamodo_interface/DENSITY/icesat2_2018336_54hr.msis2.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2d169b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T18:17:36.201773Z",
     "start_time": "2021-09-10T18:17:36.198062Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46bd48ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T18:17:36.603543Z",
     "start_time": "2021-09-10T18:17:36.203061Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>YYMMDD</th>\n",
       "      <th>HHMMSS</th>\n",
       "      <th>Height_kilometers</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>STLOC</th>\n",
       "      <th>AVGFLX</th>\n",
       "      <th>FLUX</th>\n",
       "      <th>sattime_utctimestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-01 21:01:09</td>\n",
       "      <td>181201</td>\n",
       "      <td>210109</td>\n",
       "      <td>486.242</td>\n",
       "      <td>41.976</td>\n",
       "      <td>65.686</td>\n",
       "      <td>1.55973</td>\n",
       "      <td>70.34</td>\n",
       "      <td>68.16</td>\n",
       "      <td>1.543698e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-01 21:02:09</td>\n",
       "      <td>181201</td>\n",
       "      <td>210209</td>\n",
       "      <td>485.539</td>\n",
       "      <td>38.151</td>\n",
       "      <td>65.208</td>\n",
       "      <td>1.54454</td>\n",
       "      <td>70.34</td>\n",
       "      <td>68.16</td>\n",
       "      <td>1.543698e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-01 21:03:09</td>\n",
       "      <td>181201</td>\n",
       "      <td>210309</td>\n",
       "      <td>484.882</td>\n",
       "      <td>34.323</td>\n",
       "      <td>64.753</td>\n",
       "      <td>1.53085</td>\n",
       "      <td>70.34</td>\n",
       "      <td>68.16</td>\n",
       "      <td>1.543698e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-01 21:04:09</td>\n",
       "      <td>181201</td>\n",
       "      <td>210409</td>\n",
       "      <td>484.290</td>\n",
       "      <td>30.492</td>\n",
       "      <td>64.316</td>\n",
       "      <td>1.51836</td>\n",
       "      <td>70.34</td>\n",
       "      <td>68.16</td>\n",
       "      <td>1.543698e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-01 21:05:09</td>\n",
       "      <td>181201</td>\n",
       "      <td>210509</td>\n",
       "      <td>483.779</td>\n",
       "      <td>26.659</td>\n",
       "      <td>63.892</td>\n",
       "      <td>1.50679</td>\n",
       "      <td>70.34</td>\n",
       "      <td>68.16</td>\n",
       "      <td>1.543698e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14353</th>\n",
       "      <td>2018-12-04 02:42:09</td>\n",
       "      <td>181204</td>\n",
       "      <td>024209</td>\n",
       "      <td>488.215</td>\n",
       "      <td>-16.097</td>\n",
       "      <td>-23.534</td>\n",
       "      <td>1.28048</td>\n",
       "      <td>70.27</td>\n",
       "      <td>68.67</td>\n",
       "      <td>1.543891e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14354</th>\n",
       "      <td>2018-12-04 02:43:09</td>\n",
       "      <td>181204</td>\n",
       "      <td>024309</td>\n",
       "      <td>489.508</td>\n",
       "      <td>-19.929</td>\n",
       "      <td>-23.932</td>\n",
       "      <td>1.27060</td>\n",
       "      <td>70.27</td>\n",
       "      <td>68.67</td>\n",
       "      <td>1.543891e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14355</th>\n",
       "      <td>2018-12-04 02:44:09</td>\n",
       "      <td>181204</td>\n",
       "      <td>024409</td>\n",
       "      <td>490.911</td>\n",
       "      <td>-23.759</td>\n",
       "      <td>-24.337</td>\n",
       "      <td>1.26023</td>\n",
       "      <td>70.27</td>\n",
       "      <td>68.67</td>\n",
       "      <td>1.543891e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14356</th>\n",
       "      <td>2018-12-04 02:45:09</td>\n",
       "      <td>181204</td>\n",
       "      <td>024509</td>\n",
       "      <td>492.405</td>\n",
       "      <td>-27.585</td>\n",
       "      <td>-24.752</td>\n",
       "      <td>1.24925</td>\n",
       "      <td>70.27</td>\n",
       "      <td>68.67</td>\n",
       "      <td>1.543892e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14357</th>\n",
       "      <td>2018-12-04 02:46:09</td>\n",
       "      <td>181204</td>\n",
       "      <td>024609</td>\n",
       "      <td>493.973</td>\n",
       "      <td>-31.407</td>\n",
       "      <td>-25.178</td>\n",
       "      <td>1.23748</td>\n",
       "      <td>70.27</td>\n",
       "      <td>68.66</td>\n",
       "      <td>1.543892e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14358 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Date  YYMMDD  HHMMSS Height_kilometers     Lat     Lon  \\\n",
       "0     2018-12-01 21:01:09  181201  210109           486.242  41.976  65.686   \n",
       "1     2018-12-01 21:02:09  181201  210209           485.539  38.151  65.208   \n",
       "2     2018-12-01 21:03:09  181201  210309           484.882  34.323  64.753   \n",
       "3     2018-12-01 21:04:09  181201  210409           484.290  30.492  64.316   \n",
       "4     2018-12-01 21:05:09  181201  210509           483.779  26.659  63.892   \n",
       "...                   ...     ...     ...               ...     ...     ...   \n",
       "14353 2018-12-04 02:42:09  181204  024209           488.215 -16.097 -23.534   \n",
       "14354 2018-12-04 02:43:09  181204  024309           489.508 -19.929 -23.932   \n",
       "14355 2018-12-04 02:44:09  181204  024409           490.911 -23.759 -24.337   \n",
       "14356 2018-12-04 02:45:09  181204  024509           492.405 -27.585 -24.752   \n",
       "14357 2018-12-04 02:46:09  181204  024609           493.973 -31.407 -25.178   \n",
       "\n",
       "         STLOC AVGFLX   FLUX  sattime_utctimestamp  \n",
       "0      1.55973  70.34  68.16          1.543698e+09  \n",
       "1      1.54454  70.34  68.16          1.543698e+09  \n",
       "2      1.53085  70.34  68.16          1.543698e+09  \n",
       "3      1.51836  70.34  68.16          1.543698e+09  \n",
       "4      1.50679  70.34  68.16          1.543698e+09  \n",
       "...        ...    ...    ...                   ...  \n",
       "14353  1.28048  70.27  68.67          1.543891e+09  \n",
       "14354  1.27060  70.27  68.67          1.543891e+09  \n",
       "14355  1.26023  70.27  68.67          1.543891e+09  \n",
       "14356  1.24925  70.27  68.67          1.543892e+09  \n",
       "14357  1.23748  70.27  68.66          1.543892e+09  \n",
       "\n",
       "[14358 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "DEN_csv = pd.read_csv('/data/data_geodyn/results/icesat2/msis2/msis2_acceloffPCE_kamodo_interface/DENSITY/icesat2_2018336_54hr.msis2_msisin', \n",
    "#                     skiprows = 1, \n",
    "                    dtype=object,\n",
    "                    names = ['YYMMDD',\n",
    "                             'HHMMSS',\n",
    "                             'Height_kilometers',\n",
    "                             'Lat',\n",
    "                             'Lon',\n",
    "                             'STLOC',\n",
    "                             'AVGFLX',\n",
    "                             'FLUX',\n",
    "                                 ],\n",
    "                    sep = '\\s+',\n",
    "                    )\n",
    "\n",
    "\n",
    "sat_time1 = list(DEN_csv['YYMMDD'])  #\"031115\" #  \n",
    "sat_time2 = list(DEN_csv['HHMMSS'])  #\"120000\" #1068897600        \n",
    "sattime   =    [x+y   for x,y   in zip(sat_time1, sat_time2)]\n",
    "\n",
    "sattime   =    [datetime.strptime(x, '%y%m%d%H%M%S')   for x   in sattime ]\n",
    "sattime   =    [datetime.timestamp(x)   for x   in sattime ]\n",
    "\n",
    "DEN_csv['sattime_utctimestamp'] = sattime\n",
    "# DEN_csv['Height_kilometers'] = DEN_csv['Height (meters)'].astype(float)*1e-3\n",
    "DEN_csv['Lon'] = DEN_csv['Lon'].astype(float)\n",
    "DEN_csv['Lat'] = DEN_csv['Lat'].astype(float)\n",
    "\n",
    "timeHHMMSS = [] \n",
    "for i,val in enumerate(DEN_csv['HHMMSS'].values.astype(int)):\n",
    "    # print(len(str(val)))\n",
    "    if len(str(val)) == 1:\n",
    "        timehhmmss_val = '00000'+ str(val)\n",
    "        timeHHMMSS.append(timehhmmss_val)\n",
    "    elif len(str(val)) == 2:\n",
    "        timehhmmss_val = '0000'+ str(val)\n",
    "        timeHHMMSS.append(timehhmmss_val)\n",
    "    elif len(str(val)) == 3:\n",
    "        timehhmmss_val = '000'+ str(val)\n",
    "        timeHHMMSS.append(timehhmmss_val)\n",
    "    elif len(str(val)) == 4:\n",
    "        timehhmmss_val = '00'+ str(val)\n",
    "        timeHHMMSS.append(timehhmmss_val)\n",
    "    elif len(str(val)) == 5:\n",
    "        timehhmmss_val = '0'+ str(val)\n",
    "        timeHHMMSS.append(timehhmmss_val)\n",
    "    else:\n",
    "        timeHHMMSS.append(str(val))\n",
    "DEN_csv['timeHHMMSS'] = timeHHMMSS\n",
    "YR = int(18)\n",
    "\n",
    "YYMMDD_list = DEN_csv['YYMMDD'].astype(int).astype(str)\n",
    "timeHHMMSS_list = DEN_csv['timeHHMMSS'].astype(str)\n",
    "\n",
    "if YR < 10:\n",
    "    year    = ['200' + x[:1]  for x in YYMMDD_list]\n",
    "    month   = [        x[1:3] for x in YYMMDD_list]\n",
    "    day     = [        x[3:]  for x in YYMMDD_list]\n",
    "    hours   = [        x[:2]  for x in timeHHMMSS_list]\n",
    "    minutes = [        x[2:4] for x in timeHHMMSS_list]\n",
    "    secs    = [        x[4:]  for x in timeHHMMSS_list]\n",
    "else:\n",
    "    year    = ['20' + x[:2]  for x in YYMMDD_list]\n",
    "    month   = [       x[2:4] for x in YYMMDD_list]\n",
    "    day     = [       x[4:]  for x in YYMMDD_list]\n",
    "    hours   = [       x[:2]  for x in timeHHMMSS_list]\n",
    "    minutes = [       x[2:4] for x in timeHHMMSS_list]\n",
    "    secs    = [       x[4:]  for x in timeHHMMSS_list]\n",
    "#--------------------------------------------------------\n",
    "DEN_csv['year']  = year\n",
    "DEN_csv['month'] = month\n",
    "DEN_csv['day']   = day\n",
    "DEN_csv['hours']  = hours\n",
    "DEN_csv['minutes'] = minutes\n",
    "DEN_csv['secs']  = secs\n",
    "#--------------------------------------------------------\n",
    "year= list(map(int, DEN_csv['year'].values))\n",
    "month= list(map(int, DEN_csv['month'].values))\n",
    "day= list(map(int, DEN_csv['day'].values))\n",
    "hour= list(map(int, DEN_csv['hours'].values))\n",
    "minute = list(map(int, DEN_csv['minutes'].values))\n",
    "second = list(map(int, DEN_csv['secs'].values))\n",
    "\n",
    "DATE = list(map(datetime, year,month, day, hour,minute,second ))\n",
    "\n",
    "#self.DEN_df['Date']  = DATE\n",
    "DEN_csv.insert(0, 'Date', DATE)\n",
    "\n",
    "del DEN_csv['timeHHMMSS']\n",
    "del DEN_csv['year']\n",
    "del DEN_csv['month']\n",
    "del DEN_csv['day']\n",
    "del DEN_csv['hours']\n",
    "del DEN_csv['minutes']\n",
    "del DEN_csv['secs']\n",
    "\n",
    "\n",
    "DEN_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69664f59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T18:17:36.613596Z",
     "start_time": "2021-09-10T18:17:36.605157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516852"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14357*9*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b0078cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T18:17:36.641630Z",
     "start_time": "2021-09-10T18:17:36.616373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>YYMMDD</th>\n",
       "      <th>HHMMSS</th>\n",
       "      <th>Height_kilometers</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>STLOC</th>\n",
       "      <th>AVGFLX</th>\n",
       "      <th>FLUX</th>\n",
       "      <th>sattime_utctimestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-01 21:01:09</td>\n",
       "      <td>181201</td>\n",
       "      <td>210109</td>\n",
       "      <td>486.242</td>\n",
       "      <td>41.976</td>\n",
       "      <td>65.686</td>\n",
       "      <td>1.55973</td>\n",
       "      <td>70.34</td>\n",
       "      <td>68.16</td>\n",
       "      <td>1.543698e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-01 21:02:09</td>\n",
       "      <td>181201</td>\n",
       "      <td>210209</td>\n",
       "      <td>485.539</td>\n",
       "      <td>38.151</td>\n",
       "      <td>65.208</td>\n",
       "      <td>1.54454</td>\n",
       "      <td>70.34</td>\n",
       "      <td>68.16</td>\n",
       "      <td>1.543698e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-01 21:03:09</td>\n",
       "      <td>181201</td>\n",
       "      <td>210309</td>\n",
       "      <td>484.882</td>\n",
       "      <td>34.323</td>\n",
       "      <td>64.753</td>\n",
       "      <td>1.53085</td>\n",
       "      <td>70.34</td>\n",
       "      <td>68.16</td>\n",
       "      <td>1.543698e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-01 21:04:09</td>\n",
       "      <td>181201</td>\n",
       "      <td>210409</td>\n",
       "      <td>484.290</td>\n",
       "      <td>30.492</td>\n",
       "      <td>64.316</td>\n",
       "      <td>1.51836</td>\n",
       "      <td>70.34</td>\n",
       "      <td>68.16</td>\n",
       "      <td>1.543698e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-01 21:05:09</td>\n",
       "      <td>181201</td>\n",
       "      <td>210509</td>\n",
       "      <td>483.779</td>\n",
       "      <td>26.659</td>\n",
       "      <td>63.892</td>\n",
       "      <td>1.50679</td>\n",
       "      <td>70.34</td>\n",
       "      <td>68.16</td>\n",
       "      <td>1.543698e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14353</th>\n",
       "      <td>2018-12-04 02:42:09</td>\n",
       "      <td>181204</td>\n",
       "      <td>024209</td>\n",
       "      <td>488.215</td>\n",
       "      <td>-16.097</td>\n",
       "      <td>-23.534</td>\n",
       "      <td>1.28048</td>\n",
       "      <td>70.27</td>\n",
       "      <td>68.67</td>\n",
       "      <td>1.543891e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14354</th>\n",
       "      <td>2018-12-04 02:43:09</td>\n",
       "      <td>181204</td>\n",
       "      <td>024309</td>\n",
       "      <td>489.508</td>\n",
       "      <td>-19.929</td>\n",
       "      <td>-23.932</td>\n",
       "      <td>1.27060</td>\n",
       "      <td>70.27</td>\n",
       "      <td>68.67</td>\n",
       "      <td>1.543891e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14355</th>\n",
       "      <td>2018-12-04 02:44:09</td>\n",
       "      <td>181204</td>\n",
       "      <td>024409</td>\n",
       "      <td>490.911</td>\n",
       "      <td>-23.759</td>\n",
       "      <td>-24.337</td>\n",
       "      <td>1.26023</td>\n",
       "      <td>70.27</td>\n",
       "      <td>68.67</td>\n",
       "      <td>1.543891e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14356</th>\n",
       "      <td>2018-12-04 02:45:09</td>\n",
       "      <td>181204</td>\n",
       "      <td>024509</td>\n",
       "      <td>492.405</td>\n",
       "      <td>-27.585</td>\n",
       "      <td>-24.752</td>\n",
       "      <td>1.24925</td>\n",
       "      <td>70.27</td>\n",
       "      <td>68.67</td>\n",
       "      <td>1.543892e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14357</th>\n",
       "      <td>2018-12-04 02:46:09</td>\n",
       "      <td>181204</td>\n",
       "      <td>024609</td>\n",
       "      <td>493.973</td>\n",
       "      <td>-31.407</td>\n",
       "      <td>-25.178</td>\n",
       "      <td>1.23748</td>\n",
       "      <td>70.27</td>\n",
       "      <td>68.66</td>\n",
       "      <td>1.543892e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14358 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Date  YYMMDD  HHMMSS Height_kilometers     Lat     Lon  \\\n",
       "0     2018-12-01 21:01:09  181201  210109           486.242  41.976  65.686   \n",
       "1     2018-12-01 21:02:09  181201  210209           485.539  38.151  65.208   \n",
       "2     2018-12-01 21:03:09  181201  210309           484.882  34.323  64.753   \n",
       "3     2018-12-01 21:04:09  181201  210409           484.290  30.492  64.316   \n",
       "4     2018-12-01 21:05:09  181201  210509           483.779  26.659  63.892   \n",
       "...                   ...     ...     ...               ...     ...     ...   \n",
       "14353 2018-12-04 02:42:09  181204  024209           488.215 -16.097 -23.534   \n",
       "14354 2018-12-04 02:43:09  181204  024309           489.508 -19.929 -23.932   \n",
       "14355 2018-12-04 02:44:09  181204  024409           490.911 -23.759 -24.337   \n",
       "14356 2018-12-04 02:45:09  181204  024509           492.405 -27.585 -24.752   \n",
       "14357 2018-12-04 02:46:09  181204  024609           493.973 -31.407 -25.178   \n",
       "\n",
       "         STLOC AVGFLX   FLUX  sattime_utctimestamp  \n",
       "0      1.55973  70.34  68.16          1.543698e+09  \n",
       "1      1.54454  70.34  68.16          1.543698e+09  \n",
       "2      1.53085  70.34  68.16          1.543698e+09  \n",
       "3      1.51836  70.34  68.16          1.543698e+09  \n",
       "4      1.50679  70.34  68.16          1.543698e+09  \n",
       "...        ...    ...    ...                   ...  \n",
       "14353  1.28048  70.27  68.67          1.543891e+09  \n",
       "14354  1.27060  70.27  68.67          1.543891e+09  \n",
       "14355  1.26023  70.27  68.67          1.543891e+09  \n",
       "14356  1.24925  70.27  68.67          1.543892e+09  \n",
       "14357  1.23748  70.27  68.66          1.543892e+09  \n",
       "\n",
       "[14358 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEN_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c50627",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T23:19:21.882864Z",
     "start_time": "2021-09-01T23:19:21.868497Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c20448a",
   "metadata": {},
   "source": [
    "## Make a cube of uncertainty around the init_orbit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789a3cd0",
   "metadata": {},
   "source": [
    "**Considerations**\n",
    " - its possible that as long as our resolution is on par with MSIS we aren't introducing additional error. \n",
    " - Gauss legendre sampling scheme\n",
    " - Perhaps can access geodyn's sampling method in the early iterations.\n",
    " - nearest neighbor interpolation within Fortran for optimized speed. Weighted average for distance between each point\n",
    " - how much memory to story the data-table in memory.\n",
    "  - we will make MSISsubset  using msis\n",
    "\n",
    "\n",
    "**Desired Features in the Data Structure**\n",
    " - Must be able to interpolate to a desired location\n",
    " - Should be able to expand the bounds of uncertainty at any given timestep along the orbit\n",
    "    - prefereably without having to redo the already constructed portions\n",
    " - Each timestep should contain information on the `Lon`, `Lat`, `Alt` as well as the `RHO` and `DRHODZ` at each location\n",
    " - Include GEODYN run info (Satellite, Arc#, Arc Dates, density model used to initialize, etc.)\n",
    "\n",
    "\n",
    "Parent: timestep  \n",
    "    - each parent has square that contains uncertainty around the orbit \n",
    "    - lon lat, alt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0cb645d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T18:17:36.646197Z",
     "start_time": "2021-09-10T18:17:36.643790Z"
    }
   },
   "outputs": [],
   "source": [
    "# 20150*9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda37ea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T16:19:58.267370Z",
     "start_time": "2021-09-01T16:19:58.257824Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ffba60f",
   "metadata": {},
   "source": [
    "**START WITH A SIMPLE BOX**\n",
    "Just draw a cube around the coordinate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ea6740",
   "metadata": {},
   "source": [
    "## Next steps:\n",
    "\n",
    "1. What data structure would work best for FORTRAN to read these tables at each timestep?\n",
    "    - ~~linked list structue?~~\n",
    "    - ~~a look up table?~~\n",
    "    - ~~pass the dict straight to fortran?~~\n",
    "    - NETCDF file\n",
    "    - **CSV file lookup table**\n",
    "\n",
    "2. Do a full run of the INIT_ORBIT through the Kamodo Cube of Uncertainty function\n",
    "    - expand the deltas in each direction so that we always have our box surrounding the orbit.\n",
    "\n",
    "3. Plug this data structure into fortran such that at any given timestep, requested by GEODYN the value can be found in the cube.\n",
    "\n",
    "4. Add the interpolation function to the fortran code.\n",
    "\n",
    "5. Do a full run of Kamodo-TIEGCM with the new interpolation method \n",
    "    - there is a chance this wont work and we may need to go ahead and implement the improved grid in the cube.\n",
    "    \n",
    "    \n",
    "Additional Features and Queries that will need to be addressed:\n",
    "  - increase the resolution of the grid within the cube\n",
    "      - can maybe make it match MSISe2's grid resolution\n",
    "      - if we have many cubes within the overall cube surrounding our INIT_ORBIT, we should write a simple selector code block that checks which sub-cube the coordinate is in, and only do the interpolation with that sub-cube.\n",
    "  - determine by how much GEODYN perturbs the coordinates on the orbit in the early iterations\n",
    "  \n",
    "  - how can this all be written such that the file doesn't have to be re-written but is only added to.\n",
    "      - can we construct the data-structures on a grid relative to earth such that additions can be made from separate runs?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce2a7d1",
   "metadata": {},
   "source": [
    "### Write data as a simple CSV \n",
    "\n",
    "Just save each points time, value, coordinate, and corner on cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9ae2d8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T18:17:36.658967Z",
     "start_time": "2021-09-10T18:17:36.647491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14358"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_NUMS = np.size(DEN_csv['Date'])\n",
    "TEST_NUMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "299aa9fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T18:19:55.616474Z",
     "start_time": "2021-09-10T18:17:36.661421Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import time: 1.3782889880239964\n",
      "**** 181201210109 -- 0 ****\n",
      "**** 181201210209 -- 1 ****\n",
      "**** 181201210309 -- 2 ****\n",
      "**** 181201210409 -- 3 ****\n",
      "**** 181201210509 -- 4 ****\n",
      "**** 181201210009 -- 5 ****\n",
      "**** 181201205909 -- 6 ****\n",
      "**** 181201205809 -- 7 ****\n",
      "**** 181201205709 -- 8 ****\n",
      "**** 181201205609 -- 9 ****\n",
      "**** 181201210509 -- 10 ****\n",
      "**** 181201210409 -- 11 ****\n",
      "**** 181201210309 -- 12 ****\n",
      "**** 181201210209 -- 13 ****\n",
      "**** 181201210009 -- 14 ****\n",
      "**** 181201205909 -- 15 ****\n",
      "**** 181201205809 -- 16 ****\n",
      "**** 181201205709 -- 17 ****\n",
      "**** 181201205609 -- 18 ****\n",
      "**** 181201210509 -- 19 ****\n",
      "**** 181201210409 -- 20 ****\n",
      "**** 181201210309 -- 21 ****\n",
      "**** 181201210209 -- 22 ****\n",
      "**** 181201210009 -- 23 ****\n",
      "**** 181201205909 -- 24 ****\n",
      "**** 181201205809 -- 25 ****\n",
      "**** 181201205709 -- 26 ****\n",
      "**** 181201205609 -- 27 ****\n",
      "**** 181201210509 -- 28 ****\n",
      "**** 181201210409 -- 29 ****\n",
      "**** 181201210309 -- 30 ****\n",
      "**** 181201210209 -- 31 ****\n",
      "**** 181201210009 -- 32 ****\n",
      "**** 181201205909 -- 33 ****\n",
      "**** 181201205809 -- 34 ****\n",
      "**** 181201205709 -- 35 ****\n",
      "**** 181201205609 -- 36 ****\n",
      "**** 181201210509 -- 37 ****\n",
      "**** 181201210409 -- 38 ****\n",
      "**** 181201210309 -- 39 ****\n",
      "**** 181201210209 -- 40 ****\n",
      "**** 181201210009 -- 41 ****\n",
      "**** 181201205909 -- 42 ****\n",
      "**** 181201205809 -- 43 ****\n",
      "**** 181201205709 -- 44 ****\n",
      "**** 181201205609 -- 45 ****\n",
      "**** 181201210509 -- 46 ****\n",
      "**** 181201210409 -- 47 ****\n",
      "**** 181201210309 -- 48 ****\n",
      "**** 181201210209 -- 49 ****\n",
      "**** 181201210009 -- 50 ****\n",
      "**** 181201205909 -- 51 ****\n",
      "**** 181201205809 -- 52 ****\n",
      "**** 181201205709 -- 53 ****\n",
      "**** 181201205609 -- 54 ****\n",
      "**** 181201210509 -- 55 ****\n",
      "**** 181201210409 -- 56 ****\n",
      "**** 181201210309 -- 57 ****\n",
      "**** 181201210209 -- 58 ****\n",
      "**** 181201210009 -- 59 ****\n",
      "**** 181201205909 -- 60 ****\n",
      "**** 181201205809 -- 61 ****\n",
      "**** 181201205709 -- 62 ****\n",
      "**** 181201205609 -- 63 ****\n",
      "**** 181201210609 -- 64 ****\n",
      "**** 181201210709 -- 65 ****\n",
      "**** 181201210809 -- 66 ****\n",
      "**** 181201210909 -- 67 ****\n",
      "**** 181201211009 -- 68 ****\n",
      "**** 181201211109 -- 69 ****\n",
      "**** 181201211209 -- 70 ****\n",
      "**** 181201211309 -- 71 ****\n",
      "**** 181201211409 -- 72 ****\n",
      "**** 181201211509 -- 73 ****\n",
      "**** 181201211609 -- 74 ****\n",
      "**** 181201211709 -- 75 ****\n",
      "**** 181201211809 -- 76 ****\n",
      "**** 181201211909 -- 77 ****\n",
      "**** 181201212009 -- 78 ****\n",
      "**** 181201212109 -- 79 ****\n",
      "**** 181201212209 -- 80 ****\n",
      "**** 181201212309 -- 81 ****\n",
      "**** 181201212409 -- 82 ****\n",
      "**** 181201212509 -- 83 ****\n",
      "**** 181201212609 -- 84 ****\n",
      "**** 181201212709 -- 85 ****\n",
      "**** 181201212809 -- 86 ****\n",
      "**** 181201212909 -- 87 ****\n",
      "**** 181201213009 -- 88 ****\n",
      "**** 181201213109 -- 89 ****\n",
      "**** 181201213209 -- 90 ****\n",
      "**** 181201213309 -- 91 ****\n",
      "**** 181201213409 -- 92 ****\n",
      "**** 181201213509 -- 93 ****\n",
      "**** 181201213609 -- 94 ****\n",
      "**** 181201213709 -- 95 ****\n",
      "**** 181201213809 -- 96 ****\n",
      "**** 181201213909 -- 97 ****\n",
      "**** 181201214009 -- 98 ****\n",
      "**** 181201214109 -- 99 ****\n",
      "**** 181201214209 -- 100 ****\n",
      "**** 181201214309 -- 101 ****\n",
      "**** 181201214409 -- 102 ****\n",
      "**** 181201214509 -- 103 ****\n",
      "**** 181201214609 -- 104 ****\n",
      "**** 181201214709 -- 105 ****\n",
      "**** 181201214809 -- 106 ****\n",
      "**** 181201214909 -- 107 ****\n",
      "**** 181201215009 -- 108 ****\n",
      "**** 181201215109 -- 109 ****\n",
      "**** 181201215209 -- 110 ****\n",
      "**** 181201215309 -- 111 ****\n",
      "**** 181201215409 -- 112 ****\n",
      "**** 181201215509 -- 113 ****\n",
      "**** 181201215609 -- 114 ****\n",
      "**** 181201215709 -- 115 ****\n",
      "**** 181201215809 -- 116 ****\n",
      "**** 181201215909 -- 117 ****\n",
      "**** 181201220009 -- 118 ****\n",
      "**** 181201220109 -- 119 ****\n",
      "**** 181201220209 -- 120 ****\n",
      "**** 181201220309 -- 121 ****\n",
      "**** 181201220409 -- 122 ****\n",
      "**** 181201220509 -- 123 ****\n",
      "**** 181201220609 -- 124 ****\n",
      "**** 181201220709 -- 125 ****\n",
      "**** 181201220809 -- 126 ****\n",
      "**** 181201220909 -- 127 ****\n",
      "**** 181201221009 -- 128 ****\n",
      "**** 181201221109 -- 129 ****\n",
      "**** 181201221209 -- 130 ****\n",
      "**** 181201221309 -- 131 ****\n",
      "**** 181201221409 -- 132 ****\n",
      "**** 181201221509 -- 133 ****\n",
      "**** 181201221609 -- 134 ****\n",
      "**** 181201221709 -- 135 ****\n",
      "**** 181201221809 -- 136 ****\n",
      "**** 181201221909 -- 137 ****\n",
      "**** 181201222009 -- 138 ****\n",
      "**** 181201222109 -- 139 ****\n",
      "**** 181201222209 -- 140 ****\n",
      "**** 181201222309 -- 141 ****\n",
      "**** 181201222409 -- 142 ****\n",
      "**** 181201222509 -- 143 ****\n",
      "**** 181201222609 -- 144 ****\n",
      "**** 181201222709 -- 145 ****\n",
      "**** 181201222809 -- 146 ****\n",
      "**** 181201222909 -- 147 ****\n",
      "**** 181201223009 -- 148 ****\n",
      "**** 181201223109 -- 149 ****\n",
      "**** 181201223209 -- 150 ****\n",
      "**** 181201223309 -- 151 ****\n",
      "**** 181201223409 -- 152 ****\n",
      "**** 181201223509 -- 153 ****\n",
      "**** 181201223609 -- 154 ****\n",
      "**** 181201223709 -- 155 ****\n",
      "**** 181201223809 -- 156 ****\n",
      "**** 181201223909 -- 157 ****\n",
      "**** 181201224009 -- 158 ****\n",
      "**** 181201224109 -- 159 ****\n",
      "**** 181201224209 -- 160 ****\n",
      "**** 181201224309 -- 161 ****\n",
      "**** 181201224409 -- 162 ****\n",
      "**** 181201224509 -- 163 ****\n",
      "**** 181201224609 -- 164 ****\n",
      "**** 181201224709 -- 165 ****\n",
      "**** 181201224809 -- 166 ****\n",
      "**** 181201224909 -- 167 ****\n",
      "**** 181201225009 -- 168 ****\n",
      "**** 181201225109 -- 169 ****\n",
      "**** 181201225209 -- 170 ****\n",
      "**** 181201225309 -- 171 ****\n",
      "**** 181201225409 -- 172 ****\n",
      "**** 181201225509 -- 173 ****\n",
      "**** 181201225609 -- 174 ****\n",
      "**** 181201225709 -- 175 ****\n",
      "**** 181201225809 -- 176 ****\n",
      "**** 181201225909 -- 177 ****\n",
      "**** 181201230009 -- 178 ****\n",
      "**** 181201230109 -- 179 ****\n",
      "**** 181201230209 -- 180 ****\n",
      "**** 181201230309 -- 181 ****\n",
      "**** 181201230409 -- 182 ****\n",
      "**** 181201230509 -- 183 ****\n",
      "**** 181201230609 -- 184 ****\n",
      "**** 181201230709 -- 185 ****\n",
      "**** 181201230809 -- 186 ****\n",
      "**** 181201230909 -- 187 ****\n",
      "**** 181201231009 -- 188 ****\n",
      "**** 181201231109 -- 189 ****\n",
      "**** 181201231209 -- 190 ****\n",
      "**** 181201231309 -- 191 ****\n",
      "**** 181201231409 -- 192 ****\n",
      "**** 181201231509 -- 193 ****\n",
      "**** 181201231609 -- 194 ****\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-42655b08f6d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m## Plug vectorized coordinates into Kamodo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     results = ModelFlythrough(model, file_dir, variable_list, sat_time, c1, c2, c3, \n\u001b[0m\u001b[1;32m     85\u001b[0m                         \u001b[0mcoord_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh_res\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                         csv_output='', plot_output='')\n",
      "\u001b[0;32m/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/SatelliteFlythrough.py\u001b[0m in \u001b[0;36mModelFlythrough\u001b[0;34m(model, file_dir, variable_list, sat_time, c1, c2, c3, coord_type, coord_grid, high_res, verbose, csv_output, plot_output)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m#get interpolated results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;31m#coord_type should be one of SpacePy's coordinates, coord_grid is either 'sph' or 'car'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     results = U.Model_SatelliteFlythrough(model, file_dir, variable_list, \n\u001b[0m\u001b[1;32m    185\u001b[0m                                 \u001b[0msat_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                                 \u001b[0mcoord_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh_res\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/SF_utilities.py\u001b[0m in \u001b[0;36mModel_SatelliteFlythrough\u001b[0;34m(model, file_dir, variable_list, sat_time, c1, c2, c3, coord_type, coord_grid, high_res, verbose)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;31m#interpolate requested data for each day. FlyAway is specific to each wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;31m#reader, file_name, variable_list, sat_time in hrs, c1, c2, c3, z_unit, z_dependencies, high_res\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         list_results = [Model_FlyAway(reader, times[file_date][0], coord_dict[key][0], \n\u001b[0m\u001b[1;32m    626\u001b[0m                                           \u001b[0mts_to_hrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msat_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_date\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_date\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                                           \u001b[0mcoord_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_date\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/SF_utilities.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;31m#interpolate requested data for each day. FlyAway is specific to each wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;31m#reader, file_name, variable_list, sat_time in hrs, c1, c2, c3, z_unit, z_dependencies, high_res\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         list_results = [Model_FlyAway(reader, times[file_date][0], coord_dict[key][0], \n\u001b[0m\u001b[1;32m    626\u001b[0m                                           \u001b[0mts_to_hrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msat_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_date\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_date\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                                           \u001b[0mcoord_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_date\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/SF_utilities.py\u001b[0m in \u001b[0;36mModel_FlyAway\u001b[0;34m(reader, filename, variable_list, sat_time, c1, c2, c3, z_unit, z_dependencies, high_res, verbose)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m#create kamodo object, initialize some variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#save copy before it gets altered by the reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mkamodo_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariable_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgridded_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m#create satellite tracks of types needed based on vertical dependencies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/readers/tiegcm_4D.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, full_filename, variables_requested, runname, filetime, verbose, gridded_int, printfiles, fulltime, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;31m#                     print(\"C\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     self.register_4D_variable(self.variables[varname]['units'], \n\u001b[0m\u001b[1;32m    386\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvarname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvarname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                                           gridded_int)\n",
      "\u001b[0;32m/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/readers/tiegcm_4D.py\u001b[0m in \u001b[0;36mregister_4D_variable\u001b[0;34m(self, units, variable, varname, gridded_int)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;31m#### define and register the interpolators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'lat'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxvec_dependencies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m                 \u001b[0mwrapped_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_4Dlatlon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvarname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                 \u001b[0mtop_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/readers/tiegcm_4D.py\u001b[0m in \u001b[0;36mwrap_4Dlatlon\u001b[0;34m(self, varname, variable)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mshape_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m  \u001b[0;31m#need one more place in longitude\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mtmp_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_list\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#array to set-up wrapped data in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mtmp_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariable\u001b[0m  \u001b[0;31m#copy data into grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mtmp_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m#wrap in longitude first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mtmp_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#wrap in latitude...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "from SingleSatelliteFlythrough import SingleModelFlythrough\n",
    "sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "from SatelliteFlythrough import ModelFlythrough\n",
    "\n",
    "\n",
    "times_list = []\n",
    "lons_list = []\n",
    "lats_list = []\n",
    "alts_list = []\n",
    "rhos_list = []\n",
    "# drhodz_list = []\n",
    "cube_corner = []\n",
    "\n",
    "count=0\n",
    "for it,val in enumerate(DEN_csv['Date'][:TEST_NUMS]):\n",
    "    \n",
    "    date_index = DEN_csv['YYMMDD'][it] + DEN_csv['HHMMSS'][it]\n",
    "#     date_index = datetime.strptime(date_str, '%y%m%d%H%M%S')\n",
    "    unix_time  = DEN_csv['sattime_utctimestamp'][it]\n",
    "    print('****',date_index,'--',count, '****' )    \n",
    "    count+=1\n",
    "\n",
    "    ### Get the coordinates along the orbit:\n",
    "    lon = float(DEN_csv['Lon'][it])\n",
    "    lat = float(DEN_csv['Lat'][it])\n",
    "    alt = float(DEN_csv['Height_kilometers'][it])\n",
    "    center_coord = [lon, lat, alt]\n",
    "    \n",
    "    \n",
    "    ### Find the coordinates of the cube surround the orbit point:\n",
    "    delta_deg = 2    # degrees\n",
    "    delta_m = 1000.*1e-3 # meters to kilometers\n",
    "    A = [lon + delta_deg, lat+delta_deg, alt+delta_m]  # top,    front, left\n",
    "    B = [lon + delta_deg, lat-delta_deg, alt+delta_m]  # top,    back,  Left\n",
    "    C = [lon - delta_deg, lat+delta_deg, alt+delta_m]  # top,    front, right\n",
    "    D = [lon - delta_deg, lat-delta_deg, alt+delta_m]  # top,    back,  right\n",
    "    E = [lon + delta_deg, lat+delta_deg, alt-delta_m]  # bottom, front, left\n",
    "    F = [lon + delta_deg, lat-delta_deg, alt-delta_m]  # bottom, back,  left\n",
    "    G = [lon - delta_deg, lat+delta_deg, alt-delta_m]  # bottom, front, right\n",
    "    H = [lon - delta_deg, lat-delta_deg, alt-delta_m]  # bottom, back,  right\n",
    "    \n",
    "    \n",
    "    ### Store the cube's coordinates in the dictionary index\n",
    "    cube_corners_and_center = []\n",
    "    cube_corners_and_center.append(center_coord)\n",
    "    cube_corners_and_center.append(A)\n",
    "    cube_corners_and_center.append(B)\n",
    "    cube_corners_and_center.append(C)\n",
    "    cube_corners_and_center.append(D)\n",
    "    cube_corners_and_center.append(E)\n",
    "    cube_corners_and_center.append(F)\n",
    "    cube_corners_and_center.append(G)\n",
    "    cube_corners_and_center.append(H)\n",
    "    \n",
    "    #### Import Coordinates to Kamodo\n",
    "    ##\n",
    "    #### Kamodo static inputs:\n",
    "    model          = 'TIEGCM'\n",
    "    file_dir       = '/data/data_geodyn/atmos_models_data/tiegcm/2018/Lutz_Rastaetter_072319_IT_1/'\n",
    "    variable_list  = ['rho','psi_O2', 'psi_O',  'psi_He', 'T_n']\n",
    "    coord_type     = 'SPH'\n",
    "    coord_grid     = 'sph'\n",
    "    high_res       = 1.\n",
    "    verbose        = False  \n",
    "    csv_output     = '' \n",
    "    plot_output    = ''\n",
    "    \n",
    "    \n",
    "    #### Extract the coordinates from each list to plug into Kamodo with vectorization\n",
    "    lons_in = [item[0] for item in cube_corners_and_center]\n",
    "    lats_in = [item[1] for item in cube_corners_and_center]\n",
    "    alts_in = [item[2] for item in cube_corners_and_center]\n",
    "       \n",
    "    \n",
    "    ## Gather inputs\n",
    "    sat_time       = unix_time*np.ones(np.size(alts_in))\n",
    "    c1             = lons_in\n",
    "    c2             = lats_in\n",
    "    c3             = alts_in\n",
    "    \n",
    "    ## Plug vectorized coordinates into Kamodo\n",
    "    results = ModelFlythrough(model, file_dir, variable_list, sat_time, c1, c2, c3, \n",
    "                        coord_type, coord_grid, high_res=20., verbose=False, \n",
    "                        csv_output='', plot_output='')\n",
    "\n",
    "    \n",
    "    \n",
    "    corners = ['0','1','2','3','4','5','6','7','8']\n",
    "    for ival, valrho in enumerate(results['rho']):\n",
    "#         print(ival)\n",
    "        times_list.append(date_index)\n",
    "        lons_list.append(results['c1'][ival])\n",
    "        lats_list.append(results['c2'][ival])\n",
    "        alts_list.append(results['c3'][ival])\n",
    "        rhos_list.append(valrho)\n",
    "#         drhodz_list.append( )\n",
    "        cube_corner.append(corners[ival])\n",
    "    \n",
    "\n",
    "filename ='/data/data_geodyn/atmos_models_data/tiegcm/2018/Lutz_Rastaetter_072319_IT_1/orbit_step60_w_UncCub_csv.csv'\n",
    "\n",
    "# pd.options.display.float_format = '${:,.6f}'.format\n",
    "\n",
    "df = pd.DataFrame(data={\n",
    "                        'times':times_list  ,\n",
    "                        'lon':lons_list  ,\n",
    "                        'lat':lats_list  ,\n",
    "                        'alt':alts_list  ,\n",
    "                        'rho':rhos_list  ,\n",
    "                        'corner':cube_corner  ,\n",
    "                        })\n",
    "\n",
    "file = open(filename,  'w')\n",
    "for i,val in enumerate(df['times']):\n",
    "    file.write(f\"{df['times'][i]}   {df['lon'][i]:8.4f}   {df['lat'][i]:8.4f}   {df['alt'][i]:8.4f}   {df['rho'][i]:15.8e}   {df['corner'][i]} \\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce794a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T18:19:55.619078Z",
     "start_time": "2021-09-10T18:17:35.049Z"
    }
   },
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4c915e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T01:20:58.750784Z",
     "start_time": "2021-09-08T01:20:58.729880Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315a69a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T15:51:07.663263Z",
     "start_time": "2021-09-08T15:51:07.653348Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e9cdf56",
   "metadata": {},
   "source": [
    "## Compare indexed rho to pymsis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c5362",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T18:19:55.619964Z",
     "start_time": "2021-09-10T18:17:35.052Z"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from pymsis import msis\n",
    "# import pandas as pd\n",
    "# import sys\n",
    "# sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "# from SingleSatelliteFlythrough import SingleModelFlythrough\n",
    "# sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "# from SatelliteFlythrough import ModelFlythrough\n",
    "\n",
    "\n",
    "# # import pandas as pd\n",
    "# msisin_den_file = '/data/data_geodyn/results/st/msis2/msis2_acceloffSLR_kamodo_interface/DENSITY/' + \"st031109_2wk.goco05s_msisin\"\n",
    "# # DEN_csv = pd.read_csv('/data/data_geodyn/results/icesat2/msis2/msis2_acceloffPCE_kamodo_interface/DENSITY/icesat2_2018336_54hr.msis2_msisin', \n",
    "# # #                     skiprows = 1, \n",
    "# #                     dtype=object,\n",
    "# #                     names = ['YYMMDD',\n",
    "# #                              'HHMMSS',\n",
    "# #                              'Height_kilometers',\n",
    "# #                              'Lat',\n",
    "# #                              'Lon',\n",
    "# #                              'STLOC',\n",
    "# #                              'AVGFLX',\n",
    "# #                              'FLUX',\n",
    "# #                                  ],\n",
    "# #                     sep = '\\s+',\n",
    "# #                     )\n",
    "\n",
    "# DEN1_csv = pd.read_csv(msisin_den_file, \n",
    "#                     skiprows = 1, \n",
    "#                     names = ['IYYDDD',\n",
    "#                              'IYR',\n",
    "#                               'DAY',\n",
    "#                              'UTSEC',\n",
    "#                              'ALTKM',\n",
    "#                              'GLAT',\n",
    "#                              'GLON',\n",
    "#                              'STLOC', \n",
    "#                              'AVGFLX',\n",
    "#                              'FLUX',\n",
    "#                              'AP1',\n",
    "#                              'AP2',\n",
    "#                              'AP3',\n",
    "#                              'AP4',\n",
    "#                              'AP5',\n",
    "#                              'AP6',\n",
    "#                              'AP7',\n",
    "#                             ],\n",
    "#                     sep = '\\s+',\n",
    "#                     )\n",
    "\n",
    "\n",
    "# DEN1_csv['Date'] = (pd.to_datetime('0'+ ((DEN1_csv['IYR'].astype(int).astype(str))),  format='%y') \n",
    "#                     +  pd.to_timedelta(DEN1_csv['DAY'], unit='days'))\n",
    "\n",
    "\n",
    "\n",
    "# SWI_option = [1.0]*25\n",
    "# SWI_option[8] = -1.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# msis2_df= pd.DataFrame(data={'Rho'   :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "# #                               'N2'    :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "# #                               'O2'    :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "# #                               'O'     :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "# #                               'He'    :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "# #                               'H'     :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "# #                               'Ar'    :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "# #                               'N'     :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "# #                               'AnomO' :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "# #                               'NO'    :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "# #                               'Temp'  :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "#                             })\n",
    "\n",
    "\n",
    "# for index, row in DEN1_csv[:500].iterrows():\n",
    "\n",
    "#     lon = DEN_csv['Lon'][index] #row['GLON']\n",
    "#     lat = DEN_csv['Lat'][index] #row['GLAT']\n",
    "#     alts = DEN_csv['Height_kilometers'][index] #row['ALTKM']   \n",
    "#     f107 = DEN_csv['FLUX'][index] # row['FLUX'] \n",
    "#     f107a = DEN_csv['AVGFLX'][index] # row['AVGFLX']\n",
    "\n",
    "#     aps = [[row['AP1'],row['AP2'],row['AP3'],row['AP4'],row['AP5'],row['AP6'],row['AP7']]]\n",
    "#     date = DEN_csv['Date'][index]  #row['Date']\n",
    "\n",
    "#     msis_data2 =  msis.run(date, lon, lat, alts, f107, f107a, aps, version=2,  options = SWI_option)\n",
    "#     msis_data2  = np.squeeze(msis_data2)\n",
    "\n",
    "#     msis2_df.loc[index, 'Rho'] = msis_data2[0]\n",
    "#     msis2_df.loc[index, 'Date'] = row['Date']\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "#     #### Kamodo static inputs:\n",
    "#     model          = 'TIEGCM'\n",
    "#     file_dir       = '/data/data_geodyn/atmos_models_data/tiegcm/2018/Lutz_Rastaetter_072319_IT_1/'\n",
    "#     variable_list  = ['rho','psi_O2', 'psi_O',  'psi_He', 'T_n']\n",
    "#     coord_type     = 'SPH'\n",
    "#     coord_grid     = 'sph'\n",
    "#     high_res       = 1.\n",
    "#     verbose        = False  \n",
    "#     csv_output     = '' \n",
    "#     plot_output    = ''\n",
    "    \n",
    "           \n",
    "#     unix_time  = DEN_csv['sattime_utctimestamp'][index]\n",
    "# #                 DEN_csv['Lon'][index]\n",
    "#     ## Gather inputs\n",
    "#     sat_time       = unix_time*np.ones(np.size(lon))\n",
    "#     c1             = [float(lon)]\n",
    "#     c2             = [float(lat)]\n",
    "#     c3             = [float(alts)]\n",
    "    \n",
    "#     ## Plug vectorized coordinates into Kamodo\n",
    "#     results = ModelFlythrough(model, file_dir, variable_list, sat_time, c1, c2, c3, \n",
    "#                         coord_type, coord_grid, high_res=20., verbose=False, \n",
    "#                         csv_output='', plot_output='')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# #################### MAKE PLOT ####################\n",
    "\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.offline import plot, iplot\n",
    "# from plotly.subplots import make_subplots\n",
    "# import plotly.express as px\n",
    "\n",
    "\n",
    "# config = dict({\n",
    "#                 'displayModeBar': True,\n",
    "#                 'responsive': False,\n",
    "#                 'staticPlot': False,\n",
    "#                 'displaylogo': False,\n",
    "#                 'showTips': False,\n",
    "#                 })\n",
    "\n",
    "# fig = make_subplots(rows=1, cols=1,\n",
    "#                    )\n",
    "# fig.add_trace(go.Scatter(x=msis2_df['Date'][:500],\n",
    "#                          y=msis2_df['Rho'][:500],\n",
    "#                          name= 'MSIS2 direct read',\n",
    "#                          mode='markers',\n",
    "#                          marker=dict(size=8)),\n",
    "#                          )\n",
    "# fig.add_trace(go.Scatter(y=DEN_csv['rho (kg/m**3)'][:500],\n",
    "#                          x=DEN_csv['Date'][:500],\n",
    "#                          name= 'Density File (GEODYN_msis2)',\n",
    "#                          mode='markers',\n",
    "#                         marker=dict(size=4)),\n",
    "#                          )\n",
    "                        \n",
    "# # fig.add_trace(go.Scatter(y=results['max_height']*1e-3, x=results['rho'], mode='markers'))\n",
    "\n",
    "# fig.update_yaxes(type=\"log\", exponentformat= 'power', row=1, col=1, title ='Den')\n",
    "# fig.update_xaxes(title ='Date')\n",
    "# fig.update_layout(title=\"MSIS2 Direct Read, Comparison of Values\")\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b91862b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T15:54:51.215676Z",
     "start_time": "2021-09-08T15:54:51.211893Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
