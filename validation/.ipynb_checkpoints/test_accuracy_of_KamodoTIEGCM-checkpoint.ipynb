{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87b2d542",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:28:21.608641Z",
     "start_time": "2021-12-10T20:28:21.315876Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timezone, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85e677e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T23:32:47.136071Z",
     "start_time": "2021-12-10T23:32:46.475114Z"
    }
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import numpy as np \n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot, iplot\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "config = dict({\n",
    "                'displayModeBar': True,\n",
    "                'responsive': False,\n",
    "                'staticPlot': False,\n",
    "                'displaylogo': False,\n",
    "                'showTips': False,\n",
    "                })\n",
    "\n",
    "# Simplify Plotting Schemes:\n",
    "col1 = px.colors.qualitative.Plotly[0]\n",
    "col2 = px.colors.qualitative.Plotly[1]\n",
    "col3 = px.colors.qualitative.Plotly[2]\n",
    "col4 = px.colors.qualitative.Plotly[3]\n",
    "col5 = px.colors.qualitative.Plotly[4]\n",
    "col6 = px.colors.qualitative.Plotly[5]\n",
    "\n",
    "\n",
    "\n",
    "def read_nc_file( filename, variables):\n",
    "    ''' This function reads the TIEGCM .nc files and saves the given input variables to a dictionary.\n",
    "        The breakloop feature is here so that if the file doesn't exist the code can still continue.  '''\n",
    "    status = os.path.exists(filename)\n",
    "    \n",
    "    if status == True:\n",
    "        data = {}\n",
    "        for i, var_names in enumerate(variables):\n",
    "            ncid =  Dataset(filename,\"r+\", format=\"NETCDF4\")# filename must be a string\n",
    "            varData = ncid.variables\n",
    "            data[var_names] = np.array(varData[var_names])  \n",
    "    elif status == False:\n",
    "        print('No File Found', filename )\n",
    "        breakloop = True\n",
    "        data = 0\n",
    "        return( data , breakloop)\n",
    "    breakloop = False\n",
    "    return(data,breakloop )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "41821303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T23:33:24.309249Z",
     "start_time": "2021-12-10T23:33:24.264286Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data '287' does not match format '%Y%j' (match)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime_to_datetime64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m                 \u001b[0mdta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatetimeArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtz_to_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unrecognized value type: <class 'str'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-e0a47359d6fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mf107a_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf107_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f107a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%Y%j'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mkp_expand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkp_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m    830\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    458\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                     result, timezones = array_strptime(\n\u001b[0m\u001b[1;32m    424\u001b[0m                         \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                     )\n",
      "\u001b[0;32mpandas/_libs/tslibs/strptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data '287' does not match format '%Y%j' (match)"
     ]
    }
   ],
   "source": [
    "path_to_f107 = '/data/data_geodyn/gpi_1960001-2021243_f107aDaily.nc'\n",
    "variables = ['year_day', 'f107d', 'f107a', 'kp']\n",
    "f107_data = read_nc_file(path_to_f107, variables)\n",
    "\n",
    "date = []\n",
    "kp_list = []\n",
    "f107d_list = []\n",
    "f107a_list  = []\n",
    "\n",
    "for i,val in enumerate(np.arange(287, 365, 1) ):\n",
    "    \n",
    "    index = f107_data[0]['year_day']==str(int('2018'+str(val)))\n",
    "    kp_list.append(f107_data[0]['kp'][index][0])\n",
    "    f107d_list.append(f107_data[0]['f107d'][index][0])\n",
    "    f107a_list.append(f107_data[0]['f107a'][index][0])\n",
    "    \n",
    "    date.append(pd.to_datetime( str(val), format='%Y%j'))\n",
    "kp_expand = []\n",
    "for i in kp_list:\n",
    "    for ii in i:\n",
    "        kp_expand.append(ii)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=(['F10.7', 'Kp']),\n",
    "    vertical_spacing = 0.2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scattergl(  x=date,\n",
    "                             y=f107d_list,\n",
    "                             name= 'f107d',\n",
    "                             mode='markers+lines',\n",
    "                             opacity=1,\n",
    "                             marker=dict(\n",
    "                                color=col2, \n",
    "                                size=8,\n",
    "                                        ),\n",
    "                             showlegend=True,\n",
    "                          ),\n",
    "                              secondary_y=False,\n",
    "                               row=1, col=1,\n",
    "                          )\n",
    "\n",
    "fig.add_trace(go.Scattergl(  x=date,\n",
    "                             y=f107a_list,\n",
    "                             name= 'f107a',\n",
    "                             mode='markers+lines',\n",
    "                             opacity=1,\n",
    "                             marker=dict(\n",
    "                                color=col1, \n",
    "                                size=8,\n",
    "                                        ),\n",
    "                             showlegend=True,\n",
    "                          ),\n",
    "                              secondary_y=False,\n",
    "                               row=1, col=1,\n",
    "                          )\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scattergl(  x=np.arange(1,np.size(kp_expand)),\n",
    "                             y=kp_expand,\n",
    "                             name= 'kp',\n",
    "                             mode='markers+lines',\n",
    "                             opacity=1,\n",
    "                             marker=dict(\n",
    "                                color=col3, \n",
    "                                size=8,\n",
    "                                        ),\n",
    "                             showlegend=True,\n",
    "                          ),\n",
    "                              secondary_y=False,\n",
    "                               row=2, col=1,\n",
    "                          )\n",
    "\n",
    "fig.update_layout(title= 'NGDC Geophysical Indices -- F10.7 and Kp',\n",
    "                autosize=True,\n",
    "                font=dict(size=14),\n",
    "                legend= {'itemsizing': 'constant'})\n",
    "\n",
    "fig.update_yaxes( title=\"sfu\", row=1, col=1)\n",
    "fig.update_yaxes( title=\"Kp\", row=2, col=1)\n",
    "\n",
    "fig.show(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7271c71f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T23:33:58.559020Z",
     "start_time": "2021-12-10T23:33:58.554574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018287"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int('2018'+str(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c79bd88",
   "metadata": {},
   "source": [
    "### TIEGCM manual functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa3a9f11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:28:21.646091Z",
     "start_time": "2021-12-10T20:28:21.610364Z"
    }
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import numpy as np \n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def read_tiegcm( filename, variables):\n",
    "    ''' This function reads the TIEGCM .nc files and saves the given input variables to a dictionary.\n",
    "        The breakloop feature is here so that if the file doesn't exist the code can still continue if placed in a loop.'''\n",
    "    status = os.path.exists(filename)\n",
    " \n",
    "    if status == True:\n",
    "        data = {}\n",
    "        for i, var_names in enumerate(variables):\n",
    "            ncid =  Dataset(filename,\"r+\", format=\"NETCDF4\")# filename must be a string\n",
    "            varData = ncid.variables\n",
    "            data[var_names] = np.array(varData[var_names])  \n",
    "    elif status == False:\n",
    "        print('No File Found', filename )\n",
    "        breakloop = True\n",
    "        data = 0\n",
    "        return( data , breakloop)\n",
    "    breakloop = False\n",
    "    return(data,breakloop )\n",
    "\n",
    "\n",
    "def find_modelgrid_base_index(TIEGCM, lon_sat, lat_sat, time_sat):\n",
    "    \"\"\" \n",
    "    Interpolation function: (3 / 5)\n",
    "\n",
    "    This function locates the grid points that make up thr square surrounding out desired point.\n",
    "    \"\"\"\n",
    "\n",
    "    lon_start = -180 # first longitude point of the model grid (deg)\n",
    "    dlon = 5  # difference between adjacent longitude grid points (deg)\n",
    "    index_lon0 = int(np.mod(np.floor( (lon_sat - lon_start )/dlon ), 72 ) ) \n",
    "\n",
    "\n",
    "    lat_start = -87.5 # first longitude point of the model grid (deg)\n",
    "    dlat = 5 # difference between adjacent longitude grid points (deg)\n",
    "    index_lat0 = int(np.mod(np.floor( (lat_sat - lat_start)/dlat ), 36 ) )\n",
    "\n",
    "    time_start = 0 # first longitude point of the model grid (deg)\n",
    "    dtime = 1 # difference between adjacent longitude grid points (deg)\n",
    "    index_time = int((np.mod(np.floor( (time_sat - time_start)/dtime ), 24 ) )) \n",
    "\n",
    "    if index_lon0 == 71:\n",
    "        index_lon1 = 0\n",
    "    else:\n",
    "        index_lon1 = index_lon0 + 1\n",
    "\n",
    "\n",
    "    if index_lat0 >= 35 :\n",
    "        index_lat1 = 35\n",
    "        NPole_Flag = True\n",
    "        SPole_Flag = False \n",
    "\n",
    "    elif index_lat0 <= 0: \n",
    "        index_lat1 = 0\n",
    "        SPole_Flag = True\n",
    "        NPole_Flag = False\n",
    "    else: \n",
    "        index_lat1 = index_lat0 + 1\n",
    "        NPole_Flag = False \n",
    "        SPole_Flag = False \n",
    "\n",
    "\n",
    "    return(index_lon0, index_lat0, index_lon1, index_lat1, index_time, NPole_Flag, SPole_Flag )\n",
    "\n",
    "\n",
    "def DEN_and_ZG_vertprofs(TIEGCM, lon_sat, lat_sat, time_sat, param):\n",
    "    '''\n",
    "    Interpolation function: (2 / 5)\n",
    "\n",
    "    This function finds the vertical profiles of the four grid points around a desired point.\n",
    "    '''\n",
    "    \n",
    "    #### First we find the four grid points:\n",
    "    (indexlon0, \n",
    "    indexlat0, \n",
    "    indexlon1, \n",
    "    indexlat1, \n",
    "    indexut, \n",
    "    NPole_Flag, \n",
    "    SPole_Flag) = find_modelgrid_base_index(TIEGCM, lon_sat, lat_sat, time_sat)\n",
    "    grid_vals = pd.DataFrame(data = {'lon0' : TIEGCM['lon'][indexlon0] ,\\\n",
    "                                 'lonindex0': indexlon0 ,\\\n",
    "                                 'lon1'     :TIEGCM['lon'][indexlon1] ,\\\n",
    "                                 'lonindex1':indexlon1 ,\\\n",
    "                                 'lat0'     :TIEGCM['lat'][indexlat0] ,\\\n",
    "                                 'latindex0':indexlat0 ,\\\n",
    "                                 'lat1'     :TIEGCM['lat'][indexlat1] ,\\\n",
    "                                 'latindex1':indexlat1  }, index=[0])\n",
    "    \n",
    "\n",
    "#     print('UT index',indexut)\n",
    "#     print('UT value',TIEGCM['ut'][indexut])\n",
    "#     print()\n",
    "#     print('Lon0 index',indexlon0)\n",
    "#     print('Lon0 value',TIEGCM['lon'][indexlon0])\n",
    "#     print('Lon1 index',indexlon1)\n",
    "#     print('Lon1 value',TIEGCM['lon'][indexlon1])\n",
    "#     print()\n",
    "#     print('Lat0 index',indexlat0)\n",
    "#     print('Lat0 value',TIEGCM['lat'][indexlat0])\n",
    "#     print('Lat1 index',indexlat1)\n",
    "#     print('Lat1 value',TIEGCM['lat'][indexlat1])\n",
    "    \n",
    "#     print('alt index',indexut)\n",
    "#     print('alt value',TIEGCM['ut'][indexut])\n",
    "\n",
    "    DEN_prof00 = TIEGCM[param][indexut, :-1, indexlat0, indexlon0]\n",
    "    DEN_prof10 = TIEGCM[param][indexut, :-1, indexlat1, indexlon0]\n",
    "    DEN_prof01 = TIEGCM[param][indexut, :-1, indexlat0, indexlon1]\n",
    "    DEN_prof11 = TIEGCM[param][indexut, :-1, indexlat1, indexlon1]\n",
    "    \n",
    "\n",
    "    ZG_prof00 = TIEGCM['ZG'][indexut, :-1, indexlat0, indexlon0]\n",
    "    ZG_prof10 = TIEGCM['ZG'][indexut, :-1, indexlat1, indexlon0]\n",
    "    ZG_prof01 = TIEGCM['ZG'][indexut, :-1, indexlat0, indexlon1]\n",
    "    ZG_prof11 = TIEGCM['ZG'][indexut, :-1, indexlat1, indexlon1]\n",
    "\n",
    "    DEN_df = pd.DataFrame(data = {'00' :DEN_prof00 ,\\\n",
    "                                  '10' :DEN_prof10 ,\\\n",
    "                                  '01' :DEN_prof01 ,\\\n",
    "                                  '11' :DEN_prof11 ,\\\n",
    "                                })\n",
    "    ZG_df = pd.DataFrame(data = {'00' :ZG_prof00 ,\\\n",
    "                                  '10' :ZG_prof10 ,\\\n",
    "                                  '01' :ZG_prof01 ,\\\n",
    "                                  '11' :ZG_prof11 ,\\\n",
    "                                })\n",
    "    return(DEN_df, ZG_df, grid_vals)\n",
    "\n",
    "\n",
    "\n",
    "def interp_DENSITY_to_altitude(DEN_df, ZG_df, height_sat):\n",
    "    '''\n",
    "    Interpolation function: (4 / 5)\n",
    "\n",
    "    This function interpolates Density in the log space then converts it back'''\n",
    "    density_surf_at_height_sat = np.zeros(np.size(ZG_df.columns))\n",
    "    i = 0\n",
    "    for col in ZG_df.columns:\n",
    "        xp = ZG_df[col][:].values\n",
    "        fp = DEN_df[col][:].values\n",
    "        xval = height_sat\n",
    "        density_surf_at_height_sat[i] =  np.exp( np.interp(xval, xp, np.log(fp))  )\n",
    "        i += 1\n",
    "    return(density_surf_at_height_sat)\n",
    "\n",
    "\n",
    "\n",
    "def interp_param_to_altitude(df, ZG_df, height_sat):\n",
    "    \n",
    "    '''\n",
    "    Interpolation function: (5 / 5)\n",
    "\n",
    "    This function interpolates all other parameters (not density) using linear interpolation\n",
    "    '''\n",
    "\n",
    "    param_surf_at_height_sat = np.zeros(np.size(ZG_df.columns))\n",
    "    i = 0\n",
    "    for col in ZG_df.columns:\n",
    "        xp = ZG_df[col][:].values\n",
    "        fp = df[col][:].values\n",
    "        xval = height_sat\n",
    "        param_surf_at_height_sat[i] =  np.interp(xval, xp, fp)  \n",
    "        i += 1\n",
    "    return(param_surf_at_height_sat)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def interpolate_tiegcm(TIEGCM, lon_sat, lat_sat, time_sat, height_sat, param):\n",
    "    '''\n",
    "    Interpolation function: (1 / 5)\n",
    "    \n",
    "    This function finds the interpolated value of a TIEGCM parameter.  \n",
    "    Interpolated to a desired lon,lat,alt\n",
    "    '''\n",
    "    \n",
    "    # Find the vertical profiles of the four grid points making up the grid square around your desired point.\n",
    "#     print('time_sat:', time_sat)\n",
    "    df, ZG_df, grid_vals = DEN_and_ZG_vertprofs(TIEGCM, lon_sat, lat_sat, time_sat, param)\n",
    "    \n",
    "    if param == 'DEN':\n",
    "        param_surf_at_height_sat = interp_DENSITY_to_altitude(df, ZG_df, height_sat)\n",
    "    else:\n",
    "        param_surf_at_height_sat = interp_param_to_altitude(df, ZG_df, height_sat)\n",
    "\n",
    "\n",
    "    xval = lon_sat\n",
    "\n",
    "    x_lon = [grid_vals['lon0'][0], grid_vals['lon1'][0]]\n",
    "    f_den0 = [param_surf_at_height_sat[0], param_surf_at_height_sat[1]]\n",
    "    interp_lon0 =   np.interp(xval, x_lon, f_den0  )\n",
    "\n",
    "    f_den1 = [param_surf_at_height_sat[2], param_surf_at_height_sat[3]]\n",
    "    interp_lon1 =   np.interp(xval, x_lon, f_den1  )\n",
    "\n",
    "    final_interped_value = interp_lon0 + ((lat_sat - grid_vals['lat0'][0]) / (grid_vals['lat1'][0] - grid_vals['lat0'][0]))*(interp_lon1 - interp_lon0)\n",
    "\n",
    "    return(final_interped_value)\n",
    "\n",
    "\n",
    "# def gravity(h):\n",
    "#     \"\"\"For h in same units as R_e  (computes in cm as artifact of old code)\"\"\"\n",
    "#     return g_0*pow(R_e/(R_e + h), 2)\n",
    "\n",
    "\n",
    "\n",
    "# def interp_to_altitude(DEN_df, ZG_df, height_sat):\n",
    "#     density_surf_at_height_sat = np.zeros(np.size(ZG_df.columns))\n",
    "#     i = 0\n",
    "#     for col in ZG_df.columns:\n",
    "#         xp = ZG_df[col][:].values*1e-5\n",
    "#         fp = DEN_df[col][:].values\n",
    "#         xval = height_sat\n",
    "#         density_surf_at_height_sat[i] =  np.exp( np.interp(xval, xp, np.log(fp))  )\n",
    "#         i += 1\n",
    "#     return(density_surf_at_height_sat)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def interp_lon_lat(TIEGCM, lon_sat, lat_sat, time_sat, height_sat, param):\n",
    "#     DEN_df, ZG_df, grid_vals = DEN_and_ZG_vertprofs(TIEGCM, lon_sat, lat_sat, time_sat, param)\n",
    "#     density_surf_at_height_sat = interp_to_altitude(DEN_df, ZG_df, height_sat)\n",
    "\n",
    "#     xval = lon_sat\n",
    "\n",
    "#     x_lon = [grid_vals['lon0'][0], grid_vals['lon1'][0]]\n",
    "#     f_den0 = [density_surf_at_height_sat[0], density_surf_at_height_sat[1]]\n",
    "#     interp_lon0 =   np.interp(xval, x_lon, f_den0  )\n",
    "\n",
    "    \n",
    "#     f_den1 = [density_surf_at_height_sat[2], density_surf_at_height_sat[3]]\n",
    "#     interp_lon1 =   np.interp(xval, x_lon, f_den1  )\n",
    "    \n",
    "#     density = interp_lon0 + ((lat_sat - grid_vals['lat0'][0]) / (grid_vals['lat1'][0] - grid_vals['lat0'][0]))*(interp_lon1 - interp_lon0)\n",
    "# #     print(density)\n",
    "#     return(density)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a530c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T21:58:19.352441Z",
     "start_time": "2021-12-08T21:58:19.338210Z"
    }
   },
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c3e22f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:28:21.656713Z",
     "start_time": "2021-12-10T20:28:21.647998Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# import sys  \n",
    "# import pickle \n",
    "# sys.path.insert(0, '/data/geodyn_proj/pygeodyn/pygeodyn_develop/')\n",
    "# from PYGEODYN import Pygeodyn\n",
    "\n",
    "\n",
    "# Obj_Geodyn = {}\n",
    "# for i,val in enumerate(['msis2','tiegcm_oc']):\n",
    "#     run_settings = '/data/geodyn_proj/validation/NoCD_Arc24_AllDensModels_settings/NoCdArc24_'+val+'.yaml'\n",
    "\n",
    "#     ### Load the data into an object\n",
    "#     Obj_Geodyn[val] = Pygeodyn(run_settings)\n",
    "#     Obj_Geodyn[val].getData()\n",
    "# #     Obj_Geodyn.post_getData_ValidationMetrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e365ca3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:28:21.663360Z",
     "start_time": "2021-12-10T20:28:21.659036Z"
    }
   },
   "outputs": [],
   "source": [
    "arc = '2018.313'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4dc6c9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:28:21.669180Z",
     "start_time": "2021-12-10T20:28:21.664664Z"
    }
   },
   "outputs": [],
   "source": [
    "# Obj_Geodyn['msis2'].__dict__['Density'][arc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd9f093b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:28:21.676037Z",
     "start_time": "2021-12-10T20:28:21.670484Z"
    }
   },
   "outputs": [],
   "source": [
    "# den_df = Obj_Geodyn['tiegcm_oc'].__dict__['Density'][arc]\n",
    "\n",
    "\n",
    "# vals  = np.arange(den_df.index[0],den_df.index[-1]+1)\n",
    "# df = den_df.set_index('Date',drop=False ) \n",
    "# df['i_vals'] = vals\n",
    "# index_date = df.loc[df.index.max()]['i_vals'].min()\n",
    "\n",
    "# den_df = den_df[:index_date-4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83f3e9b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:28:21.682883Z",
     "start_time": "2021-12-10T20:28:21.677447Z"
    }
   },
   "outputs": [],
   "source": [
    "# den_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79ac28ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:28:21.690931Z",
     "start_time": "2021-12-10T20:28:21.685111Z"
    }
   },
   "outputs": [],
   "source": [
    "# den_df['LON'] = (den_df['Lon'] - 180) \n",
    "# den_df['LAT'] = den_df['Lat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ac1fc86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:28:21.695707Z",
     "start_time": "2021-12-10T20:28:21.693488Z"
    }
   },
   "outputs": [],
   "source": [
    "# den_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355f2127",
   "metadata": {},
   "source": [
    "### Load the MSIS2 inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3801f756",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:28:23.067152Z",
     "start_time": "2021-12-10T20:28:21.697023Z"
    }
   },
   "outputs": [],
   "source": [
    "path_msisin = '/data/data_geodyn/results/icesat2/msis2/msis2_acceloff_valid_ctrlrun/DENSITY/icesat2_2018313_24hr.msis2.NoCD_Arc24_msisin'\n",
    "\n",
    "msisinputs = pd.read_csv(path_msisin, \n",
    "                    dtype=object,\n",
    "                    names = ['YYMMDD',\n",
    "                             'HHMMSS',\n",
    "                             'Height_kilometers',\n",
    "                             'Lat',\n",
    "                             'Lon',\n",
    "                                 ],\n",
    "                    sep = '\\s+',\n",
    "                    )\n",
    "\n",
    "sat_time1 = list(msisinputs['YYMMDD'])  #\"031115\" #  \n",
    "sat_time2 = list(msisinputs['HHMMSS'])  #\"120000\" #1068897600        \n",
    "sattime   =    [x+y   for x,y   in zip(sat_time1, sat_time2)]\n",
    "sattime   =    [datetime.strptime(x, '%y%m%d%H%M%S')   for x   in sattime ]\n",
    "sattime   =    [datetime.timestamp(x)   for x   in sattime ]\n",
    "\n",
    "msisinputs['sattime_utctimestamp'] = sattime\n",
    "msisinputs['Lon'] = msisinputs['Lon'].astype(float)\n",
    "msisinputs['Lat'] = msisinputs['Lat'].astype(float)\n",
    "\n",
    "\n",
    "\n",
    "timeHHMMSS = [] \n",
    "for i,val in enumerate(msisinputs['HHMMSS'].values.astype(int)):\n",
    "    # print(len(str(val)))\n",
    "    if len(str(val)) == 1:\n",
    "        timehhmmss_val = '00000'+ str(val)\n",
    "        timeHHMMSS.append(timehhmmss_val)\n",
    "    elif len(str(val)) == 2:\n",
    "        timehhmmss_val = '0000'+ str(val)\n",
    "        timeHHMMSS.append(timehhmmss_val)\n",
    "    elif len(str(val)) == 3:\n",
    "        timehhmmss_val = '000'+ str(val)\n",
    "        timeHHMMSS.append(timehhmmss_val)\n",
    "    elif len(str(val)) == 4:\n",
    "        timehhmmss_val = '00'+ str(val)\n",
    "        timeHHMMSS.append(timehhmmss_val)\n",
    "    elif len(str(val)) == 5:\n",
    "        timehhmmss_val = '0'+ str(val)\n",
    "        timeHHMMSS.append(timehhmmss_val)\n",
    "    else:\n",
    "        timeHHMMSS.append(str(val))\n",
    "msisinputs['timeHHMMSS'] = timeHHMMSS\n",
    "YR = int(18)\n",
    "\n",
    "YYMMDD_list = msisinputs['YYMMDD'].astype(int).astype(str)\n",
    "timeHHMMSS_list = msisinputs['timeHHMMSS'].astype(str)\n",
    "\n",
    "if YR < 10:\n",
    "    year    = ['200' + x[:1]  for x in YYMMDD_list]\n",
    "    month   = [        x[1:3] for x in YYMMDD_list]\n",
    "    day     = [        x[3:]  for x in YYMMDD_list]\n",
    "    hours   = [        x[:2]  for x in timeHHMMSS_list]\n",
    "    minutes = [        x[2:4] for x in timeHHMMSS_list]\n",
    "    secs    = [        x[4:]  for x in timeHHMMSS_list]\n",
    "else:\n",
    "    year    = ['20' + x[:2]  for x in YYMMDD_list]\n",
    "    month   = [       x[2:4] for x in YYMMDD_list]\n",
    "    day     = [       x[4:]  for x in YYMMDD_list]\n",
    "    hours   = [       x[:2]  for x in timeHHMMSS_list]\n",
    "    minutes = [       x[2:4] for x in timeHHMMSS_list]\n",
    "    secs    = [       x[4:]  for x in timeHHMMSS_list]\n",
    "#--------------------------------------------------------\n",
    "msisinputs['year']  = year\n",
    "msisinputs['month'] = month\n",
    "msisinputs['day']   = day\n",
    "msisinputs['hours']  = hours\n",
    "msisinputs['minutes'] = minutes\n",
    "msisinputs['secs']  = secs\n",
    "#--------------------------------------------------------\n",
    "year   = list(map(int, msisinputs['year'].values))\n",
    "month  = list(map(int, msisinputs['month'].values))\n",
    "day    = list(map(int, msisinputs['day'].values))\n",
    "hour   = list(map(int, msisinputs['hours'].values))\n",
    "minute = list(map(int, msisinputs['minutes'].values))\n",
    "second = list(map(int, msisinputs['secs'].values))\n",
    "\n",
    "DATE = list(map(datetime, year,month, day, hour,minute,second ))\n",
    "msisinputs.insert(0, 'Date', DATE)\n",
    "\n",
    "del msisinputs['timeHHMMSS']\n",
    "del msisinputs['year']\n",
    "del msisinputs['month']\n",
    "del msisinputs['day']\n",
    "del msisinputs['hours']\n",
    "del msisinputs['minutes']\n",
    "del msisinputs['secs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09128a9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:28:23.161773Z",
     "start_time": "2021-12-10T20:28:23.069052Z"
    }
   },
   "outputs": [],
   "source": [
    "path_msisingpi = '/data/data_geodyn/results/icesat2/msis2/msis2_acceloff_valid_ctrlrun/DENSITY/icesat2_2018313_24hr.msis2.NoCD_Arc24_msisin_gpiflux'\n",
    "\n",
    "msisinput_gpi = pd.read_csv(path_msisingpi, \n",
    "                names = [\n",
    "                        'YYMMDD',\n",
    "                        'HHMMSS',\n",
    "                        'flux_daily',\n",
    "                        'flux_avg',\n",
    "                        'Ap1',\n",
    "                        'Ap2',\n",
    "                        'Ap3',\n",
    "                        'Ap4',\n",
    "                        'Ap5',\n",
    "                        'Ap6',\n",
    "                        'Ap7',\n",
    "                        'Kp',\n",
    "                      ],\n",
    "                sep = '\\s+',\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4e348b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:28:23.199342Z",
     "start_time": "2021-12-10T20:28:23.163838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>YYMMDD</th>\n",
       "      <th>HHMMSS</th>\n",
       "      <th>Height_kilometers</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>sattime_utctimestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-09 00:01:09</td>\n",
       "      <td>181109</td>\n",
       "      <td>000109</td>\n",
       "      <td>482.623</td>\n",
       "      <td>11.309</td>\n",
       "      <td>-145.122</td>\n",
       "      <td>1.541722e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-09 00:01:19</td>\n",
       "      <td>181109</td>\n",
       "      <td>000119</td>\n",
       "      <td>482.599</td>\n",
       "      <td>11.949</td>\n",
       "      <td>-145.187</td>\n",
       "      <td>1.541722e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-09 00:01:29</td>\n",
       "      <td>181109</td>\n",
       "      <td>000129</td>\n",
       "      <td>482.580</td>\n",
       "      <td>12.589</td>\n",
       "      <td>-145.252</td>\n",
       "      <td>1.541722e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-09 00:01:39</td>\n",
       "      <td>181109</td>\n",
       "      <td>000139</td>\n",
       "      <td>482.564</td>\n",
       "      <td>13.229</td>\n",
       "      <td>-145.317</td>\n",
       "      <td>1.541722e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-09 00:01:49</td>\n",
       "      <td>181109</td>\n",
       "      <td>000149</td>\n",
       "      <td>482.553</td>\n",
       "      <td>13.869</td>\n",
       "      <td>-145.382</td>\n",
       "      <td>1.541722e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>2018-11-09 23:40:49</td>\n",
       "      <td>181109</td>\n",
       "      <td>234049</td>\n",
       "      <td>483.779</td>\n",
       "      <td>31.720</td>\n",
       "      <td>-141.577</td>\n",
       "      <td>1.541807e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>2018-11-09 23:40:59</td>\n",
       "      <td>181109</td>\n",
       "      <td>234059</td>\n",
       "      <td>483.872</td>\n",
       "      <td>32.359</td>\n",
       "      <td>-141.650</td>\n",
       "      <td>1.541807e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>2018-11-09 23:41:09</td>\n",
       "      <td>181109</td>\n",
       "      <td>234109</td>\n",
       "      <td>483.968</td>\n",
       "      <td>32.997</td>\n",
       "      <td>-141.723</td>\n",
       "      <td>1.541807e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59946</th>\n",
       "      <td>2018-11-09 23:41:19</td>\n",
       "      <td>181109</td>\n",
       "      <td>234119</td>\n",
       "      <td>484.067</td>\n",
       "      <td>33.636</td>\n",
       "      <td>-141.796</td>\n",
       "      <td>1.541807e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59947</th>\n",
       "      <td>2018-11-09 23:41:29</td>\n",
       "      <td>181109</td>\n",
       "      <td>234129</td>\n",
       "      <td>484.167</td>\n",
       "      <td>34.274</td>\n",
       "      <td>-141.870</td>\n",
       "      <td>1.541807e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59948 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Date  YYMMDD  HHMMSS Height_kilometers     Lat      Lon  \\\n",
       "0     2018-11-09 00:01:09  181109  000109           482.623  11.309 -145.122   \n",
       "1     2018-11-09 00:01:19  181109  000119           482.599  11.949 -145.187   \n",
       "2     2018-11-09 00:01:29  181109  000129           482.580  12.589 -145.252   \n",
       "3     2018-11-09 00:01:39  181109  000139           482.564  13.229 -145.317   \n",
       "4     2018-11-09 00:01:49  181109  000149           482.553  13.869 -145.382   \n",
       "...                   ...     ...     ...               ...     ...      ...   \n",
       "59943 2018-11-09 23:40:49  181109  234049           483.779  31.720 -141.577   \n",
       "59944 2018-11-09 23:40:59  181109  234059           483.872  32.359 -141.650   \n",
       "59945 2018-11-09 23:41:09  181109  234109           483.968  32.997 -141.723   \n",
       "59946 2018-11-09 23:41:19  181109  234119           484.067  33.636 -141.796   \n",
       "59947 2018-11-09 23:41:29  181109  234129           484.167  34.274 -141.870   \n",
       "\n",
       "       sattime_utctimestamp  \n",
       "0              1.541722e+09  \n",
       "1              1.541722e+09  \n",
       "2              1.541722e+09  \n",
       "3              1.541722e+09  \n",
       "4              1.541722e+09  \n",
       "...                     ...  \n",
       "59943          1.541807e+09  \n",
       "59944          1.541807e+09  \n",
       "59945          1.541807e+09  \n",
       "59946          1.541807e+09  \n",
       "59947          1.541807e+09  \n",
       "\n",
       "[59948 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msisinputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb3922a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:28:23.227261Z",
     "start_time": "2021-12-10T20:28:23.200732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YYMMDD</th>\n",
       "      <th>HHMMSS</th>\n",
       "      <th>flux_daily</th>\n",
       "      <th>flux_avg</th>\n",
       "      <th>Ap1</th>\n",
       "      <th>Ap2</th>\n",
       "      <th>Ap3</th>\n",
       "      <th>Ap4</th>\n",
       "      <th>Ap5</th>\n",
       "      <th>Ap6</th>\n",
       "      <th>Ap7</th>\n",
       "      <th>Kp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>181109</td>\n",
       "      <td>109</td>\n",
       "      <td>70.37</td>\n",
       "      <td>68.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.38</td>\n",
       "      <td>8.25</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181109</td>\n",
       "      <td>119</td>\n",
       "      <td>70.37</td>\n",
       "      <td>68.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.38</td>\n",
       "      <td>8.25</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181109</td>\n",
       "      <td>129</td>\n",
       "      <td>70.37</td>\n",
       "      <td>68.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.38</td>\n",
       "      <td>8.25</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181109</td>\n",
       "      <td>139</td>\n",
       "      <td>70.37</td>\n",
       "      <td>68.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.38</td>\n",
       "      <td>8.25</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181109</td>\n",
       "      <td>149</td>\n",
       "      <td>70.37</td>\n",
       "      <td>68.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.38</td>\n",
       "      <td>8.25</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>181109</td>\n",
       "      <td>234049</td>\n",
       "      <td>70.37</td>\n",
       "      <td>69.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>11.50</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>181109</td>\n",
       "      <td>234059</td>\n",
       "      <td>70.37</td>\n",
       "      <td>69.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>11.50</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>181109</td>\n",
       "      <td>234109</td>\n",
       "      <td>70.37</td>\n",
       "      <td>69.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>11.50</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59946</th>\n",
       "      <td>181109</td>\n",
       "      <td>234119</td>\n",
       "      <td>70.37</td>\n",
       "      <td>69.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>11.50</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59947</th>\n",
       "      <td>181109</td>\n",
       "      <td>234129</td>\n",
       "      <td>70.37</td>\n",
       "      <td>69.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>11.50</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59948 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       YYMMDD  HHMMSS  flux_daily  flux_avg  Ap1   Ap2   Ap3   Ap4  Ap5  \\\n",
       "0      181109     109       70.37     68.91  0.0   5.0   5.0   6.0  4.0   \n",
       "1      181109     119       70.37     68.91  0.0   5.0   5.0   6.0  4.0   \n",
       "2      181109     129       70.37     68.91  0.0   5.0   5.0   6.0  4.0   \n",
       "3      181109     139       70.37     68.91  0.0   5.0   5.0   6.0  4.0   \n",
       "4      181109     149       70.37     68.91  0.0   5.0   5.0   6.0  4.0   \n",
       "...       ...     ...         ...       ...  ...   ...   ...   ...  ...   \n",
       "59943  181109  234049       70.37     69.28  0.0  27.0  22.0  15.0  5.0   \n",
       "59944  181109  234059       70.37     69.28  0.0  27.0  22.0  15.0  5.0   \n",
       "59945  181109  234109       70.37     69.28  0.0  27.0  22.0  15.0  5.0   \n",
       "59946  181109  234119       70.37     69.28  0.0  27.0  22.0  15.0  5.0   \n",
       "59947  181109  234129       70.37     69.28  0.0  27.0  22.0  15.0  5.0   \n",
       "\n",
       "         Ap6    Ap7    Kp  \n",
       "0      11.38   8.25  1.33  \n",
       "1      11.38   8.25  1.33  \n",
       "2      11.38   8.25  1.33  \n",
       "3      11.38   8.25  1.33  \n",
       "4      11.38   8.25  1.33  \n",
       "...      ...    ...   ...  \n",
       "59943   4.50  11.50  4.00  \n",
       "59944   4.50  11.50  4.00  \n",
       "59945   4.50  11.50  4.00  \n",
       "59946   4.50  11.50  4.00  \n",
       "59947   4.50  11.50  4.00  \n",
       "\n",
       "[59948 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msisinput_gpi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843611c8",
   "metadata": {},
   "source": [
    "### Plot comparison wrt Altitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3828cc59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:28:23.236177Z",
     "start_time": "2021-12-10T20:28:23.229056Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# from numpy import array\n",
    "# import sys\n",
    "# # sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "# # from SingleSatelliteFlythrough import SingleModelFlythrough\n",
    "# sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "# from SatelliteFlythrough import ModelFlythrough\n",
    "# from pymsis import msis\n",
    "\n",
    "\n",
    "# variables =['lon','lat' ,'ut','ilev','f107d','f107a','Kp', 'O2', 'O1', 'HE', 'DEN', 'TN', 'Z', 'ZG', 'ZGMID']\n",
    "# tiegcm_file = '/data/data_geodyn/atmos_models_data/tiegcm/2018/Nov2018_ccmcRoR/' +'s%03d.nc' % 25  \n",
    "# tiegcm = read_tiegcm(tiegcm_file, variables)\n",
    "# tiegcm  = tiegcm[0]\n",
    "\n",
    "\n",
    "# rho_tiegcm = []\n",
    "# rho_kamodo = []\n",
    "# rho_msise2 = []\n",
    "\n",
    "# alts_range = np.arange(400,520, 5)\n",
    "\n",
    "\n",
    "# # for i,val in enumerate(msisinputs['HHMMSS'][0:15]) :    \n",
    "# for i,val in enumerate(alts_range) :    \n",
    "\n",
    "#     time =msisinputs['Date'][0]\n",
    "#     lat = float(msisinputs['Lat'][0])\n",
    "#     lon = float(msisinputs['Lon'][0])\n",
    "#     alt = val#float(msisinputs['Height_kilometers'][i])\n",
    "    \n",
    "#     print(f'|——————————————————————————————————————————————————————————————————————————')\n",
    "#     print(f'|  Time: {time}')\n",
    "#     print(f'|  Lat:  {lat}')\n",
    "#     print(f'|  Lon:  {lon}')\n",
    "#     print(f'|  Alt:  {alt}')\n",
    "# #     maxalt = np.max([tiegcm['ZG'][indexut,:-2, indexlat0, indexlon0 ].max(), tiegcm['ZG'][indexut,:-2, indexlat1, indexlon1 ].max()]) \n",
    "# #     print('                        Top boundary TIEGCM file: ',maxalt/100000)\n",
    "#     print(f' ')\n",
    "\n",
    "    \n",
    "#     ##############################################################################\n",
    "#     ##### CALL TIEGCM Manually---------------------------------------------------\n",
    "#     ##############################################################################\n",
    "# #     time_hour = datetime.strptime(sat_time1+sat_time2, '%y%m%d%H%M%S').hour\n",
    "#     den_TIEGCM_sat_alt = interpolate_tiegcm(tiegcm, lon, lat, time.hour, alt*100000, 'DEN')*1e3\n",
    "#     rho_tiegcm.append(den_TIEGCM_sat_alt)\n",
    "\n",
    "#     print('    TIEGCM Manual   : ',den_TIEGCM_sat_alt ,' kg/m^3')  \n",
    "# #     print('----------------------------------------------------------------------')\n",
    "\n",
    "#     ##############################################################################\n",
    "#     ##### CALL KAMODO ------------------------------------------------------------\n",
    "#     ##############################################################################\n",
    "#     #### Kamodo static inputs:\n",
    "#     model          = 'TIEGCM'\n",
    "#     file_dir       = '/data/data_geodyn/atmos_models_data/tiegcm/2018/Nov2018_ccmcRoR/'\n",
    "#     variable_list  = ['rho','psi_O2', 'psi_O',  'psi_He', 'T_n']\n",
    "#     coord_type     = 'SPH'\n",
    "#     coord_grid     = 'sph'\n",
    "#     high_res       = 1.\n",
    "#     verbose        = False  \n",
    "#     csv_output     = ''\n",
    "#     plot_output    = ''        \n",
    "\n",
    "    \n",
    "    \n",
    "#     results = ModelFlythrough(model,\n",
    "#                               file_dir,\n",
    "#                               variable_list,\n",
    "#                               [msisinputs['sattime_utctimestamp'][i]],\n",
    "#                               [lon],\n",
    "#                               [lat],\n",
    "#                               [alt],\n",
    "#                               coord_type,\n",
    "#                               coord_grid,\n",
    "#                               high_res=20.,\n",
    "#                               verbose=False,\n",
    "#                               csv_output='',\n",
    "#                               plot_output='')\n",
    "#     rho_kamodo.append(results['rho'][0]*1e3)\n",
    "# #     print()\n",
    "#     print('    Kamodo w extrap : ',results['rho'][0]*1e3, ' kg/m^3')\n",
    "\n",
    "\n",
    "#     ##############################################################################\n",
    "#     ##### CALL MSIS2 ---------------------------------------------------\n",
    "#     ##############################################################################\n",
    "#     dates = time\n",
    "#     f107 = msisinput_gpi['flux_daily'][i]\n",
    "#     f107a = msisinput_gpi['flux_avg'][i]\n",
    "#     aps = [[msisinput_gpi['Ap1'][i],\n",
    "#             msisinput_gpi['Ap2'][i],\n",
    "#             msisinput_gpi['Ap3'][i],\n",
    "#             msisinput_gpi['Ap4'][i],\n",
    "#             msisinput_gpi['Ap5'][i],\n",
    "#             msisinput_gpi['Ap6'][i],\n",
    "#             msisinput_gpi['Ap7'][i] ]]\n",
    "\n",
    "#     output2 = msis.run(dates, lon, lat, alt, f107, f107a, aps, version = 2)\n",
    "#     print('    MSIS2           : ',output2[0][0][0][0][0] , '          kg/m^3')\n",
    "#     rho_msise2.append(output2[0][0][0][0][0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.offline import plot, iplot\n",
    "# from plotly.subplots import make_subplots\n",
    "# import plotly.express as px\n",
    "# import pandas as pd\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# config = dict({\n",
    "#                 'displayModeBar': True,\n",
    "#                 'responsive': False,\n",
    "#                 'staticPlot': False,\n",
    "#                 'displaylogo': False,\n",
    "#                 'showTips': False,\n",
    "#                 })\n",
    "\n",
    "# # Simplify Plotting Schemes:\n",
    "# col1 = px.colors.qualitative.Plotly[0]\n",
    "# col2 = px.colors.qualitative.Plotly[1]\n",
    "# col3 = px.colors.qualitative.Plotly[2]\n",
    "# col4 = px.colors.qualitative.Plotly[3]\n",
    "# col5 = px.colors.qualitative.Plotly[4]\n",
    "# col6 = px.colors.qualitative.Plotly[5]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fig = make_subplots(\n",
    "#     rows=1, cols=1,\n",
    "#     subplot_titles=(['Compare Model Densities wrt to Altitude (lon, lat, time are constant)']),\n",
    "#     vertical_spacing = 0.15)\n",
    "\n",
    "# fig.add_trace(go.Scattergl(  x=alts_range,\n",
    "#                              y=rho_tiegcm,\n",
    "#                              name= 'manually index tiegcm (no extrapolation done)',\n",
    "#                              mode='markers',\n",
    "#                              opacity=1,\n",
    "#                              marker=dict(\n",
    "# #                                 color=col, \n",
    "# #                                 size=m_size,\n",
    "#                                         ),\n",
    "#                              showlegend=True,\n",
    "#                           ),\n",
    "#                               secondary_y=False,\n",
    "#                                row=1, col=1,\n",
    "#                           )\n",
    "# fig.add_trace(go.Scattergl(  x=alts_range,\n",
    "#                              y=rho_msise2,\n",
    "#                              name= 'msis2',\n",
    "#                              mode='markers',\n",
    "#                              opacity=1,\n",
    "#                              marker=dict(\n",
    "# #                                 color=col, \n",
    "# #                                 size=m_size,\n",
    "#                                         ),\n",
    "#                              showlegend=True,\n",
    "#                           ),\n",
    "#                               secondary_y=False,\n",
    "#                                row=1, col=1,\n",
    "#                           )\n",
    "# fig.add_trace(go.Scattergl(  x=alts_range,\n",
    "#                              y=rho_kamodo,\n",
    "#                              name= 'kamodo (includes extrap)',\n",
    "#                              mode='markers',\n",
    "#                              opacity=1,\n",
    "#                              marker=dict(\n",
    "# #                                 color=col, \n",
    "# #                                 size=m_size,\n",
    "#                                         ),\n",
    "#                              showlegend=True,\n",
    "#                           ),\n",
    "#                               secondary_y=False,\n",
    "#                                row=1, col=1,\n",
    "#                           )\n",
    "# fig.update_yaxes( title=\"rho (kg/m**3)\", type='log', exponentformat= 'power',row=1, col=1)\n",
    "# fig.update_xaxes( title=\"Altitude\", row=1, col=1)\n",
    "\n",
    "# fig.show(config=config)\n",
    "\n",
    "\n",
    "# # fig.write_image(plots_dir+ 'Density_along_orbit.jpg', format='jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af82923",
   "metadata": {},
   "source": [
    "### Plot comparisons thru time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9081a108",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:28:23.244185Z",
     "start_time": "2021-12-10T20:28:23.237913Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# from numpy import array\n",
    "# import sys\n",
    "# # sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "# # from SingleSatelliteFlythrough import SingleModelFlythrough\n",
    "# sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "# from SatelliteFlythrough import ModelFlythrough\n",
    "# from pymsis import msis\n",
    "\n",
    "\n",
    "# variables =['lon','lat' ,'ut','ilev','f107d','f107a','Kp', 'O2', 'O1', 'HE', 'DEN', 'TN', 'Z', 'ZG', 'ZGMID']\n",
    "# tiegcm_file = '/data/data_geodyn/atmos_models_data/tiegcm/2018/Nov2018_ccmcRoR/' +'s%03d.nc' % 25  \n",
    "# tiegcm = read_tiegcm(tiegcm_file, variables)\n",
    "# tiegcm  = tiegcm[0]\n",
    "\n",
    "\n",
    "# rho_tiegcm = []\n",
    "# rho_kamodo = []\n",
    "# rho_msise2 = []\n",
    "\n",
    "# # alts_range = np.arange(400,520, 5)\n",
    "# dates_plot = []\n",
    "\n",
    "# # for i,val in enumerate(msisinputs['HHMMSS'][0:15]) :    \n",
    "# for i,val in enumerate(msisinputs['Date'][:15]) :    \n",
    "\n",
    "#     time =msisinputs['Date'][i]\n",
    "#     lat = float(msisinputs['Lat'][i])\n",
    "#     lon = float(msisinputs['Lon'][i])\n",
    "#     alt = float(msisinputs['Height_kilometers'][i])\n",
    "#     dates_plot.append(time)\n",
    "    \n",
    "    \n",
    "#     print(f'|——————————————————————————————————————————————————————————————————————————')\n",
    "#     print(f'|  Time: {time}')\n",
    "#     print(f'|  Lat:  {lat}')\n",
    "#     print(f'|  Lon:  {lon}')\n",
    "#     print(f'|  Alt:  {alt}')\n",
    "# #     maxalt = np.max([tiegcm['ZG'][indexut,:-2, indexlat0, indexlon0 ].max(), tiegcm['ZG'][indexut,:-2, indexlat1, indexlon1 ].max()]) \n",
    "# #     print('                        Top boundary TIEGCM file: ',maxalt/100000)\n",
    "#     print(f' ')\n",
    "\n",
    "    \n",
    "#     ##############################################################################\n",
    "#     ##### CALL TIEGCM Manually---------------------------------------------------\n",
    "#     ##############################################################################\n",
    "# #     time_hour = datetime.strptime(sat_time1+sat_time2, '%y%m%d%H%M%S').hour\n",
    "#     den_TIEGCM_sat_alt = interpolate_tiegcm(tiegcm, lon, lat, time.hour, alt*100000, 'DEN')*1e3\n",
    "#     rho_tiegcm.append(den_TIEGCM_sat_alt)\n",
    "\n",
    "#     print('    TIEGCM Manual   : ',den_TIEGCM_sat_alt ,' kg/m^3')  \n",
    "# #     print('----------------------------------------------------------------------')\n",
    "\n",
    "#     ##############################################################################\n",
    "#     ##### CALL KAMODO ------------------------------------------------------------\n",
    "#     ##############################################################################\n",
    "#     #### Kamodo static inputs:\n",
    "#     model          = 'TIEGCM'\n",
    "#     file_dir       = '/data/data_geodyn/atmos_models_data/tiegcm/2018/Nov2018_ccmcRoR/'\n",
    "#     variable_list  = ['rho','psi_O2', 'psi_O',  'psi_He', 'T_n']\n",
    "#     coord_type     = 'SPH'\n",
    "#     coord_grid     = 'sph'\n",
    "#     high_res       = 1.\n",
    "#     verbose        = False  \n",
    "#     csv_output     = ''\n",
    "#     plot_output    = ''        \n",
    "\n",
    "    \n",
    "    \n",
    "#     results = ModelFlythrough(model,\n",
    "#                               file_dir,\n",
    "#                               variable_list,\n",
    "#                               [msisinputs['sattime_utctimestamp'][i]],\n",
    "#                               [lon],\n",
    "#                               [lat],\n",
    "#                               [alt],\n",
    "#                               coord_type,\n",
    "#                               coord_grid,\n",
    "#                               high_res=20.,\n",
    "#                               verbose=False,\n",
    "#                               csv_output='',\n",
    "#                               plot_output='')\n",
    "#     rho_kamodo.append(results['rho'][0]*1e3)\n",
    "# #     print()\n",
    "#     print('    Kamodo w extrap : ',results['rho'][0]*1e3, ' kg/m^3')\n",
    "\n",
    "\n",
    "#     ##############################################################################\n",
    "#     ##### CALL MSIS2 ---------------------------------------------------\n",
    "#     ##############################################################################\n",
    "#     dates = time\n",
    "#     f107 = msisinput_gpi['flux_daily'][i]\n",
    "#     f107a = msisinput_gpi['flux_avg'][i]\n",
    "#     aps = [[msisinput_gpi['Ap1'][i],\n",
    "#             msisinput_gpi['Ap2'][i],\n",
    "#             msisinput_gpi['Ap3'][i],\n",
    "#             msisinput_gpi['Ap4'][i],\n",
    "#             msisinput_gpi['Ap5'][i],\n",
    "#             msisinput_gpi['Ap6'][i],\n",
    "#             msisinput_gpi['Ap7'][i] ]]\n",
    "\n",
    "#     output2 = msis.run(dates, lon, lat, alt, f107, f107a, aps, version = 2)\n",
    "#     print('    MSIS2           : ',output2[0][0][0][0][0] , '          kg/m^3')\n",
    "#     rho_msise2.append(output2[0][0][0][0][0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.offline import plot, iplot\n",
    "# from plotly.subplots import make_subplots\n",
    "# import plotly.express as px\n",
    "# import pandas as pd\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# config = dict({\n",
    "#                 'displayModeBar': True,\n",
    "#                 'responsive': False,\n",
    "#                 'staticPlot': False,\n",
    "#                 'displaylogo': False,\n",
    "#                 'showTips': False,\n",
    "#                 })\n",
    "\n",
    "# # Simplify Plotting Schemes:\n",
    "# col1 = px.colors.qualitative.Plotly[0]\n",
    "# col2 = px.colors.qualitative.Plotly[1]\n",
    "# col3 = px.colors.qualitative.Plotly[2]\n",
    "# col4 = px.colors.qualitative.Plotly[3]\n",
    "# col5 = px.colors.qualitative.Plotly[4]\n",
    "# col6 = px.colors.qualitative.Plotly[5]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fig = make_subplots(\n",
    "#     rows=1, cols=1,\n",
    "#     subplot_titles=(['Comparison of Model Densities thru indexed Orbit']),\n",
    "#     vertical_spacing = 0.15)\n",
    "\n",
    "# fig.add_trace(go.Scattergl(  x=dates_plot,\n",
    "#                              y=rho_tiegcm,\n",
    "#                              name= 'tiegcm',\n",
    "#                              mode='markers',\n",
    "#                              opacity=1,\n",
    "#                              marker=dict(\n",
    "# #                                 color=col, \n",
    "# #                                 size=m_size,\n",
    "#                                         ),\n",
    "#                              showlegend=True,\n",
    "#                           ),\n",
    "#                               secondary_y=False,\n",
    "#                                row=1, col=1,\n",
    "#                           )\n",
    "# fig.add_trace(go.Scattergl(  x=dates_plot,\n",
    "#                              y=rho_msise2,\n",
    "#                              name= 'msis2',\n",
    "#                              mode='markers',\n",
    "#                              opacity=1,\n",
    "#                              marker=dict(\n",
    "# #                                 color=col, \n",
    "# #                                 size=m_size,\n",
    "#                                         ),\n",
    "#                              showlegend=True,\n",
    "#                           ),\n",
    "#                               secondary_y=False,\n",
    "#                                row=1, col=1,\n",
    "#                           )\n",
    "# fig.add_trace(go.Scattergl(  x=dates_plot,\n",
    "#                              y=rho_kamodo,\n",
    "#                              name= 'kamodo',\n",
    "#                              mode='markers',\n",
    "#                              opacity=1,\n",
    "#                              marker=dict(\n",
    "# #                                 color=col, \n",
    "# #                                 size=m_size,\n",
    "#                                         ),\n",
    "#                              showlegend=True,\n",
    "#                           ),\n",
    "#                               secondary_y=False,\n",
    "#                                row=1, col=1,\n",
    "#                           )\n",
    "# fig.update_yaxes( title=\"rho (kg/m**3)\", type='log', exponentformat= 'power',row=1, col=1)\n",
    "# fig.update_xaxes( title=\"Dates\", row=1, col=1)\n",
    "\n",
    "# fig.show(config=config)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e50681",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T17:56:24.732542Z",
     "start_time": "2021-12-10T17:56:24.701173Z"
    }
   },
   "source": [
    "### NOTE ON THE ABOVE PLOT, It is the manual index of TIEGCM does not include a top boundary extrapolation so its higher density is a result of this.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08006fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18782278",
   "metadata": {},
   "source": [
    "# Final test, run through as Orbit Cloud file outside of GEODYN and without the cube cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6caeaaaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:28:23.249320Z",
     "start_time": "2021-12-10T20:28:23.245965Z"
    }
   },
   "outputs": [],
   "source": [
    "### some external prep\n",
    "\n",
    "DEN_csv= msisinputs\n",
    "# DEN_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7463b5a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:28:25.320288Z",
     "start_time": "2021-12-10T20:28:23.250934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Date: 2018-11-09 23:41:29\n",
      "Running thru Kamodo\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Run Time: 0.636052131652832 seconds\n",
      "Run Time: 0.010600868860880535 minutes\n",
      "Run Time: 0.00017668114768134224 hours\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "from SatelliteFlythrough import ModelFlythrough\n",
    "from pymsis import msis\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "date_list = []\n",
    "unixtimes_list = []\n",
    "lons_list = []\n",
    "lats_list = []\n",
    "alts_list = []\n",
    "\n",
    "count=0\n",
    "rho_msise2 = []\n",
    "\n",
    "#### Open the file\n",
    "#### We will loop thru the DEN CSV and if the file already contains the the date, don't overwrite.\n",
    "### NOTE: The below will search thru the file to see if the date is already in there but it does \n",
    "####      not account for the fact that the data must be written in blocks of 9 points of the cube.  \n",
    "#####     This is a limitation and should be addressed eventually\n",
    "\n",
    "delta_deg = 2    # degrees\n",
    "delta_m = 1000.*1e-3 # meters to kilometers\n",
    "\n",
    "vals  = np.arange(DEN_csv.index[0],DEN_csv.index[-1]+1)\n",
    "df = DEN_csv.set_index('Date',drop=False ) \n",
    "df['i_vals'] = vals\n",
    "index_date = df.loc[df.index.max()]['i_vals'].min()\n",
    "\n",
    "print('Last Date:', DEN_csv['Date'][index_date])\n",
    "for it,val in enumerate(DEN_csv['Date'][:index_date]):\n",
    "#     print(val)\n",
    "\n",
    "    \n",
    "    date_index = DEN_csv['YYMMDD'][it] + DEN_csv['HHMMSS'][it]\n",
    "    unix_time  = DEN_csv['sattime_utctimestamp'][it]\n",
    "\n",
    "    count+=1\n",
    "\n",
    "    ### Get the coordinates along the orbit:\n",
    "    lon = float(DEN_csv['Lon'][it])\n",
    "    lat = float(DEN_csv['Lat'][it])\n",
    "    alt = float(DEN_csv['Height_kilometers'][it])\n",
    "    center_coord = [lon, lat, alt]\n",
    "\n",
    "    lon_plus_delta = lon + delta_deg\n",
    "    lon_mins_delta = lon - delta_deg\n",
    "    lat_plus_delta = lat + delta_deg\n",
    "    lat_mins_delta = lat - delta_deg\n",
    "\n",
    "    ### WRAP THE LONS AROUND -180 to 180\n",
    "    if lon_plus_delta < -180:\n",
    "        lon_plus_delta = np.mod(lon_plus_delta, 180)\n",
    "    elif lon_plus_delta > 180:\n",
    "        lon_plus_delta = np.mod(lon_plus_delta, -180)\n",
    "    else:        \n",
    "        lon_plus_delta = lon_plus_delta\n",
    "\n",
    "    if lon_mins_delta < -180:\n",
    "        lon_mins_delta = np.mod(lon_mins_delta, 180)\n",
    "    elif lon_mins_delta > 180:\n",
    "        lon_mins_delta = np.mod(lon_mins_delta, -180)\n",
    "    else:\n",
    "        lon_mins_delta = lon_mins_delta\n",
    "      \n",
    "        \n",
    "    if lat_plus_delta < -90:\n",
    "        lat_plus_delta = np.mod(lat_plus_delta, 90)\n",
    "    elif lat_plus_delta > 90:\n",
    "        lat_plus_delta = np.mod(lat_plus_delta, -90)\n",
    "    else:\n",
    "        lat_plus_delta = lat_plus_delta\n",
    "\n",
    "    if lat_mins_delta < -90:\n",
    "        lat_mins_delta = np.mod(lat_mins_delta, 90)\n",
    "    elif lat_mins_delta > 90:\n",
    "        lat_mins_delta = np.mod(lat_mins_delta, -90)\n",
    "    else:\n",
    "        lat_mins_delta = lat_mins_delta\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    ### Find the coordinates of the cube surround the orbit point:\n",
    "    A = [lon_plus_delta, lat_plus_delta, alt+delta_m]  # top,    front, left\n",
    "    B = [lon_plus_delta, lat_mins_delta, alt+delta_m]  # top,    back,  Left\n",
    "    C = [lon_mins_delta, lat_plus_delta, alt+delta_m]  # top,    front, right\n",
    "    D = [lon_mins_delta, lat_mins_delta, alt+delta_m]  # top,    back,  right\n",
    "    E = [lon_plus_delta, lat_plus_delta, alt-delta_m]  # bottom, front, left\n",
    "    F = [lon_plus_delta, lat_mins_delta, alt-delta_m]  # bottom, back,  left\n",
    "    G = [lon_mins_delta, lat_plus_delta, alt-delta_m]  # bottom, front, right\n",
    "    H = [lon_mins_delta, lat_mins_delta, alt-delta_m]  # bottom, back,  right\n",
    "\n",
    "\n",
    "    ### Store the cube's coordinates in the dictionary index\n",
    "    cube_corners_and_center = []\n",
    "    cube_corners_and_center.append(center_coord)\n",
    "    cube_corners_and_center.append(A)\n",
    "    cube_corners_and_center.append(B)\n",
    "    cube_corners_and_center.append(C)\n",
    "    cube_corners_and_center.append(D)\n",
    "    cube_corners_and_center.append(E)\n",
    "    cube_corners_and_center.append(F)\n",
    "    cube_corners_and_center.append(G)\n",
    "    cube_corners_and_center.append(H)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #### Extract the coordinates from each list to plug into Kamodo with vectorization\n",
    "    lons_in = [item[0] for item in cube_corners_and_center]\n",
    "    lats_in = [item[1] for item in cube_corners_and_center]\n",
    "    alts_in = [item[2] for item in cube_corners_and_center]\n",
    "\n",
    "    ## Gather inputs for Kamodo\n",
    "    sat_time       = unix_time*np.ones(np.size(alts_in))\n",
    "    dates          = [date_index]*np.size(alts_in)\n",
    "    c1             = lons_in\n",
    "    c2             = lats_in\n",
    "    c3             = alts_in\n",
    "\n",
    "\n",
    "    unixtimes_list.extend(sat_time)\n",
    "    date_list.extend(dates)\n",
    "    lons_list.extend(c1)\n",
    "    lats_list.extend(c2)\n",
    "    alts_list.extend(c3)\n",
    "\n",
    "    \n",
    "#     dates = DEN_csv['Date'][it]\n",
    "#     f107 = msisinput_gpi['flux_daily'][it]\n",
    "#     f107a = msisinput_gpi['flux_avg'][it]\n",
    "#     aps = [[msisinput_gpi['Ap1'][it],\n",
    "#             msisinput_gpi['Ap2'][it],\n",
    "#             msisinput_gpi['Ap3'][it],\n",
    "#             msisinput_gpi['Ap4'][it],\n",
    "#             msisinput_gpi['Ap5'][it],\n",
    "#             msisinput_gpi['Ap6'][it],\n",
    "#             msisinput_gpi['Ap7'][it] ]]\n",
    "#     output2 = msis.run(dates, lon, lat, alt, f107, f107a, aps, version = 2)\n",
    "# #     print('    MSIS2           : ',output2[0][0][0][0][0] , '          kg/m^3')\n",
    "#     rho_msise2.append(output2[0][0][0][0][0])\n",
    "    \n",
    "\n",
    "    \n",
    "#### Import Coordinates to Kamodo\n",
    "##\n",
    "#### Kamodo static inputs:\n",
    "model          = 'TIEGCM'\n",
    "file_dir       =  '/data/data_geodyn/atmos_models_data/tiegcm/2018/Nov2018_ccmcRoR/'\n",
    "variable_list  = ['rho','psi_O2', 'psi_O',  'psi_He', 'T_n']\n",
    "coord_type     = 'SPH'\n",
    "coord_grid     = 'sph'\n",
    "high_res       = 1.\n",
    "verbose        = False  \n",
    "csv_output     = '' \n",
    "plot_output    = ''        \n",
    "\n",
    "\n",
    "print('Running thru Kamodo')\n",
    "# results = ModelFlythrough(model, file_dir, variable_list, unixtimes_list, lons_list, lats_list, alts_list,\n",
    "#                           coord_type, coord_grid, high_res=20., verbose=False,csv_output='', plot_output='')\n",
    "\n",
    "\n",
    "#         print(results)\n",
    "# with open(self.orbitcloud_csv_file, 'r+') as file:\n",
    "#     for ii, valrho in enumerate(results['rho']):\n",
    "#         file.write(f\"{datetime.strftime(datetime.fromtimestamp(results['utc_time'][ii]), '%y%m%d%H%M%S')}   {results['c1'][ii]:8.4f}   {results['c2'][ii]:8.4f}   {results['c3'][ii]:8.4f}   {valrho:15.8e} \\n\")\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "print('Run Time:', elapsed,         'seconds' )\n",
    "print('Run Time:', elapsed/60,    'minutes' )\n",
    "print('Run Time:', elapsed/60/60, 'hours'   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0f36e00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T21:36:22.368283Z",
     "start_time": "2021-12-10T21:36:22.363159Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i,val in enumerate(lons_list):\n",
    "#     print(f'|  Time: {date_list[i]},  Lon:  {lons_list[i]},  Lat:  {lats_list[i]},  Alt:  {alts_list[i]}')\n",
    "\n",
    "# # A = pd.DataFrame.from_dict(results)\n",
    "\n",
    "# # A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b90383b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:28:34.816034Z",
     "start_time": "2021-12-10T20:28:34.813054Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.offline import plot, iplot\n",
    "# from plotly.subplots import make_subplots\n",
    "# import plotly.express as px\n",
    "# import pandas as pd\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# config = dict({\n",
    "#                 'displayModeBar': True,\n",
    "#                 'responsive': False,\n",
    "#                 'staticPlot': False,\n",
    "#                 'displaylogo': False,\n",
    "#                 'showTips': False,\n",
    "#                 })\n",
    "\n",
    "# # Simplify Plotting Schemes:\n",
    "# col1 = px.colors.qualitative.Plotly[0]\n",
    "# col2 = px.colors.qualitative.Plotly[1]\n",
    "# col3 = px.colors.qualitative.Plotly[2]\n",
    "# col4 = px.colors.qualitative.Plotly[3]\n",
    "# col5 = px.colors.qualitative.Plotly[4]\n",
    "# col6 = px.colors.qualitative.Plotly[5]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fig = make_subplots(\n",
    "#     rows=1, cols=1,\n",
    "#     subplot_titles=(['Comparison of Model Densities']),\n",
    "#     vertical_spacing = 0.15)\n",
    "# fig.add_trace(go.Scattergl(  x=DEN_csv['Date'],\n",
    "#                              y=rho_msise2,\n",
    "#                              name= 'MSIS2',\n",
    "#                              mode='markers',\n",
    "#                              opacity=1,\n",
    "#                              marker=dict(\n",
    "# #                                 color=col, \n",
    "# #                                 size=m_size,\n",
    "#                                         ),\n",
    "#                              showlegend=True,\n",
    "#                           ),\n",
    "#                               secondary_y=False,\n",
    "#                                row=1, col=1,\n",
    "#                           )\n",
    "\n",
    "# fig.add_trace(go.Scattergl(  x=DEN_csv['Date'],\n",
    "#                              y=results['rho']*1e3,\n",
    "#                              name= 'Kamodo-TIEGCM',\n",
    "#                              mode='markers',\n",
    "#                              opacity=1,\n",
    "#                              marker=dict(\n",
    "# #                                 color=col, \n",
    "# #                                 size=m_size,\n",
    "#                                         ),\n",
    "#                              showlegend=True,\n",
    "#                           ),\n",
    "#                               secondary_y=False,\n",
    "#                                row=1, col=1,\n",
    "#                           )\n",
    "\n",
    "# fig.update_yaxes( title=\"rho (kg/m**3)\", type='log', exponentformat= 'power',row=1, col=1)\n",
    "# fig.update_xaxes( title=\"Dates\", row=1, col=1)\n",
    "\n",
    "# fig.show(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28045726",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T19:20:35.868173Z",
     "start_time": "2021-12-10T19:20:35.835645Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc1dc744",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:28:34.825228Z",
     "start_time": "2021-12-10T20:28:34.817346Z"
    }
   },
   "outputs": [],
   "source": [
    "# def orb_avg(den_df, arc):\n",
    "    \n",
    "    \n",
    "#     #### Find the index for the correct date\n",
    "#     vals  = np.arange(den_df[arc].index[0],den_df[arc].index[-1]+1)\n",
    "#     df = den_df[arc].set_index('Date',drop=False ) \n",
    "#     df['i_vals'] = vals\n",
    "#     index_date = df.loc[df.index.max()]['i_vals'].min()\n",
    "    \n",
    "# #     print('index_date', index_date)\n",
    "#     lat = np.asarray(den_df[arc]['Lat'][:index_date])\n",
    "#     time_pd = pd.to_datetime(den_df[arc]['Date'][:index_date])\n",
    "#     i = np.nonzero( lat[1:]*lat[0:-1]  <  np.logical_and(0 , lat[1:] > lat[0:-1] )  )\n",
    "#     i = i[0]\n",
    "\n",
    "#     d_avg = np.zeros(np.size(i))\n",
    "#     height_avg = np.zeros(np.size(i))\n",
    "    \n",
    "# #     print('time_pd',time_pd)\n",
    "\n",
    "#     time_avg = []\n",
    "#     d_avg_rolling = []\n",
    "    \n",
    "#     roll_avg_count = 0\n",
    "#     for j in range(np.size(i)-1):\n",
    "#         d_avg[j]      = np.mean(den_df[arc]['rho (kg/m**3)'  ][i[j] : i[j+1]-1  ]  )\n",
    "#         height_avg[j] = np.mean(den_df[arc]['Height (meters)'][i[j] : i[j+1]-1  ]  )\n",
    "# #         mean_time      = np.mean(time_pd[   i[j] : i[j+1]-1  ])\n",
    "#         t1 = pd.to_datetime(time_pd[ i[j]    ])\n",
    "#         t2 = pd.to_datetime(time_pd[ i[j+1]-1])\n",
    "#         datemiddle = pd.Timestamp(t1) + (pd.Timestamp(t2) - pd.Timestamp(t1)) / 2\n",
    "\n",
    "#         time_avg.append(datemiddle)\n",
    "\n",
    "#         if roll_avg_count ==1:\n",
    "#             d_avg_rolling.append(np.mean([ d_avg[j],  d_avg[j-1]]))\n",
    "#             roll_avg_count =0\n",
    "            \n",
    "#         roll_avg_count+=1 \n",
    "#     d_avg_rolling.append(np.mean([ d_avg[j],  d_avg[j-1]]))\n",
    "        \n",
    "#     return(time_avg, d_avg, d_avg_rolling )\n",
    "    \n",
    "\n",
    "\n",
    "# vals  = np.arange(obj_m1.__dict__['Density'][arc].index[0],obj_m1.__dict__['Density'][arc].index[-1]+1)\n",
    "# df = obj_m1.__dict__['Density'][arc].set_index('Date',drop=False ) \n",
    "# df['i_vals'] = vals\n",
    "# index_date = df.loc[df.index.max()]['i_vals'].min()\n",
    "\n",
    "\n",
    "# time_avg,d_avg, d_avg_rolling = orb_avg(obj_m1.Density, arc)\n",
    "\n",
    "\n",
    "# fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                          y=d_avg_rolling,\n",
    "# #                                  y=d_avg,\n",
    "# #                                 name= ' Arc ' +str(i_arc) ,\n",
    "#                          mode='markers',\n",
    "#                          marker=dict(\n",
    "#                          color=col,\n",
    "#                          size=4,),\n",
    "#                          showlegend=False,\n",
    "#                            ),\n",
    "#                            row=1, col=1,\n",
    "#                            )\n",
    "\n",
    "\n",
    "# fig.update_yaxes(type=\"log\", exponentformat= 'power',row=1, col=1)\n",
    "# fig.update_xaxes(title_text=\"Date\", row=1, col=1)\n",
    "# fig.update_yaxes(title_text=\"kg/m^3\", row=1, col=1)\n",
    "# fig.update_layout(legend= {'itemsizing': 'constant'})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "efc48e39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T21:47:28.549501Z",
     "start_time": "2021-12-10T21:47:28.544204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -175     -178        176\n"
     ]
    }
   ],
   "source": [
    "# lon0     = -175\n",
    "# loncheck =  -178\n",
    "# lon1     =  176\n",
    "\n",
    "# if lon0 < 0:\n",
    "#     lon0= np.mod(lon0+360,360)\n",
    "# if lon1 < 0:\n",
    "#     lon1= np.mod(lon1+360,360)\n",
    "# if loncheck < 0:\n",
    "#     loncheck= np.mod(loncheck+360,360)\n",
    "\n",
    "\n",
    "print(f\" {lon0}     {loncheck}        {lon1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140d54a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(lon0-loncheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1795e847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
