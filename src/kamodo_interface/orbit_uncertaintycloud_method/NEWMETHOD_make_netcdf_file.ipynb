{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d384d4ae",
   "metadata": {},
   "source": [
    "# Developing New method for Using Kamodo with GEODYN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699b036a",
   "metadata": {},
   "source": [
    "*This new method should run the orbits of GEODYN through Kamodo in a faster way that doesn't sacrifice accuracy of the interpolation in Kamodo and doesn't require a trimming of other Kamodo functionality to accomodate large overhead.*\n",
    "\n",
    "1. Pre-run initialization of the orbit.\n",
    "   - \"initialize\" a run of GEODYN with MSIS2 that gives us a \"best guess\" for the orbit of the satellite.\n",
    "2. Construct box of estimated orbits with variation\n",
    "   - Before running GEODYN with TIEGCM, we will take the \"best guess\" orbit and perturbate the input coordinates outward for each timestep that GEODYN asks for.  This will construct a box of best guesses around our satellite that can then be plugged into Kamodo.  \n",
    "   - From here we just have a meshed index of possible density values from Kamodo for each timepoint and within some standard deviation of possible values along the orbit of the s/c.\n",
    "3. Get density in GEODYN\n",
    "   - now instead of calling the Kamodo model at each time step which has tons of overhead, we can call a relatively simple interpolation scheme in fortran at each timestep that will return the density value.  The orbit grid will be saved in a file that will be indexed by time according to what the MSIS model returned.\n",
    "   - We will need to build in functionality such that if GEODYN requests a value outside of the box we requested, then it stops the program and restarts the process with a slightly larger grid around the orbit.\n",
    "   \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f60648",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Function for trilinear interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ddce7a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:46.056759Z",
     "start_time": "2021-08-31T16:33:46.046491Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def interpolate_point_in_cube(lon, lat, alt, uncertain_grid, timestep, delta_deg, delta_m):\n",
    "    '''\n",
    "    This function performs a manual calculation for trilinear interoplation.\n",
    "    Interpolates values on a cube to a desired coordinate.  \n",
    "    Currently, it is set up for Lon, Lat, Alt.\n",
    "    '''    \n",
    "    x  = lon\n",
    "    x0 = x - delta_deg\n",
    "    x1 = x + delta_deg\n",
    "\n",
    "    y  = lat\n",
    "    y0 = y - delta_deg\n",
    "    y1 = y + delta_deg\n",
    "\n",
    "    z  = alt\n",
    "    z0 = z - delta_m\n",
    "    z1 = z + delta_m\n",
    "\n",
    "    C000 = np.array(uncertain_grid[timestep]['values'][5])  # bottom, front, left\n",
    "    C100 = np.array(uncertain_grid[timestep]['values'][7])  # bottom, front, right\n",
    "    C001 = np.array(uncertain_grid[timestep]['values'][1])  # top,    front, left\n",
    "    C101 = np.array(uncertain_grid[timestep]['values'][3])  # top,    front, right\n",
    "    C010 = np.array(uncertain_grid[timestep]['values'][6])  # bottom, back,  left\n",
    "    C110 = np.array(uncertain_grid[timestep]['values'][8])  # bottom, back,  right\n",
    "    C011 = np.array(uncertain_grid[timestep]['values'][2])  # top,    back,  Left\n",
    "    C111 = np.array(uncertain_grid[timestep]['values'][4])  # top,    back,  right\n",
    "\n",
    "\n",
    "    ##===================================================================\n",
    "    ##        Manually INTERPOLATE-- Trilinear Interpolation Calculation\n",
    "    ##===================================================================\n",
    "\n",
    "    ### On a periodic and cubic lattice, let xd, yd, zd be the differences \n",
    "    ### between each of x, y, z and the smaller coordinate related.\n",
    "    #\n",
    "    ###  x0 indicates the lattice point below x \n",
    "    ###  x1 indicates the lattice point above x\n",
    "    xd =  (x-x0)/(x1-x0)\n",
    "    yd =  (y-y0)/(y1-y0)\n",
    "    zd =  (z-z0)/(z1-z0)\n",
    "    # print(xd,yd,zd)\n",
    "\n",
    "    ##### First we interpolate along x:   (push one of the X faces of cube towards the opposing face)\n",
    "    ###   C000 uis the function value (x0, y0, z0)\n",
    "    C00 = C000*(1-xd) + (C100*xd)\n",
    "    C01 = C001*(1-xd) + (C101*xd)\n",
    "    C10 = C010*(1-xd) + (C110*xd)\n",
    "    C11 = C011*(1-xd) + (C111*xd)\n",
    "\n",
    "    #### Next we interpolate along y:  (pushing the values that are now in middle of cube towards the center Y)\n",
    "    C0 = C00*(1-yd) + C10*yd\n",
    "    C1 = C01*(1-yd) + C11*yd\n",
    "\n",
    "    #### Finally we interpolate along Z   (walk through the line that remains)\n",
    "    C = C0*(1-zd) + C1*zd\n",
    "    \n",
    "    return(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde2d14",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Do a Pre-run with MSIS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afb8bee2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:46.066958Z",
     "start_time": "2021-08-31T16:33:46.058763Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# import copy\n",
    "# import time\n",
    "# import sys  \n",
    "\n",
    "\n",
    "# sys.path.insert(0, '/data/geodyn_proj/pygeodyn/pygeodyn_develop/')\n",
    "# from PYGEODYN import Pygeodyn\n",
    "\n",
    "\n",
    "# ### Identify which arcs you want to run:\n",
    "# arcs_files = [ \n",
    "#             '031109',  # 2\n",
    "#              ]\n",
    "\n",
    "# #------ A dictionary containing the run parameters ------  \n",
    "# run_params = {} \n",
    "# run_params['arc']              =   arcs_files\n",
    "# run_params['satellite']        =  'starlette'  \n",
    "# run_params['den_model']        =  'msis2'  \n",
    "# run_params['SpecialRun_name']  =  'SLR_kamodo_interface'  \n",
    "# run_params['verbose']          =  False\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# import pickle \n",
    "# sys.path.insert(0, '/data/geodyn_proj/pygeodyn/pygeodyn_develop/')\n",
    "# from PYGEODYN import Pygeodyn\n",
    "\n",
    "# for imodel,val_model in enumerate( ['msis2']):\n",
    "#     run_params1 = copy.deepcopy(run_params)\n",
    "#     run_params1['den_model']  =  val_model  \n",
    "#     run_params1['action']           =  'run'\n",
    "\n",
    "#     ### Load the data into an object\n",
    "#     Obj_Geodyn = Pygeodyn(run_params1)\n",
    "#     Obj_Geodyn.RUN_GEODYN()\n",
    "#     del Obj_Geodyn\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6f4120",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Read Density Values from Pre-Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20965ea3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:46.476739Z",
     "start_time": "2021-08-31T16:33:46.069142Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bunzip2: Can't open input file /data/data_geodyn/results/st/msis2/msis2_acceloffSLR_kamodo_interface/DENSITY/st031109_2wk.goco05s.bz2: No such file or directory.\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#### Need to bunzip the file we want to play with.\n",
    "\n",
    "!bunzip2 /data/data_geodyn/results/st/msis2/msis2_acceloffSLR_kamodo_interface/DENSITY/st031109_2wk.goco05s.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c50627",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:47.378825Z",
     "start_time": "2021-08-31T16:33:46.480244Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-8b7adbf804b3>:51: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  val_float = np.float(list_val)\n",
      "<ipython-input-4-8b7adbf804b3>:52: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  val_float2 = np.float(list_val2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Elapsed Secs</th>\n",
       "      <th>YYMMDD</th>\n",
       "      <th>HHMMSS</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Height (meters)</th>\n",
       "      <th>rho (kg/m**3)</th>\n",
       "      <th>drhodz (kg/m**3/m)</th>\n",
       "      <th>flux_daily</th>\n",
       "      <th>flux_avg</th>\n",
       "      <th>Kp</th>\n",
       "      <th>sattime_utctimestamp</th>\n",
       "      <th>Height_kilometers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-11-09 00:07:04</td>\n",
       "      <td>360.0</td>\n",
       "      <td>031109</td>\n",
       "      <td>000704</td>\n",
       "      <td>-25.1728</td>\n",
       "      <td>217.8688</td>\n",
       "      <td>1113435.865</td>\n",
       "      <td>1.914916e-15</td>\n",
       "      <td>-7.201987e-21</td>\n",
       "      <td>91.47</td>\n",
       "      <td>133.12</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1.068336e+09</td>\n",
       "      <td>1113.435865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-11-09 00:08:04</td>\n",
       "      <td>420.0</td>\n",
       "      <td>031109</td>\n",
       "      <td>000804</td>\n",
       "      <td>-22.8145</td>\n",
       "      <td>220.1761</td>\n",
       "      <td>1113033.012</td>\n",
       "      <td>1.965050e-15</td>\n",
       "      <td>-7.402988e-21</td>\n",
       "      <td>91.48</td>\n",
       "      <td>133.12</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1.068336e+09</td>\n",
       "      <td>1113.033012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-11-09 00:09:04</td>\n",
       "      <td>480.0</td>\n",
       "      <td>031109</td>\n",
       "      <td>000904</td>\n",
       "      <td>-20.4158</td>\n",
       "      <td>222.3964</td>\n",
       "      <td>1112128.477</td>\n",
       "      <td>2.018587e-15</td>\n",
       "      <td>-7.624048e-21</td>\n",
       "      <td>91.48</td>\n",
       "      <td>133.12</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1.068337e+09</td>\n",
       "      <td>1112.128477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-11-09 00:10:04</td>\n",
       "      <td>540.0</td>\n",
       "      <td>031109</td>\n",
       "      <td>001004</td>\n",
       "      <td>-17.9820</td>\n",
       "      <td>224.5414</td>\n",
       "      <td>1110730.463</td>\n",
       "      <td>2.074163e-15</td>\n",
       "      <td>-7.859084e-21</td>\n",
       "      <td>91.48</td>\n",
       "      <td>133.12</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1.068337e+09</td>\n",
       "      <td>1110.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-11-09 00:11:04</td>\n",
       "      <td>600.0</td>\n",
       "      <td>031109</td>\n",
       "      <td>001104</td>\n",
       "      <td>-15.5180</td>\n",
       "      <td>226.6222</td>\n",
       "      <td>1108848.344</td>\n",
       "      <td>2.130286e-15</td>\n",
       "      <td>-8.101387e-21</td>\n",
       "      <td>91.48</td>\n",
       "      <td>133.12</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1.068337e+09</td>\n",
       "      <td>1108.848344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20145</th>\n",
       "      <td>2003-11-09 00:05:04</td>\n",
       "      <td>240.0</td>\n",
       "      <td>031109</td>\n",
       "      <td>000504</td>\n",
       "      <td>-29.7438</td>\n",
       "      <td>212.9431</td>\n",
       "      <td>1112710.164</td>\n",
       "      <td>1.828878e-15</td>\n",
       "      <td>-6.878285e-21</td>\n",
       "      <td>91.47</td>\n",
       "      <td>133.12</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1.068336e+09</td>\n",
       "      <td>1112.710164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20146</th>\n",
       "      <td>2003-11-09 00:05:04</td>\n",
       "      <td>240.0</td>\n",
       "      <td>031109</td>\n",
       "      <td>000504</td>\n",
       "      <td>-29.7438</td>\n",
       "      <td>212.9431</td>\n",
       "      <td>1112710.164</td>\n",
       "      <td>1.828878e-15</td>\n",
       "      <td>-6.878285e-21</td>\n",
       "      <td>91.47</td>\n",
       "      <td>133.12</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1.068336e+09</td>\n",
       "      <td>1112.710164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20147</th>\n",
       "      <td>2003-11-09 00:05:04</td>\n",
       "      <td>240.0</td>\n",
       "      <td>031109</td>\n",
       "      <td>000504</td>\n",
       "      <td>-29.7438</td>\n",
       "      <td>212.9431</td>\n",
       "      <td>1112710.164</td>\n",
       "      <td>1.828878e-15</td>\n",
       "      <td>-6.878285e-21</td>\n",
       "      <td>91.47</td>\n",
       "      <td>133.12</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1.068336e+09</td>\n",
       "      <td>1112.710164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20148</th>\n",
       "      <td>2003-11-09 00:05:04</td>\n",
       "      <td>240.0</td>\n",
       "      <td>031109</td>\n",
       "      <td>000504</td>\n",
       "      <td>-29.7438</td>\n",
       "      <td>212.9431</td>\n",
       "      <td>1112710.164</td>\n",
       "      <td>1.828878e-15</td>\n",
       "      <td>-6.878285e-21</td>\n",
       "      <td>91.47</td>\n",
       "      <td>133.12</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1.068336e+09</td>\n",
       "      <td>1112.710164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20149</th>\n",
       "      <td>2003-11-09 00:06:04</td>\n",
       "      <td>300.0</td>\n",
       "      <td>031109</td>\n",
       "      <td>000604</td>\n",
       "      <td>-27.4848</td>\n",
       "      <td>215.4622</td>\n",
       "      <td>1113330.105</td>\n",
       "      <td>1.869236e-15</td>\n",
       "      <td>-7.025773e-21</td>\n",
       "      <td>91.47</td>\n",
       "      <td>133.12</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1.068336e+09</td>\n",
       "      <td>1113.330105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20150 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Date Elapsed Secs  YYMMDD  HHMMSS      Lat       Lon  \\\n",
       "0     2003-11-09 00:07:04        360.0  031109  000704 -25.1728  217.8688   \n",
       "1     2003-11-09 00:08:04        420.0  031109  000804 -22.8145  220.1761   \n",
       "2     2003-11-09 00:09:04        480.0  031109  000904 -20.4158  222.3964   \n",
       "3     2003-11-09 00:10:04        540.0  031109  001004 -17.9820  224.5414   \n",
       "4     2003-11-09 00:11:04        600.0  031109  001104 -15.5180  226.6222   \n",
       "...                   ...          ...     ...     ...      ...       ...   \n",
       "20145 2003-11-09 00:05:04        240.0  031109  000504 -29.7438  212.9431   \n",
       "20146 2003-11-09 00:05:04        240.0  031109  000504 -29.7438  212.9431   \n",
       "20147 2003-11-09 00:05:04        240.0  031109  000504 -29.7438  212.9431   \n",
       "20148 2003-11-09 00:05:04        240.0  031109  000504 -29.7438  212.9431   \n",
       "20149 2003-11-09 00:06:04        300.0  031109  000604 -27.4848  215.4622   \n",
       "\n",
       "      Height (meters)  rho (kg/m**3)  drhodz (kg/m**3/m) flux_daily flux_avg  \\\n",
       "0         1113435.865   1.914916e-15       -7.201987e-21      91.47   133.12   \n",
       "1         1113033.012   1.965050e-15       -7.402988e-21      91.48   133.12   \n",
       "2         1112128.477   2.018587e-15       -7.624048e-21      91.48   133.12   \n",
       "3         1110730.463   2.074163e-15       -7.859084e-21      91.48   133.12   \n",
       "4         1108848.344   2.130286e-15       -8.101387e-21      91.48   133.12   \n",
       "...               ...            ...                 ...        ...      ...   \n",
       "20145     1112710.164   1.828878e-15       -6.878285e-21      91.47   133.12   \n",
       "20146     1112710.164   1.828878e-15       -6.878285e-21      91.47   133.12   \n",
       "20147     1112710.164   1.828878e-15       -6.878285e-21      91.47   133.12   \n",
       "20148     1112710.164   1.828878e-15       -6.878285e-21      91.47   133.12   \n",
       "20149     1113330.105   1.869236e-15       -7.025773e-21      91.47   133.12   \n",
       "\n",
       "         Kp  sattime_utctimestamp  Height_kilometers  \n",
       "0      4.67          1.068336e+09        1113.435865  \n",
       "1      4.67          1.068336e+09        1113.033012  \n",
       "2      4.67          1.068337e+09        1112.128477  \n",
       "3      4.67          1.068337e+09        1110.730463  \n",
       "4      4.67          1.068337e+09        1108.848344  \n",
       "...     ...                   ...                ...  \n",
       "20145  4.67          1.068336e+09        1112.710164  \n",
       "20146  4.67          1.068336e+09        1112.710164  \n",
       "20147  4.67          1.068336e+09        1112.710164  \n",
       "20148  4.67          1.068336e+09        1112.710164  \n",
       "20149  4.67          1.068336e+09        1113.330105  \n",
       "\n",
       "[20150 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "DEN_csv = pd.read_csv('/data/data_geodyn/results/st/msis2/msis2_acceloffSLR_kamodo_interface/DENSITY/st031109_2wk.goco05s', \n",
    "                    skiprows = 1, \n",
    "                    dtype=object,\n",
    "                    names = ['Elapsed Secs',\n",
    "                            'YYMMDD',\n",
    "                            'HHMMSS',\n",
    "                            'Lat',\n",
    "                            'Lon',\n",
    "                            'Height (meters)',\n",
    "                            'rho (kg/m**3)',\n",
    "                            'drhodz (kg/m**3/m)',\n",
    "                             'flux_daily',\n",
    "                            'flux_avg',\n",
    "                            'Kp',\n",
    "                          ],\n",
    "                    sep = '\\s+',\n",
    "                    )\n",
    "sat_time1 = list(DEN_csv['YYMMDD'])  #\"031115\" #  \n",
    "sat_time2 = list(DEN_csv['HHMMSS'])  #\"120000\" #1068897600        \n",
    "sattime   =    [x+y   for x,y   in zip(sat_time1, sat_time2)]\n",
    "\n",
    "sattime   =    [datetime.strptime(x, '%y%m%d%H%M%S')   for x   in sattime ]\n",
    "sattime   =    [datetime.timestamp(x)   for x   in sattime ]\n",
    "DEN_csv['sattime_utctimestamp'] = sattime\n",
    "DEN_csv['Height_kilometers'] = DEN_csv['Height (meters)'].astype(float)*1e-3\n",
    "DEN_csv['Lon'] = DEN_csv['Lon'].astype(float)\n",
    "DEN_csv['Lat'] = DEN_csv['Lat'].astype(float)\n",
    "\n",
    "fix_D_decimal_to_E = []\n",
    "fix_D_decimal_to_E2 = []\n",
    "\n",
    "for i,val in enumerate(DEN_csv['rho (kg/m**3)']):\n",
    "    val2 = DEN_csv['drhodz (kg/m**3/m)'][i]\n",
    "\n",
    "    list_val = list(val)\n",
    "    list_val2 = list(val2)\n",
    "\n",
    "    indx = list(val).index('D')\n",
    "    indx2 = list(val2).index('D')\n",
    "\n",
    "    list_val[indx] = 'E'\n",
    "    list_val2[indx2] = 'E'\n",
    "\n",
    "    list_val = \"\".join(list_val)\n",
    "    list_val2 = \"\".join(list_val2)\n",
    "\n",
    "    #### If you get an error here, it is likely:\n",
    "    ####\n",
    "    ###\n",
    "\n",
    "    val_float = np.float(list_val)\n",
    "    val_float2 = np.float(list_val2)\n",
    "\n",
    "    fix_D_decimal_to_E.append(val_float)\n",
    "    fix_D_decimal_to_E2.append(val_float2)\n",
    "\n",
    "DEN_csv['rho (kg/m**3)'] = fix_D_decimal_to_E\n",
    "DEN_csv['drhodz (kg/m**3/m)'] = fix_D_decimal_to_E2\n",
    "timeHHMMSS = [] \n",
    "for i,val in enumerate(DEN_csv['HHMMSS'].values.astype(int)):\n",
    "    # print(len(str(val)))\n",
    "    if len(str(val)) == 1:\n",
    "        timehhmmss_val = '00000'+ str(val)\n",
    "        timeHHMMSS.append(timehhmmss_val)\n",
    "    elif len(str(val)) == 2:\n",
    "        timehhmmss_val = '0000'+ str(val)\n",
    "        timeHHMMSS.append(timehhmmss_val)\n",
    "    elif len(str(val)) == 3:\n",
    "        timehhmmss_val = '000'+ str(val)\n",
    "        timeHHMMSS.append(timehhmmss_val)\n",
    "    elif len(str(val)) == 4:\n",
    "        timehhmmss_val = '00'+ str(val)\n",
    "        timeHHMMSS.append(timehhmmss_val)\n",
    "    elif len(str(val)) == 5:\n",
    "        timehhmmss_val = '0'+ str(val)\n",
    "        timeHHMMSS.append(timehhmmss_val)\n",
    "    else:\n",
    "        timeHHMMSS.append(str(val))\n",
    "DEN_csv['timeHHMMSS'] = timeHHMMSS\n",
    "YR = int(3)\n",
    "\n",
    "YYMMDD_list = DEN_csv['YYMMDD'].astype(int).astype(str)\n",
    "timeHHMMSS_list = DEN_csv['timeHHMMSS'].astype(str)\n",
    "\n",
    "if YR < 10:\n",
    "    year    = ['200' + x[:1]  for x in YYMMDD_list]\n",
    "    month   = [        x[1:3] for x in YYMMDD_list]\n",
    "    day     = [        x[3:]  for x in YYMMDD_list]\n",
    "    hours   = [        x[:2]  for x in timeHHMMSS_list]\n",
    "    minutes = [        x[2:4] for x in timeHHMMSS_list]\n",
    "    secs    = [        x[4:]  for x in timeHHMMSS_list]\n",
    "else:\n",
    "    year    = ['20' + x[:2]  for x in YYMMDD_list]\n",
    "    month   = [       x[2:4] for x in YYMMDD_list]\n",
    "    day     = [       x[4:]  for x in YYMMDD_list]\n",
    "    hours   = [       x[:2]  for x in timeHHMMSS_list]\n",
    "    minutes = [       x[2:4] for x in timeHHMMSS_list]\n",
    "    secs    = [       x[4:]  for x in timeHHMMSS_list]\n",
    "#--------------------------------------------------------\n",
    "DEN_csv['year']  = year\n",
    "DEN_csv['month'] = month\n",
    "DEN_csv['day']   = day\n",
    "DEN_csv['hours']  = hours\n",
    "DEN_csv['minutes'] = minutes\n",
    "DEN_csv['secs']  = secs\n",
    "#--------------------------------------------------------\n",
    "year= list(map(int, DEN_csv['year'].values))\n",
    "month= list(map(int, DEN_csv['month'].values))\n",
    "day= list(map(int, DEN_csv['day'].values))\n",
    "hour= list(map(int, DEN_csv['hours'].values))\n",
    "minute = list(map(int, DEN_csv['minutes'].values))\n",
    "second = list(map(int, DEN_csv['secs'].values))\n",
    "\n",
    "DATE = list(map(datetime, year,month, day, hour,minute,second ))\n",
    "\n",
    "#self.DEN_df['Date']  = DATE\n",
    "DEN_csv.insert(0, 'Date', DATE)\n",
    "\n",
    "del DEN_csv['timeHHMMSS']\n",
    "del DEN_csv['year']\n",
    "del DEN_csv['month']\n",
    "del DEN_csv['day']\n",
    "del DEN_csv['hours']\n",
    "del DEN_csv['minutes']\n",
    "del DEN_csv['secs']\n",
    "\n",
    "\n",
    "DEN_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c20448a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Make a cube of uncertainty around the init_orbit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789a3cd0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Considerations**\n",
    " - its possible that as long as our resolution is on par with MSIS we aren't introducing additional error. \n",
    " - Gauss legendre sampling scheme\n",
    " - Perhaps can access geodyn's sampling method in the early iterations.\n",
    " - nearest neighbor interpolation within Fortran for optimized speed. Weighted average for distance between each point\n",
    " - how much memory to story the data-table in memory.\n",
    "  - we will make MSISsubset  using msis\n",
    "\n",
    "\n",
    "**Desired Features in the Data Structure**\n",
    " - Must be able to interpolate to a desired location\n",
    " - Should be able to expand the bounds of uncertainty at any given timestep along the orbit\n",
    "    - prefereably without having to redo the already constructed portions\n",
    " - Each timestep should contain information on the `Lon`, `Lat`, `Alt` as well as the `RHO` and `DRHODZ` at each location\n",
    " - Include GEODYN run info (Satellite, Arc#, Arc Dates, density model used to initialize, etc.)\n",
    "\n",
    "\n",
    "Parent: timestep  \n",
    "    - each parent has square that contains uncertainty around the orbit \n",
    "    - lon lat, alt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cda37ea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:47.383798Z",
     "start_time": "2021-08-31T16:33:47.380846Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TEST_NUMS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffba60f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**START WITH A SIMPLE BOX**\n",
    "Just draw a cube around the coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6294c82d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.146522Z",
     "start_time": "2021-08-31T16:33:47.387111Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import time: 1.3721626379992813\n",
      "**** 2003-11-09 00:07:04 ****\n",
      "**** 2003-11-09 00:08:04 ****\n",
      "**** 2003-11-09 00:09:04 ****\n",
      "**** 2003-11-09 00:10:04 ****\n",
      "**** 2003-11-09 00:11:04 ****\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "from SingleSatelliteFlythrough import SingleModelFlythrough\n",
    "sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "from SatelliteFlythrough import ModelFlythrough\n",
    "\n",
    "\n",
    "uncertain_grid = {}\n",
    "\n",
    "for i,val in enumerate(DEN_csv['Elapsed Secs'][:TEST_NUMS]):\n",
    "    ## Make each timestep a dictionary to hold our coordinates\n",
    "    date_str = DEN_csv['YYMMDD'][i] + DEN_csv['HHMMSS'][i]\n",
    "    date_index = datetime.strptime(date_str, '%y%m%d%H%M%S')\n",
    "\n",
    "    \n",
    "    unix_time  = DEN_csv['sattime_utctimestamp'][i]\n",
    "    print('****',date_index, '****' )\n",
    "\n",
    "    \n",
    "    uncertain_grid[date_index] = {}\n",
    "    uncertain_grid[date_index]['coords'] = []\n",
    "    uncertain_grid[date_index]['values'] = []\n",
    "    \n",
    "    \n",
    "    ### Get the coordinates along the orbit:\n",
    "    lon = float(DEN_csv['Lon'][i])\n",
    "    lat = float(DEN_csv['Lat'][i])\n",
    "    alt = float(DEN_csv['Height_kilometers'][i])\n",
    "    center_coord = [lon, lat, alt]\n",
    "    \n",
    "    \n",
    "    ### Find the coordinates of the cube surround the orbit point:\n",
    "    delta_deg = 2    # degrees\n",
    "    delta_m = 1000.*1e-3 # meters to kilometers\n",
    "    A = [lon + delta_deg, lat+delta_deg, alt+delta_m]  # top,    front, left\n",
    "    B = [lon + delta_deg, lat-delta_deg, alt+delta_m]  # top,    back,  Left\n",
    "    C = [lon - delta_deg, lat+delta_deg, alt+delta_m]  # top,    front, right\n",
    "    D = [lon - delta_deg, lat-delta_deg, alt+delta_m]  # top,    back,  right\n",
    "    E = [lon + delta_deg, lat+delta_deg, alt-delta_m]  # bottom, front, left\n",
    "    F = [lon + delta_deg, lat-delta_deg, alt-delta_m]  # bottom, back,  left\n",
    "    G = [lon - delta_deg, lat+delta_deg, alt-delta_m]  # bottom, front, right\n",
    "    H = [lon - delta_deg, lat-delta_deg, alt-delta_m]  # bottom, back,  right\n",
    "    \n",
    "    \n",
    "    ### Store the cube's coordinates in the dictionary index\n",
    "    uncertain_grid[date_index]['coords'].append(center_coord)\n",
    "    uncertain_grid[date_index]['coords'].append(A)\n",
    "    uncertain_grid[date_index]['coords'].append(B)\n",
    "    uncertain_grid[date_index]['coords'].append(C)\n",
    "    uncertain_grid[date_index]['coords'].append(D)\n",
    "    uncertain_grid[date_index]['coords'].append(E)\n",
    "    uncertain_grid[date_index]['coords'].append(F)\n",
    "    uncertain_grid[date_index]['coords'].append(G)\n",
    "    uncertain_grid[date_index]['coords'].append(H)\n",
    "    \n",
    "    \n",
    "    #### Import Coordinates to Kamodo\n",
    "    ##\n",
    "    #### Kamodo static inputs:\n",
    "    model          = 'TIEGCM'\n",
    "    file_dir       = '/data/data_geodyn/atmos_models_data/tiegcm/2003/'\n",
    "    variable_list  = ['rho','psi_O2', 'psi_O', 'psi_N2', 'psi_He', 'T_n']\n",
    "    coord_type     = 'SPH'\n",
    "    coord_grid     = 'sph'\n",
    "    high_res       = 1.\n",
    "    verbose        = False  \n",
    "    csv_output     = '' \n",
    "    plot_output    = ''\n",
    "    \n",
    "    \n",
    "    #### Extract the coordinates from each list to plug into Kamodo with vectorization\n",
    "    lons_in = [item[0] for item in uncertain_grid[date_index]['coords']]\n",
    "    lats_in = [item[1] for item in uncertain_grid[date_index]['coords']]\n",
    "    alts_in = [item[2] for item in uncertain_grid[date_index]['coords']]\n",
    "    ## Gather inputs\n",
    "    sat_time       = unix_time*np.ones(np.size(alts_in))\n",
    "    c1             = lons_in\n",
    "    c2             = lats_in\n",
    "    c3             = alts_in\n",
    "    ## Plug vectorized coordinates into Kamodo\n",
    "    results = ModelFlythrough(model, file_dir, variable_list, sat_time, c1, c2, c3, \n",
    "                        coord_type, coord_grid, high_res=20., verbose=False, \n",
    "                        csv_output='', plot_output='')\n",
    "\n",
    "    \n",
    "    #### Save the values from Kamodo to the timestep:\n",
    "    uncertain_grid[date_index]['values'] = [[rho] for rho in results['rho']]    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46bd07be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.151572Z",
     "start_time": "2021-08-31T16:33:55.148289Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "orbit_w_uncertainty_cube = uncertain_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "129db428",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.158099Z",
     "start_time": "2021-08-31T16:33:55.153874Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for val in orbit_w_uncertainty_cube:\n",
    "#     print('',val)\n",
    "#     for valval in orbit_w_uncertainty_cube[val]:\n",
    "#         print('    ', valval, '-- size: ' , np.shape(orbit_w_uncertainty_cube[val][valval] ))\n",
    "#         for valvalval in orbit_w_uncertainty_cube[val][valval]:\n",
    "#             print('        ', valvalval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9098c15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:34:45.491359Z",
     "start_time": "2021-08-31T16:34:45.486182Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([datetime.datetime(2003, 11, 9, 0, 7, 4), datetime.datetime(2003, 11, 9, 0, 8, 4), datetime.datetime(2003, 11, 9, 0, 9, 4), datetime.datetime(2003, 11, 9, 0, 10, 4), datetime.datetime(2003, 11, 9, 0, 11, 4)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orbit_w_uncertainty_cube.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48811a06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.198750Z",
     "start_time": "2021-08-31T16:33:55.170123Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fff246",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.210547Z",
     "start_time": "2021-08-31T16:33:44.759Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c06146",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.211541Z",
     "start_time": "2021-08-31T16:33:44.763Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8ea6740",
   "metadata": {},
   "source": [
    "## Next steps:\n",
    "\n",
    "1. What data structure would work best for FORTRAN to read these tables at each timestep?\n",
    "    - ~~linked list structue?~~\n",
    "    - ~~a look up table?~~\n",
    "    - ~~pass the dict straight to fortran?~~\n",
    "    - **NETCDF file**\n",
    "\n",
    "2. Do a full run of the INIT_ORBIT through the Kamodo Cube of Uncertainty function\n",
    "    - expand the deltas in each direction so that we always have our box surrounding the orbit.\n",
    "\n",
    "3. Plug this data structure into fortran such that at any given timestep, requested by GEODYN the value can be found in the cube.\n",
    "\n",
    "4. Add the interpolation function to the fortran code.\n",
    "\n",
    "5. Do a full run of Kamodo-TIEGCM with the new interpolation method \n",
    "    - there is a chance this wont work and we may need to go ahead and implement the improved grid in the cube.\n",
    "    \n",
    "    \n",
    "Additional Features and Queries that will need to be addressed:\n",
    "  - increase the resolution of the grid within the cube\n",
    "      - can maybe make it match MSISe2's grid resolution\n",
    "      - if we have many cubes within the overall cube surrounding our INIT_ORBIT, we should write a simple selector code block that checks which sub-cube the coordinate is in, and only do the interpolation with that sub-cube.\n",
    "  - determine by how much GEODYN perturbs the coordinates on the orbit in the early iterations\n",
    "  \n",
    "  - how can this all be written such that the file doesn't have to be re-written but is only added to.\n",
    "      - can we construct the data-structures on a grid relative to earth such that additions can be made from separate runs?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce2a7d1",
   "metadata": {},
   "source": [
    "### Write dict as NETCDF file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d9ae2d8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T17:34:00.774988Z",
     "start_time": "2021-08-31T17:34:00.772433Z"
    }
   },
   "outputs": [],
   "source": [
    "TEST_NUMS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5021bcb0",
   "metadata": {},
   "source": [
    "We need to initialize these arrays and add on to them if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf2d2a",
   "metadata": {},
   "source": [
    "Make a grid that contains the possible altitude and longitude values.  We will save the values from the orbit to the nearest point on this grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8a12c164",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T17:35:36.255290Z",
     "start_time": "2021-08-31T17:35:36.245940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape lats_array (90,)\n",
      "shape lons_array (180,)\n",
      "shape alts_array (120,)\n"
     ]
    }
   ],
   "source": [
    "lons_array = np.arange(0, 360, 2)     # accurate to a degree\n",
    "lats_array = np.arange(-90, 90, 2)    # accurate to a degree\n",
    "alts_array = np.arange(440, 500, .5)  # accurate to 20 meters\n",
    "\n",
    "print('shape lats_array',lats_array.shape)\n",
    "print('shape lons_array',lons_array.shape)\n",
    "print('shape alts_array',alts_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "299aa9fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T17:51:17.600530Z",
     "start_time": "2021-08-31T17:51:08.634979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** 031109000704 ****\n",
      "0\n",
      "**** 031109000804 ****\n",
      "1\n",
      "**** 031109000904 ****\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "from SingleSatelliteFlythrough import SingleModelFlythrough\n",
    "sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "from SatelliteFlythrough import ModelFlythrough\n",
    "\n",
    "\n",
    "times_list = []\n",
    "rhos  = np.empty((TEST_NUMS,np.size(lons_array),np.size(lats_array), np.size(alts_array)))*np.nan\n",
    "\n",
    "for it,val in enumerate(DEN_csv['Elapsed Secs'][:TEST_NUMS]):\n",
    "    ## Make each timestep a dictionary to hold our coordinates\n",
    "    date_index = DEN_csv['YYMMDD'][it] + DEN_csv['HHMMSS'][it]\n",
    "#     date_index = datetime.strptime(date_str, '%y%m%d%H%M%S')\n",
    "    unix_time  = DEN_csv['sattime_utctimestamp'][it]\n",
    "    print('****',date_index, '****' )    \n",
    "\n",
    "    times_list.append(date_str)\n",
    "\n",
    "    ### Get the coordinates along the orbit:\n",
    "    lon = float(DEN_csv['Lon'][it])\n",
    "    lat = float(DEN_csv['Lat'][it])\n",
    "    alt = float(DEN_csv['Height_kilometers'][it])\n",
    "    center_coord = [lon, lat, alt]\n",
    "    \n",
    "    \n",
    "    ### Find the coordinates of the cube surround the orbit point:\n",
    "    delta_deg = 2    # degrees\n",
    "    delta_m = 1000.*1e-3 # meters to kilometers\n",
    "    A = [lon + delta_deg, lat+delta_deg, alt+delta_m]  # top,    front, left\n",
    "    B = [lon + delta_deg, lat-delta_deg, alt+delta_m]  # top,    back,  Left\n",
    "    C = [lon - delta_deg, lat+delta_deg, alt+delta_m]  # top,    front, right\n",
    "    D = [lon - delta_deg, lat-delta_deg, alt+delta_m]  # top,    back,  right\n",
    "    E = [lon + delta_deg, lat+delta_deg, alt-delta_m]  # bottom, front, left\n",
    "    F = [lon + delta_deg, lat-delta_deg, alt-delta_m]  # bottom, back,  left\n",
    "    G = [lon - delta_deg, lat+delta_deg, alt-delta_m]  # bottom, front, right\n",
    "    H = [lon - delta_deg, lat-delta_deg, alt-delta_m]  # bottom, back,  right\n",
    "    \n",
    "    \n",
    "    ### Store the cube's coordinates in the dictionary index\n",
    "    cube_corners_and_center = []\n",
    "    cube_corners_and_center.append(center_coord)\n",
    "    cube_corners_and_center.append(A)\n",
    "    cube_corners_and_center.append(B)\n",
    "    cube_corners_and_center.append(C)\n",
    "    cube_corners_and_center.append(D)\n",
    "    cube_corners_and_center.append(E)\n",
    "    cube_corners_and_center.append(F)\n",
    "    cube_corners_and_center.append(G)\n",
    "    cube_corners_and_center.append(H)\n",
    "    \n",
    "    \n",
    "    #### Import Coordinates to Kamodo\n",
    "    ##\n",
    "    #### Kamodo static inputs:\n",
    "    model          = 'TIEGCM'\n",
    "    file_dir       = '/data/data_geodyn/atmos_models_data/tiegcm/2003/'\n",
    "    variable_list  = ['rho','psi_O2', 'psi_O', 'psi_N2', 'psi_He', 'T_n']\n",
    "    coord_type     = 'SPH'\n",
    "    coord_grid     = 'sph'\n",
    "    high_res       = 1.\n",
    "    verbose        = False  \n",
    "    csv_output     = '' \n",
    "    plot_output    = ''\n",
    "    \n",
    "    \n",
    "    #### Extract the coordinates from each list to plug into Kamodo with vectorization\n",
    "    lons_in = [item[0] for item in cube_corners_and_center]\n",
    "    lats_in = [item[1] for item in cube_corners_and_center]\n",
    "    alts_in = [item[2] for item in cube_corners_and_center]\n",
    "       \n",
    "    \n",
    "    ## Gather inputs\n",
    "    sat_time       = unix_time*np.ones(np.size(alts_in))\n",
    "    c1             = lons_in\n",
    "    c2             = lats_in\n",
    "    c3             = alts_in\n",
    "    ## Plug vectorized coordinates into Kamodo\n",
    "    results = ModelFlythrough(model, file_dir, variable_list, sat_time, c1, c2, c3, \n",
    "                        coord_type, coord_grid, high_res=20., verbose=False, \n",
    "                        csv_output='', plot_output='')\n",
    "\n",
    "    \n",
    "    \n",
    "    #### Save the values from Kamodo to the timestep:\n",
    "    rho = [rho for rho in results['rho']]\n",
    "    \n",
    "    # We will loop through the values and find the gridpoint nearest to our coord. value for each dim\n",
    "    print(it)\n",
    "    \n",
    "    \n",
    "    ### We want to save the value at each corner of the cube to the grid:\n",
    "    for icorner in np.arange(0,len(cube_corners_and_center)):\n",
    "        \n",
    "        # For each corner, get the closest index on the grid to that value for each coord.\n",
    "        closestindx_lon = min(range(len(lons_array)), key = lambda i: abs(lons_array[i]-lons_in[icorner]))        \n",
    "        closestindx_lat = min(range(len(lats_array)), key = lambda i: abs(lats_array[i]-lats_in[icorner]))\n",
    "        closestindx_alt = min(range(len(alts_array)), key = lambda i: abs(alts_array[i]-alts_in[icorner]))\n",
    "        \n",
    "        \n",
    "        rhos[it, closestindx_lon, closestindx_lat, closestindx_alt] = rho[i_corner]\n",
    "\n",
    "    \n",
    "                    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #### Save the coordinates from RHO to the nearest gridpoint index.\n",
    "#     for ilon in lons_in:\n",
    "#         closestindx_lon = min(range(len(lons_array)), key = lambda i: abs(lons_array[i]-ilon))        \n",
    "#         for ilat in lats_in:\n",
    "#             closestindx_lat = min(range(len(lats_array)), key = lambda i: abs(lats_array[i]-ilat))\n",
    "#             for ialt in alts_in:\n",
    "#                 closest_altindx = min(range(len(alts_array)), key = lambda i: abs(alts_array[i]-ialt))\n",
    "    \n",
    "    \n",
    "#                 for i_corner, corner in enumerate(rho):\n",
    "                    \n",
    "#                     rhos[it, closestindx_lon, closestindx_lat, closest_altindx] = rho[i_corner]\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "315a69a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T17:35:56.683343Z",
     "start_time": "2021-08-31T17:35:56.677163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([           nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan,            nan,\n",
       "                  nan,            nan,            nan, 1.81185775e-19])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhos[it,closestindx_lon,closestindx_lat,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e544c4",
   "metadata": {},
   "source": [
    "Practice making netcdf manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1aa916e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T17:37:59.258062Z",
     "start_time": "2021-08-31T17:37:59.251199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lons_array (180,)\n",
      "lats_array (90,)\n",
      "alts_array (120,)\n"
     ]
    }
   ],
   "source": [
    "print('lons_array',lons_array.shape)\n",
    "print('lats_array',lats_array.shape)\n",
    "print('alts_array',alts_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ea4e68ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T17:41:28.825901Z",
     "start_time": "2021-08-31T17:41:28.802508Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lats_array.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "cae35442",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T17:50:52.034605Z",
     "start_time": "2021-08-31T17:50:51.923550Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "NetCDF: Not a valid ID",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-218-374e43160561>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Variable.__len__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Variable.shape.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Variable._getdims\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NetCDF: Not a valid ID"
     ]
    }
   ],
   "source": [
    "len(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c727f8a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T17:51:42.256795Z",
     "start_time": "2021-08-31T17:51:42.197323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "var size  (3, 90, 180, 120)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import os\n",
    "fn = 'test_manualwrite.nc'\n",
    "os.remove(fn)\n",
    "\n",
    "\n",
    "ds = nc.Dataset(fn, 'w', format='NETCDF4')\n",
    "\n",
    "time = ds.createDimension('time', len(times_list))\n",
    "lat = ds.createDimension('lat', int(lats_array.shape[0]))\n",
    "lon = ds.createDimension('lon', int(lons_array.shape[0]))\n",
    "lon = ds.createDimension('alt', int(alts_array.shape[0]))\n",
    "\n",
    "times = ds.createVariable('time', 'f4', ('time',))\n",
    "lats = ds.createVariable('lat', 'f4', ('lat',))\n",
    "lons = ds.createVariable('lon', 'f4', ('lon',))\n",
    "alts = ds.createVariable('alt', 'f4', ('alt',))\n",
    "rho = ds.createVariable('rho', 'f4', ('time', 'lat', 'lon','alt'))\n",
    "rho.units = 'g/cm^3'\n",
    "\n",
    "lat_array = lats_array\n",
    "lon_array = lons_array\n",
    "alt_array = alts_array\n",
    "\n",
    "lats[:] = lat_array\n",
    "lons[:] = lon_array\n",
    "alts[:] = alt_array\n",
    "\n",
    "\n",
    "print('var size ', rho.shape)\n",
    "# rho[0, :, :, :] = np.random.uniform(0, 100, size=(360, 720))\n",
    "# print('var size after adding first data', value.shape)\n",
    "\n",
    "\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "89176e8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T17:53:51.192886Z",
     "start_time": "2021-08-31T17:53:51.146909Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = nc.Dataset(fn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "58795b94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T17:53:52.177743Z",
     "start_time": "2021-08-31T17:53:52.002167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(\n",
       "  data=[[[[--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          ...,\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --]],\n",
       "\n",
       "         [[--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          ...,\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --]],\n",
       "\n",
       "         [[--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          ...,\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          ...,\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --]],\n",
       "\n",
       "         [[--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          ...,\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --]],\n",
       "\n",
       "         [[--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          ...,\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --]]],\n",
       "\n",
       "\n",
       "        [[[--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          ...,\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --]],\n",
       "\n",
       "         [[--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          ...,\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --]],\n",
       "\n",
       "         [[--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          ...,\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          ...,\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --]],\n",
       "\n",
       "         [[--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          ...,\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --]],\n",
       "\n",
       "         [[--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          ...,\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --]]],\n",
       "\n",
       "\n",
       "        [[[--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          ...,\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --]],\n",
       "\n",
       "         [[--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          ...,\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --]],\n",
       "\n",
       "         [[--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          ...,\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          ...,\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --]],\n",
       "\n",
       "         [[--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          ...,\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --]],\n",
       "\n",
       "         [[--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          ...,\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --],\n",
       "          [--, --, --, ..., --, --, --]]]],\n",
       "  mask=[[[[ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          ...,\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          ...,\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          ...,\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          ...,\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          ...,\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          ...,\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        [[[ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          ...,\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          ...,\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          ...,\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          ...,\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          ...,\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          ...,\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        [[[ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          ...,\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          ...,\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          ...,\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          ...,\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          ...,\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          ...,\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True],\n",
       "          [ True,  True,  True, ...,  True,  True,  True]]]],\n",
       "  fill_value=9.96921e+36,\n",
       "  dtype=float32)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.variables['rho'][:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "14ec618c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T17:52:57.399165Z",
     "start_time": "2021-08-31T17:52:57.266146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NETCDF4'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0b41951c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T17:47:11.288584Z",
     "start_time": "2021-08-31T17:47:11.266995Z"
    }
   },
   "outputs": [],
   "source": [
    "# lon_array = np.arange(0, 360, 1)\n",
    "# lat_array = np.arange(-90, 90, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d631b6c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T21:10:43.899727Z",
     "start_time": "2021-08-30T21:10:43.895975Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2035dbde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.224965Z",
     "start_time": "2021-08-31T16:33:44.828Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf33a08f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T20:47:51.538084Z",
     "start_time": "2021-08-30T20:47:51.533645Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd3d0c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.225743Z",
     "start_time": "2021-08-31T16:33:44.834Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ef1535b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T17:47:13.645739Z",
     "start_time": "2021-08-31T17:47:13.619289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access the dimensions:\n",
      "     <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\n",
      "     <class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 90\n",
      "     <class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 180\n",
      "     <class 'netCDF4._netCDF4.Dimension'>: name = 'alt', size = 120\n",
      "Access the variable metadata:\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 time(time)\n",
      "unlimited dimensions: time\n",
      "current shape = (0,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 lat(lat)\n",
      "unlimited dimensions: \n",
      "current shape = (90,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 lon(lon)\n",
      "unlimited dimensions: \n",
      "current shape = (180,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 alt(alt)\n",
      "unlimited dimensions: \n",
      "current shape = (120,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 rho(time, lat, lon, alt)\n",
      "    units: g/cm^3\n",
      "unlimited dimensions: time\n",
      "current shape = (0, 90, 180, 120)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n"
     ]
    }
   ],
   "source": [
    "# print(ds.__dict__)\n",
    "\n",
    "print('Access the dimensions:')\n",
    "for dim in ds.dimensions.values():\n",
    "    print('    ',dim)\n",
    "\n",
    "    \n",
    "print('Access the variable metadata:')\n",
    "for var in ds.variables.values():\n",
    "    print(var)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2142039",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T17:21:34.104679Z",
     "start_time": "2021-08-30T17:21:34.093661Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b6d944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80b4de3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T16:20:59.000048Z",
     "start_time": "2021-08-30T16:20:58.996203Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ac0a717",
   "metadata": {},
   "source": [
    "Build a single matrix containing these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8a27ab94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:53:19.441927Z",
     "start_time": "2021-08-31T16:53:19.436262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6401cc6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:53:19.826699Z",
     "start_time": "2021-08-31T16:53:19.824452Z"
    }
   },
   "outputs": [],
   "source": [
    "# d = {}\n",
    "# d['time'] = ('time',times)\n",
    "# d['latitudes'] = ('latitudes',lats)\n",
    "# d['longitudes'] = ('longitudes', lons)\n",
    "# d['altitudes'] = ('altitudes', alts)\n",
    "# d['rhos'] = (['time'], rhos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4dc42ad2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:53:20.229082Z",
     "start_time": "2021-08-31T16:53:20.226827Z"
    }
   },
   "outputs": [],
   "source": [
    "# dxr = xr.DataArray(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0cdb3d4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:53:20.562470Z",
     "start_time": "2021-08-31T16:53:20.560108Z"
    }
   },
   "outputs": [],
   "source": [
    "# dxr.to_netcdf(path='test_file.nc', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "85d91062",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:55:12.067439Z",
     "start_time": "2021-08-31T16:55:12.062151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF4 data model, file format HDF5):\n",
       "    dimensions(sizes): \n",
       "    variables(dimensions): \n",
       "    groups: "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = nc.Dataset(fn, 'r', format='NETCDF4')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf937ff",
   "metadata": {},
   "source": [
    "Using multi-indexing we can make a series of our rho values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1980d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:38:03.555531Z",
     "start_time": "2021-08-31T16:38:03.550507Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcba3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a92454a5",
   "metadata": {},
   "source": [
    "Below is the datastructure as a pandas df with multiindexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f6e878",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.221785Z",
     "start_time": "2021-08-31T16:33:44.811Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for it, val_t in enumerate(times):\n",
    "    idx = pd.MultiIndex.from_arrays(arrays=[lats[it],lons[it], alts[it]], names=[\"lat\",\"lon\",\"alts\"])\n",
    "    s = pd.Series(data=rhos[it], index=idx)\n",
    "    \n",
    "# use from_series method\n",
    "#     da = xr.DataArray.from_series(s)\n",
    "# da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9f2a01e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:45:40.522267Z",
     "start_time": "2021-08-31T16:45:40.507790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>alt</th>\n",
       "      <th>rho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">time</th>\n",
       "      <th>center</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             lon  lat  alt  rho\n",
       "time center  NaN  NaN  NaN  NaN\n",
       "     A       NaN  NaN  NaN  NaN\n",
       "     B       NaN  NaN  NaN  NaN\n",
       "     C       NaN  NaN  NaN  NaN\n",
       "     D       NaN  NaN  NaN  NaN\n",
       "     E       NaN  NaN  NaN  NaN\n",
       "     F       NaN  NaN  NaN  NaN\n",
       "     G       NaN  NaN  NaN  NaN\n",
       "     H       NaN  NaN  NaN  NaN"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# idx = pd.MultiIndex.from_arrays(arrays=[[], [],[], []], names=[\"time\",\"lat\",\"lon\",\"alts\"])\n",
    "\n",
    "idx = pd.DataFrame(index = [['time','time','time','time','time','time','time','time','time'],\n",
    "                                           ['center','A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'], ],\n",
    "                                columns = ['lon', 'lat', 'alt', 'rho'],\n",
    "                               )\n",
    "idx\n",
    "# s = pd.Series(data='', index=idx)\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(s)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24fcac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173e556a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f97362d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37456946",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.228099Z",
     "start_time": "2021-08-31T16:33:44.855Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.exit('STOP RUNNING BEFORE THE TESTS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aa3b16",
   "metadata": {},
   "source": [
    "# Tests and Attempts Below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d415e08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:57:54.672759Z",
     "start_time": "2021-08-27T19:57:54.631536Z"
    }
   },
   "source": [
    "### Test if cube works for a set of noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4b8e31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.228897Z",
     "start_time": "2021-08-31T16:33:44.859Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "lons = DEN_csv['Lon'][:TEST_NUMS]\n",
    "lats = DEN_csv['Lat'][:TEST_NUMS]\n",
    "alts = DEN_csv['Height_kilometers'][:TEST_NUMS]       \n",
    "noisy_lons = [i+random.randint(-1,1) for i in lons]\n",
    "noisy_lats = [i+random.randint(-1,1) for i in lats]\n",
    "noisy_alts = [i+random.randint(-1,1) for i in alts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b8236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.229729Z",
     "start_time": "2021-08-31T16:33:44.862Z"
    }
   },
   "outputs": [],
   "source": [
    "kamodo_direct = []\n",
    "interpd_orbit = []\n",
    "\n",
    "for i,val in enumerate(DEN_csv['Elapsed Secs'][:TEST_NUMS]):\n",
    "    \n",
    "    print('****',date_index, '****' )\n",
    "    ## Make each timestep a dictionary to hold our coordinates\n",
    "    date_index = DEN_csv['YYMMDD'][i] + DEN_csv['HHMMSS'][i]\n",
    "    unix_time  = DEN_csv['sattime_utctimestamp'][i]\n",
    "    \n",
    "    test_lon = noisy_lons[i]\n",
    "    test_lat = noisy_lats[i]\n",
    "    test_alt = noisy_alts[i]\n",
    "    \n",
    "    sat_time       = [unix_time]\n",
    "    c1             = [test_lon]\n",
    "    c2             = [test_lat]\n",
    "    c3             = [test_alt]\n",
    "\n",
    "    results = ModelFlythrough(model, file_dir, variable_list, sat_time, c1, c2, c3, \n",
    "                        coord_type, coord_grid, high_res=20., verbose=False, \n",
    "                        csv_output='', plot_output='')\n",
    "    \n",
    "#     print('      ',results['rho'][0] )\n",
    "#     print('      ',interpolate_point_in_cube(test_lon, test_lat, test_alt, uncertain_grid, date_index, delta_deg, delta_m)[0])\n",
    "    kamodo_direct.append(results['rho'][0])\n",
    "    interpd_orbit.append(interpolate_point_in_cube(test_lon, test_lat, test_alt, uncertain_grid, date_index, delta_deg, delta_m)[0])\n",
    "\n",
    "    \n",
    "    \n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot, iplot\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "config = dict({\n",
    "                'displayModeBar': True,\n",
    "                'responsive': False,\n",
    "                'staticPlot': False,\n",
    "                'displaylogo': False,\n",
    "                'showTips': False,\n",
    "                })\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1,\n",
    "                   )\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=DEN_csv['sattime_utctimestamp'][:TEST_NUMS].values,\n",
    "                         y=kamodo_direct,\n",
    "                         mode='markers',\n",
    "                         marker=dict(size=3)),\n",
    "                         )\n",
    "\n",
    "fig.add_trace(go.Scatter(x=DEN_csv['sattime_utctimestamp'][:TEST_NUMS].values,\n",
    "                         y=interpd_orbit,\n",
    "                         mode='markers',\n",
    "                         marker=dict(size=3)),\n",
    "                         )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d6dbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T22:02:12.957563Z",
     "start_time": "2021-08-27T22:02:12.951867Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381feace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T20:29:16.929810Z",
     "start_time": "2021-08-27T20:29:16.900082Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d6da29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T22:15:23.216067Z",
     "start_time": "2021-08-27T22:15:23.213386Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d75dbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.230529Z",
     "start_time": "2021-08-31T16:33:44.869Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# from numpy import array\n",
    "# import sys\n",
    "# sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "# from SingleSatelliteFlythrough import SingleModelFlythrough\n",
    "# sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "# from SatelliteFlythrough import ModelFlythrough\n",
    "\n",
    "\n",
    "\n",
    "# #### Kamodo static inputs:\n",
    "# model          = 'TIEGCM'\n",
    "# file_dir       = '/data/data_geodyn/atmos_models_data/tiegcm/2003/'\n",
    "# variable_list  = ['rho','psi_O2', 'psi_O', 'psi_N2', 'psi_He', 'T_n']\n",
    "# coord_type     = 'SPH'\n",
    "# coord_grid     = 'sph'\n",
    "# high_res       = 1.\n",
    "# verbose        = False  \n",
    "# csv_output     = '' \n",
    "# plot_output    = ''\n",
    "\n",
    "    \n",
    "# for i,date in enumerate(uncertain_grid['YYMMDDHHMMSS']):\n",
    "#     print('***** '+ date +' *****')\n",
    "    \n",
    "#     for ii,loop in enumerate(loops):\n",
    "\n",
    "#         sat_time       = [uncertain_grid['sattime_utctimestamp'][i]]\n",
    "#         c1             = [uncertain_grid['lon'+loop[0]][i]]\n",
    "#         c2             = [uncertain_grid['lat'+loop[1]][i]]\n",
    "#         c3             = [uncertain_grid['z'+loop[2]][i]]\n",
    "#         print('    ','lon'+loop[0],'lat'+loop[1] , 'z'+loop[2] )\n",
    "        \n",
    "#         results = ModelFlythrough(model, file_dir, variable_list, sat_time, c1, c2, c3, \n",
    "#                             coord_type, coord_grid, high_res=20., verbose=False, \n",
    "#                             csv_output='', plot_output='')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51866d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.231361Z",
     "start_time": "2021-08-31T16:33:44.872Z"
    }
   },
   "outputs": [],
   "source": [
    "# ########################## CHECK WITH A PLOT:\n",
    "\n",
    "# import plotly.graph_objects as go\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# fig = go.Figure(data=[go.Scatter3d(x=[lon], y=[lat], z=[alt],\n",
    "#                                    mode='markers')])\n",
    "# ms_size = 10\n",
    "# fig.add_trace(go.Scatter3d(\n",
    "#                          x=[A[0]], y=[A[1]], z=[A[2]],\n",
    "#                          mode='markers',\n",
    "#                         name = 'A',\n",
    "#                          marker=dict(size=ms_size)),\n",
    "#                          )\n",
    "# fig.add_trace(go.Scatter3d(\n",
    "#                          x=[B[0]], y=[B[1]], z=[B[2]],\n",
    "#                          mode='markers',\n",
    "#                         name = 'B',\n",
    "#                          marker=dict(size=ms_size)),\n",
    "#                          )\n",
    "# fig.add_trace(go.Scatter3d(\n",
    "#                          x=[C[0]], y=[C[1]], z=[C[2]],\n",
    "#                          mode='markers',\n",
    "#                         name = 'C',\n",
    "#                          marker=dict(size=ms_size)),\n",
    "#                          )\n",
    "# fig.add_trace(go.Scatter3d(\n",
    "#                          x=[D[0]], y=[D[1]], z=[D[2]],\n",
    "#                          mode='markers',\n",
    "#                         name = 'D',\n",
    "#                          marker=dict(size=ms_size)),\n",
    "#                          )\n",
    "# fig.add_trace(go.Scatter3d(\n",
    "#                          x=[E[0]], y=[E[1]], z=[E[2]],\n",
    "#                          mode='markers',\n",
    "#                         name = 'E',\n",
    "#                          marker=dict(size=ms_size)),\n",
    "#                          )\n",
    "# fig.add_trace(go.Scatter3d(\n",
    "#                          x=[F[0]], y=[F[1]], z=[F[2]],\n",
    "#                          mode='markers',\n",
    "#                         name = 'F',\n",
    "#                          marker=dict(size=ms_size)),\n",
    "#                          )\n",
    "# fig.add_trace(go.Scatter3d(\n",
    "#                          x=[G[0]], y=[G[1]], z=[G[2]],\n",
    "#                          mode='markers',\n",
    "#                         name = 'G',\n",
    "#                          marker=dict(size=ms_size)),\n",
    "#                          )\n",
    "# fig.add_trace(go.Scatter3d(\n",
    "#                          x=[H[0]], y=[H[1]], z=[H[2]],\n",
    "#                          mode='markers',\n",
    "#                         name = 'H',\n",
    "#                          marker=dict(size=ms_size)),\n",
    "#                          )\n",
    "# fig.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984f5ad4",
   "metadata": {},
   "source": [
    "### Attempt for all permutations of lonlatz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140d1bfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.232210Z",
     "start_time": "2021-08-31T16:33:44.876Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uncertain_grid = {}\n",
    "\n",
    "\n",
    "delta_deg = 0.5 # degrees\n",
    "delta_met = 10.*1e-3 # meters to kilometers\n",
    "\n",
    "uncertain_grid['YYMMDDHHMMSS']  = []\n",
    "uncertain_grid['sattime_utctimestamp']  = []\n",
    "uncertain_grid['lat']           = []\n",
    "uncertain_grid['lat_p']         = []\n",
    "uncertain_grid['lat_m']         = []\n",
    "uncertain_grid['lon']           = []\n",
    "uncertain_grid['lon_p']         = []\n",
    "uncertain_grid['lon_m']         = []\n",
    "uncertain_grid['z']             = []\n",
    "uncertain_grid['z_p']           = []\n",
    "uncertain_grid['z_m']           = []\n",
    "\n",
    "\n",
    "for i,val in enumerate(DEN_csv['Elapsed Secs'][:20]):\n",
    "    uncertain_grid['YYMMDDHHMMSS'].append(DEN_csv['YYMMDD'][i] + DEN_csv['HHMMSS'][i])\n",
    "    uncertain_grid['sattime_utctimestamp'].append(DEN_csv['sattime_utctimestamp'][i])\n",
    "    \n",
    "    #### Perturbate the coordinates to some uncertainty\n",
    "    uncertain_grid['lat'].append(DEN_csv['Lat'][i])\n",
    "    uncertain_grid['lat_p'].append(DEN_csv['Lat'][i] + delta_deg)\n",
    "    uncertain_grid['lat_m'].append(DEN_csv['Lat'][i] - delta_deg)\n",
    "    \n",
    "    uncertain_grid['lon'].append(DEN_csv['Lon'][i])\n",
    "    uncertain_grid['lon_p'].append(DEN_csv['Lon'][i] + delta_deg)\n",
    "    uncertain_grid['lon_m'].append(DEN_csv['Lon'][i] - delta_deg)\n",
    "    \n",
    "    uncertain_grid['z'].append(DEN_csv['Height_kilometers'][i])\n",
    "    uncertain_grid['z_p'].append(DEN_csv['Height_kilometers'][i] + delta_met)\n",
    "    uncertain_grid['z_m'].append(DEN_csv['Height_kilometers'][i] - delta_met)\n",
    "    \n",
    "    \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from numpy import array\n",
    "import sys\n",
    "sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "from SingleSatelliteFlythrough import SingleModelFlythrough\n",
    "sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "from SatelliteFlythrough import ModelFlythrough\n",
    "import itertools\n",
    "\n",
    "# for combo in itertools.combinations_with_replacement(['', '_p', '_m'], 3):\n",
    "#     loop_options.append([i + j for i, j in zip(['', '', ''], combo)])\n",
    "\n",
    "def perm(n, seq):\n",
    "    loop_options = []\n",
    "    for p in itertools.product(seq, repeat=n):\n",
    "        loop_options.append([i + j for i, j in zip(['', '', ''], p)])\n",
    "    return(loop_options)\n",
    "loops = perm(3, ['', '_m', '_p'])\n",
    "\n",
    "\n",
    "#### Kamodo static inputs:\n",
    "model          = 'TIEGCM'\n",
    "file_dir       = '/data/data_geodyn/atmos_models_data/tiegcm/2003/'\n",
    "variable_list  = ['rho','psi_O2', 'psi_O', 'psi_N2', 'psi_He', 'T_n']\n",
    "coord_type     = 'SPH'\n",
    "coord_grid     = 'sph'\n",
    "high_res       = 1.\n",
    "verbose        = False  \n",
    "csv_output     = '' \n",
    "plot_output    = ''\n",
    "\n",
    "\n",
    "\n",
    "#### Open file to construct CSV\n",
    "# CSV_MAKE_FLAG = True\n",
    "# if CSV_MAKE_FLAG:\n",
    "\n",
    "#     csv_filename = 'orbit_uncertainty_cloud_'+'.csv'\n",
    "#     data_out = open(csv_filename, 'w')\n",
    "#     data_out.write(f'\\n  #Model: {model} \\n')\n",
    "#     data_out.write(f'\\n  YYMMDDHHMMSS  Unix time     Lon      Lat    Altitude[km]       Density         \\n')\n",
    "#                         #031109000704 1068336424.0 217.8688 -25.1728 1113.435865 1.8578944895229333e-19\n",
    "\n",
    "    \n",
    "for i,date in enumerate(uncertain_grid['YYMMDDHHMMSS']):\n",
    "    print('***** '+ date +' *****')\n",
    "    \n",
    "    for ii,loop in enumerate(loops):\n",
    "\n",
    "        sat_time       = [uncertain_grid['sattime_utctimestamp'][i]]\n",
    "        c1             = [uncertain_grid['lon'+loop[0]][i]]\n",
    "        c2             = [uncertain_grid['lat'+loop[1]][i]]\n",
    "        c3             = [uncertain_grid['z'+loop[2]][i]]\n",
    "        print('    ','lon'+loop[0],'lat'+loop[1] , 'z'+loop[2] )\n",
    "        \n",
    "        results = ModelFlythrough(model, file_dir, variable_list, sat_time, c1, c2, c3, \n",
    "                            coord_type, coord_grid, high_res=20., verbose=False, \n",
    "                            csv_output='', plot_output='')\n",
    "\n",
    "#         if CSV_MAKE_FLAG:\n",
    "#             for ii,values in enumerate(results['utc_time']):\n",
    "#                 data_out.write( uncertain_grid['YYMMDDHHMMSS'][i]+' '+\n",
    "#                                 str(results['utc_time'][ii]) +' '+\n",
    "#                                 str(c1[0]) +' '+\n",
    "#                                 str(c2[0]) +' '+\n",
    "#                                 str(c3[0]) +' '+\n",
    "#                                 #\n",
    "#                                 str(results['rho'][0])  \n",
    "#                                 +'\\n')\n",
    "data_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f569cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a44a14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T15:46:48.638609Z",
     "start_time": "2021-08-27T15:46:48.612784Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65d38cad",
   "metadata": {},
   "source": [
    "Try making a grid in the the altitude dimension only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ccd860",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.232998Z",
     "start_time": "2021-08-31T16:33:44.882Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed29f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.233853Z",
     "start_time": "2021-08-31T16:33:44.885Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from numpy import array\n",
    "import sys\n",
    "sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "from SingleSatelliteFlythrough import SingleModelFlythrough\n",
    "sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "from SatelliteFlythrough import ModelFlythrough\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "uncertain_grid = {}\n",
    "\n",
    "CSV_MAKE_FLAG = True\n",
    "delta_deg = 0.5 # degrees\n",
    "delta_met = 10.*1e-3 # meters to kilometers\n",
    "\n",
    "uncertain_grid['YYMMDDHHMMSS']  = []\n",
    "uncertain_grid['sattime_utctimestamp']  = []\n",
    "uncertain_grid['z']             = []\n",
    "uncertain_grid['z_p']           = []\n",
    "uncertain_grid['z_m']           = []\n",
    "uncertain_grid['z_2p']           = []\n",
    "uncertain_grid['z_2m']           = []\n",
    "uncertain_grid['lon']             = []\n",
    "uncertain_grid['lon_p']           = []\n",
    "uncertain_grid['lon_m']           = []\n",
    "uncertain_grid['lon_2p']           = []\n",
    "uncertain_grid['lon_2m']           = []\n",
    "uncertain_grid['lat']             = []\n",
    "uncertain_grid['lat_p']           = []\n",
    "uncertain_grid['lat_m']           = []\n",
    "uncertain_grid['lat_2p']           = []\n",
    "uncertain_grid['lat_2m']           = []\n",
    "\n",
    "\n",
    "for i,val in enumerate(DEN_csv['Elapsed Secs'][:20]):\n",
    "    uncertain_grid['YYMMDDHHMMSS'].append(DEN_csv['YYMMDD'][i] + DEN_csv['HHMMSS'][i])\n",
    "    uncertain_grid['sattime_utctimestamp'].append(DEN_csv['sattime_utctimestamp'][i])\n",
    "    uncertain_grid['lat'].append(DEN_csv['Lat'][i])\n",
    "    uncertain_grid['lon'].append(DEN_csv['Lon'][i])\n",
    "\n",
    "    #### Perturbate the coordinates to some uncertainty\n",
    "    uncertain_grid['lon'].append(DEN_csv['Lon'][i])\n",
    "    uncertain_grid['lon_p'].append(DEN_csv['Lon'][i] + delta_deg)\n",
    "    uncertain_grid['lon_m'].append(DEN_csv['Lon'][i] - delta_deg)\n",
    "    uncertain_grid['lon_2p'].append(DEN_csv['Lon'][i] + 2*delta_deg)\n",
    "    uncertain_grid['lon_2m'].append(DEN_csv['Lon'][i] - 2*delta_deg)\n",
    "    \n",
    "    uncertain_grid['lat'].append(DEN_csv['Lat'][i])\n",
    "    uncertain_grid['lat_p'].append(DEN_csv['Lat'][i] + delta_deg)\n",
    "    uncertain_grid['lat_m'].append(DEN_csv['Lat'][i] - delta_deg)\n",
    "    uncertain_grid['lat_2p'].append(DEN_csv['Lat'][i] + 2*delta_deg)\n",
    "    uncertain_grid['lat_2m'].append(DEN_csv['Lat'][i] - 2*delta_deg)\n",
    "    \n",
    "    uncertain_grid['z'].append(DEN_csv['Height_kilometers'][i])\n",
    "    uncertain_grid['z_p'].append(DEN_csv['Height_kilometers'][i] + delta_met)\n",
    "    uncertain_grid['z_m'].append(DEN_csv['Height_kilometers'][i] - delta_met)\n",
    "    uncertain_grid['z_2p'].append(DEN_csv['Height_kilometers'][i] + 2*delta_met)\n",
    "    uncertain_grid['z_2m'].append(DEN_csv['Height_kilometers'][i] - 2*delta_met)\n",
    "\n",
    "\n",
    "# import itertools\n",
    "# def perm(n, seq):\n",
    "#     loop_options = []\n",
    "#     for p in itertools.product(seq, repeat=n):\n",
    "#         loop_options.append([i + j for i, j in zip(['', '', ''], p)])\n",
    "#     return(loop_options)\n",
    "# loops = perm(3, ['', '_m', '_p'])\n",
    "\n",
    "\n",
    "### OPEN CSV FIRST outside of the loop:\n",
    "CSV_MAKE_FLAG = True\n",
    "\n",
    "if CSV_MAKE_FLAG:\n",
    "\n",
    "    csv_filename = 'orbit_uncertainty_cloud_'+'.csv'\n",
    "    data_out = open(csv_filename, 'w')\n",
    "    data_out.write(f'\\n#Model used:, {file_dir}')\n",
    "\n",
    "\n",
    "\n",
    "for i,date in enumerate(uncertain_grid['YYMMDDHHMMSS']):\n",
    "    print('***** '+ date +' *****')\n",
    "    model          = 'TIEGCM'\n",
    "    file_dir       = '/data/data_geodyn/atmos_models_data/tiegcm/2003/'\n",
    "    variable_list  = ['rho','psi_O2', 'psi_O', 'psi_N2', 'psi_He', 'T_n']\n",
    "    coord_type     = 'SPH'\n",
    "    coord_grid     = 'sph'\n",
    "    high_res       = 1.\n",
    "    verbose        = False  \n",
    "    csv_output     = '' \n",
    "    plot_output    = ''\n",
    "    \n",
    "#     c1             = [uncertain_grid['lon_2m'][i], \n",
    "#                       uncertain_grid['lon_m'][i],\n",
    "#                       uncertain_grid['lon'][i],\n",
    "#                       uncertain_grid['lon_p'][i],\n",
    "#                       uncertain_grid['lon_2p'][i] ]\n",
    "# --------------------------------------------------------\n",
    "# --------------------------------------------------------\n",
    "#     c2             = [uncertain_grid['lat_2m'][i], \n",
    "#                       uncertain_grid['lat_m'][i],\n",
    "#                       uncertain_grid['lat'][i],\n",
    "#                       uncertain_grid['lat_p'][i],\n",
    "#                       uncertain_grid['lat_2p'][i] ]\n",
    "\n",
    "    c3             = [uncertain_grid['z_2m'][i], \n",
    "                      uncertain_grid['z_m'][i],\n",
    "                      uncertain_grid['z'][i],\n",
    "                      uncertain_grid['z_p'][i],\n",
    "                      uncertain_grid['z_2p'][i] ]\n",
    "    c1             = uncertain_grid['lon'][i]*np.ones(np.size(c3))\n",
    "    c2             = uncertain_grid['lat'][i]*np.ones(np.size(c3))\n",
    "\n",
    "    sat_time       = uncertain_grid['sattime_utctimestamp'][i]*np.ones(np.size(c3))\n",
    "\n",
    "    results = ModelFlythrough(model, file_dir, variable_list, sat_time, c1, c2, c3, \n",
    "                        coord_type, coord_grid, high_res=20., verbose=False, \n",
    "                        csv_output='', plot_output='')\n",
    "    \n",
    "    if CSV_MAKE_FLAG:\n",
    "        for ii,values in enumerate(results['utc_time']):\n",
    "            data_out.write( uncertain_grid['YYMMDDHHMMSS'][i]+' '+\n",
    "                            str(results['utc_time'][ii]) +' '+\n",
    "                            str(results['c1'][ii]) +' '+\n",
    "                            str(results['c2'][ii]) +' '+\n",
    "                            str(uncertain_grid['z_2m'][ii]) +' '+\n",
    "                            str(uncertain_grid['z_m'][ii]) +' '+\n",
    "                            str(uncertain_grid['z'][ii]) +' '+\n",
    "                            str(uncertain_grid['z_p'][ii]) +' '+\n",
    "                            str(uncertain_grid['z_2p'][ii]) +' '+\n",
    "                            #\n",
    "                            str(results['rho'][0]) +' '+\n",
    "                            str(results['rho'][1]) +' '+\n",
    "                            str(results['rho'][2]) +' '+\n",
    "                            str(results['rho'][3]) +' '+\n",
    "                            str(results['rho'][4]) \n",
    "                            +'\\n')\n",
    "data_out.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c95598",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.234620Z",
     "start_time": "2021-08-31T16:33:44.888Z"
    }
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e7a2a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T15:28:55.524588Z",
     "start_time": "2021-08-26T15:28:55.497852Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d273b899",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T15:10:35.040218Z",
     "start_time": "2021-08-26T15:10:33.689Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcacbf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T15:04:42.568773Z",
     "start_time": "2021-08-26T15:04:25.204259Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7756058b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.235417Z",
     "start_time": "2021-08-31T16:33:44.895Z"
    }
   },
   "outputs": [],
   "source": [
    "# import itertools \n",
    "# A = list(itertools.product(['1', '2', '3'],['', '_p', '_m']))\n",
    "\n",
    "# list_join = []\n",
    "# for i in A:\n",
    "#     join_item = ''\n",
    "#     list_join.append(join_item.join(i))\n",
    "# # print(list_join)\n",
    "\n",
    "# B = list(itertools.product(['lon', 'lat', 'alt'],list_join))\n",
    "# print(B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5340c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.236509Z",
     "start_time": "2021-08-31T16:33:44.899Z"
    }
   },
   "outputs": [],
   "source": [
    "loop_options = []\n",
    "# for combo in itertools.combinations_with_replacement(['1', '2', '3'],3):\n",
    "for combo in itertools.permutations(['', '_m', '_p'],3):\n",
    "\n",
    "    loop_options.append([i + j for i, j in zip(['', '', ''], combo)])\n",
    "\n",
    "(loop_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7cf9e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.237398Z",
     "start_time": "2021-08-31T16:33:44.902Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def perm(n, seq):\n",
    "    count = 0\n",
    "\n",
    "    for p in itertools.product(seq, repeat=n):\n",
    "#         print((p), count)\n",
    "        count+=1\n",
    "        print(count, [i + j for i, j in zip(['lon', 'lat', 'alt'], p)])\n",
    "perm(3, ['', '_m', '_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3780bc39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.238176Z",
     "start_time": "2021-08-31T16:33:44.905Z"
    }
   },
   "outputs": [],
   "source": [
    "DEN_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1111157e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.238956Z",
     "start_time": "2021-08-31T16:33:44.908Z"
    }
   },
   "outputs": [],
   "source": [
    "1.7*40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15d522e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.239749Z",
     "start_time": "2021-08-31T16:33:44.911Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from numpy import array\n",
    "import sys\n",
    "sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "from SingleSatelliteFlythrough import SingleModelFlythrough\n",
    "\n",
    "sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "from SatelliteFlythrough import ModelFlythrough\n",
    "\n",
    "\n",
    "model          = 'TIEGCM'\n",
    "file_dir       = '/data/data_geodyn/atmos_models_data/tiegcm/2003/'\n",
    "variable_list  = ['rho','psi_O2', 'psi_O', 'psi_N2', 'psi_He', 'T_n']\n",
    "c3             = DEN_csv['Height (meters)'].astype(float)[:]\n",
    "sat_time       = DEN_csv['sattime_utctimestamp'].astype(float)[:]\n",
    "c1             = DEN_csv['Lon'].astype(float)[:]\n",
    "c2             = DEN_csv['Lat'].astype(float)[:]\n",
    "coord_type      = 'SPH'  # zach left this as sph because need lon to be mapped to -180-180   \n",
    "coord_grid      = 'sph'    \n",
    "high_res       = 1.\n",
    "verbose        = False  \n",
    "csv_output      ='' \n",
    "plot_output     =''\n",
    " \n",
    "results = ModelFlythrough(model, file_dir, variable_list, sat_time, c1, c2, c3, \n",
    "                    coord_type, coord_grid, high_res=20., verbose=False, \n",
    "                    csv_output='', plot_output='')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c420f7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T22:19:57.927423Z",
     "start_time": "2021-08-27T22:03:22.293Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ddbbc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eb1ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8891ff83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12525352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c83ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d24b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd6da2f3",
   "metadata": {},
   "source": [
    "## Do some tests to make sure Kamodo Extrapolation is working\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030b476c",
   "metadata": {},
   "source": [
    "### Kamodo full satellite flythrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a6881",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.240613Z",
     "start_time": "2021-08-31T16:33:44.924Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c647de6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.241410Z",
     "start_time": "2021-08-31T16:33:44.928Z"
    }
   },
   "outputs": [],
   "source": [
    "type(DEN_csv['Lon'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a3a04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.242312Z",
     "start_time": "2021-08-31T16:33:44.931Z"
    }
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import numpy as np \n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def read_tiegcm( filename, variables):\n",
    "    ''' This function reads the TIEGCM .nc files and saves the given input variables to a dictionary.\n",
    "        The breakloop feature is here so that if the file doesn't exist the code can still continue if placed in a loop.'''\n",
    "    status = os.path.exists(filename)\n",
    " \n",
    "    if status == True:\n",
    "        data = {}\n",
    "        for i, var_names in enumerate(variables):\n",
    "            ncid =  Dataset(filename,\"r+\", format=\"NETCDF4\")# filename must be a string\n",
    "            varData = ncid.variables\n",
    "            data[var_names] = np.array(varData[var_names])  \n",
    "    elif status == False:\n",
    "        print('No File Found', filename )\n",
    "        breakloop = True\n",
    "        data = 0\n",
    "        return( data , breakloop)\n",
    "    breakloop = False\n",
    "    return(data,breakloop )\n",
    "\n",
    "\n",
    "def find_modelgrid_base_index(TIEGCM, lon_sat, lat_sat, time_sat):\n",
    "    \"\"\" \n",
    "    Interpolation function: (3 / 5)\n",
    "\n",
    "    This function locates the grid points that make up thr square surrounding out desired point.\n",
    "    \"\"\"\n",
    "\n",
    "    lon_start = -180 # first longitude point of the model grid (deg)\n",
    "    dlon = 5  # difference between adjacent longitude grid points (deg)\n",
    "    index_lon0 = int(np.mod(np.floor( (lon_sat - lon_start )/dlon ), 72 ) ) \n",
    "\n",
    "\n",
    "    lat_start = -87.5 # first longitude point of the model grid (deg)\n",
    "    dlat = 5 # difference between adjacent longitude grid points (deg)\n",
    "    index_lat0 = int(np.mod(np.floor( (lat_sat - lat_start)/dlat ), 36 ) )\n",
    "\n",
    "    time_start = 0 # first longitude point of the model grid (deg)\n",
    "    dtime = 1 # difference between adjacent longitude grid points (deg)\n",
    "    index_time = int((np.mod(np.floor( (time_sat - time_start)/dtime ), 24 ) )) -1\n",
    "\n",
    "    if index_lon0 == 71:\n",
    "        index_lon1 = 0\n",
    "    else:\n",
    "        index_lon1 = index_lon0 + 1\n",
    "\n",
    "\n",
    "    if index_lat0 >= 35 :\n",
    "        index_lat1 = 35\n",
    "        NPole_Flag = True\n",
    "        SPole_Flag = False \n",
    "\n",
    "    elif index_lat0 <= 0: \n",
    "        index_lat1 = 0\n",
    "        SPole_Flag = True\n",
    "        NPole_Flag = False\n",
    "    else: \n",
    "        index_lat1 = index_lat0 + 1\n",
    "        NPole_Flag = False \n",
    "        SPole_Flag = False \n",
    "\n",
    "\n",
    "    return(index_lon0, index_lat0, index_lon1, index_lat1, index_time, NPole_Flag, SPole_Flag )\n",
    "\n",
    "\n",
    "def DEN_and_ZG_vertprofs(TIEGCM, lon_sat, lat_sat, time_sat, param):\n",
    "    '''\n",
    "    Interpolation function: (2 / 5)\n",
    "\n",
    "    This function finds the vertical profiles of the four grid points around a desired point.\n",
    "    '''\n",
    "    \n",
    "    #### First we find the four grid points:\n",
    "    (indexlon0, \n",
    "    indexlat0, \n",
    "    indexlon1, \n",
    "    indexlat1, \n",
    "    indexut, \n",
    "    NPole_Flag, \n",
    "    SPole_Flag) = find_modelgrid_base_index(TIEGCM, lon_sat, lat_sat, time_sat)\n",
    "    grid_vals = pd.DataFrame(data = {'lon0' : TIEGCM['lon'][indexlon0] ,\\\n",
    "                                 'lonindex0': indexlon0 ,\\\n",
    "                                 'lon1'     :TIEGCM['lon'][indexlon1] ,\\\n",
    "                                 'lonindex1':indexlon1 ,\\\n",
    "                                 'lat0'     :TIEGCM['lat'][indexlat0] ,\\\n",
    "                                 'latindex0':indexlat0 ,\\\n",
    "                                 'lat1'     :TIEGCM['lat'][indexlat1] ,\\\n",
    "                                 'latindex1':indexlat1  }, index=[0])\n",
    "#     print('UT index',indexut)\n",
    "#     print('UT value',TIEGCM['ut'][indexut])\n",
    "#     print()\n",
    "#     print('Lon0 index',indexlon0)\n",
    "#     print('Lon0 value',TIEGCM['lon'][indexlon0])\n",
    "#     print('Lon1 index',indexlon1)\n",
    "#     print('Lon1 value',TIEGCM['lon'][indexlon1])\n",
    "#     print()\n",
    "#     print('Lat0 index',indexlat0)\n",
    "#     print('Lat0 value',TIEGCM['lat'][indexlat0])\n",
    "#     print('Lat1 index',indexlat1)\n",
    "#     print('Lat1 value',TIEGCM['lat'][indexlat1])\n",
    "    \n",
    "#     print('alt index',indexut)\n",
    "#     print('alt value',TIEGCM['ut'][indexut])\n",
    "\n",
    "    DEN_prof00 = TIEGCM[param][indexut, :-1, indexlat0, indexlon0]\n",
    "    DEN_prof10 = TIEGCM[param][indexut, :-1, indexlat1, indexlon0]\n",
    "    DEN_prof01 = TIEGCM[param][indexut, :-1, indexlat0, indexlon1]\n",
    "    DEN_prof11 = TIEGCM[param][indexut, :-1, indexlat1, indexlon1]\n",
    "    \n",
    "\n",
    "    ZG_prof00 = TIEGCM['ZG'][indexut, :-1, indexlat0, indexlon0]\n",
    "    ZG_prof10 = TIEGCM['ZG'][indexut, :-1, indexlat1, indexlon0]\n",
    "    ZG_prof01 = TIEGCM['ZG'][indexut, :-1, indexlat0, indexlon1]\n",
    "    ZG_prof11 = TIEGCM['ZG'][indexut, :-1, indexlat1, indexlon1]\n",
    "\n",
    "    DEN_df = pd.DataFrame(data = {'00' :DEN_prof00 ,\\\n",
    "                                  '10' :DEN_prof10 ,\\\n",
    "                                  '01' :DEN_prof01 ,\\\n",
    "                                  '11' :DEN_prof11 ,\\\n",
    "                                })\n",
    "    ZG_df = pd.DataFrame(data = {'00' :ZG_prof00 ,\\\n",
    "                                  '10' :ZG_prof10 ,\\\n",
    "                                  '01' :ZG_prof01 ,\\\n",
    "                                  '11' :ZG_prof11 ,\\\n",
    "                                })\n",
    "    return(DEN_df, ZG_df, grid_vals)\n",
    "\n",
    "\n",
    "\n",
    "def interp_DENSITY_to_altitude(DEN_df, ZG_df, height_sat):\n",
    "    '''\n",
    "    Interpolation function: (4 / 5)\n",
    "\n",
    "    This function interpolates Density in the log space then converts it back'''\n",
    "    density_surf_at_height_sat = np.zeros(np.size(ZG_df.columns))\n",
    "    i = 0\n",
    "    for col in ZG_df.columns:\n",
    "        xp = ZG_df[col][:].values*1e-5\n",
    "        fp = DEN_df[col][:].values\n",
    "        xval = height_sat\n",
    "        density_surf_at_height_sat[i] =  np.exp( np.interp(xval, xp, np.log(fp))  )\n",
    "        i += 1\n",
    "    return(density_surf_at_height_sat)\n",
    "\n",
    "\n",
    "\n",
    "def interp_param_to_altitude(df, ZG_df, height_sat):\n",
    "    \n",
    "    '''\n",
    "    Interpolation function: (5 / 5)\n",
    "\n",
    "    This function interpolates all other parameters (not density) using linear interpolation\n",
    "    '''\n",
    "\n",
    "    param_surf_at_height_sat = np.zeros(np.size(ZG_df.columns))\n",
    "    i = 0\n",
    "    for col in ZG_df.columns:\n",
    "        xp = ZG_df[col][:].values*1e-5\n",
    "        fp = df[col][:].values\n",
    "        xval = height_sat\n",
    "        param_surf_at_height_sat[i] =  np.interp(xval, xp, fp)  \n",
    "        i += 1\n",
    "    return(param_surf_at_height_sat)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def interpolate_tiegcm(TIEGCM, lon_sat, lat_sat, time_sat, height_sat, param):\n",
    "    '''\n",
    "    Interpolation function: (1 / 5)\n",
    "    \n",
    "    This function finds the interpolated value of a TIEGCM parameter.  \n",
    "    Interpolated to a desired lon,lat,alt\n",
    "    '''\n",
    "    \n",
    "    # Find the vertical profiles of the four grid points making up the grid square around your desired point.\n",
    "#     print('time_sat:', time_sat)\n",
    "    df, ZG_df, grid_vals = DEN_and_ZG_vertprofs(TIEGCM, lon_sat, lat_sat, time_sat, param)\n",
    "    \n",
    "    if param == 'DEN':\n",
    "        param_surf_at_height_sat = interp_DENSITY_to_altitude(df, ZG_df, height_sat)\n",
    "    else:\n",
    "        param_surf_at_height_sat = interp_param_to_altitude(df, ZG_df, height_sat)\n",
    "\n",
    "\n",
    "    xval = lon_sat\n",
    "\n",
    "    x_lon = [grid_vals['lon0'][0], grid_vals['lon1'][0]]\n",
    "    f_den0 = [param_surf_at_height_sat[0], param_surf_at_height_sat[1]]\n",
    "    interp_lon0 =   np.interp(xval, x_lon, f_den0  )\n",
    "\n",
    "    f_den1 = [param_surf_at_height_sat[2], param_surf_at_height_sat[3]]\n",
    "    interp_lon1 =   np.interp(xval, x_lon, f_den1  )\n",
    "\n",
    "    final_interped_value = interp_lon0 + ((lat_sat - grid_vals['lat0'][0]) / (grid_vals['lat1'][0] - grid_vals['lat0'][0]))*(interp_lon1 - interp_lon0)\n",
    "\n",
    "    return(final_interped_value)\n",
    "\n",
    "\n",
    "# def gravity(h):\n",
    "#     \"\"\"For h in same units as R_e  (computes in cm as artifact of old code)\"\"\"\n",
    "#     return g_0*pow(R_e/(R_e + h), 2)\n",
    "\n",
    "\n",
    "\n",
    "# def interp_to_altitude(DEN_df, ZG_df, height_sat):\n",
    "#     density_surf_at_height_sat = np.zeros(np.size(ZG_df.columns))\n",
    "#     i = 0\n",
    "#     for col in ZG_df.columns:\n",
    "#         xp = ZG_df[col][:].values*1e-5\n",
    "#         fp = DEN_df[col][:].values\n",
    "#         xval = height_sat\n",
    "#         density_surf_at_height_sat[i] =  np.exp( np.interp(xval, xp, np.log(fp))  )\n",
    "#         i += 1\n",
    "#     return(density_surf_at_height_sat)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def interp_lon_lat(TIEGCM, lon_sat, lat_sat, time_sat, height_sat, param):\n",
    "#     DEN_df, ZG_df, grid_vals = DEN_and_ZG_vertprofs(TIEGCM, lon_sat, lat_sat, time_sat, param)\n",
    "#     density_surf_at_height_sat = interp_to_altitude(DEN_df, ZG_df, height_sat)\n",
    "\n",
    "#     xval = lon_sat\n",
    "\n",
    "#     x_lon = [grid_vals['lon0'][0], grid_vals['lon1'][0]]\n",
    "#     f_den0 = [density_surf_at_height_sat[0], density_surf_at_height_sat[1]]\n",
    "#     interp_lon0 =   np.interp(xval, x_lon, f_den0  )\n",
    "\n",
    "    \n",
    "#     f_den1 = [density_surf_at_height_sat[2], density_surf_at_height_sat[3]]\n",
    "#     interp_lon1 =   np.interp(xval, x_lon, f_den1  )\n",
    "    \n",
    "#     density = interp_lon0 + ((lat_sat - grid_vals['lat0'][0]) / (grid_vals['lat1'][0] - grid_vals['lat0'][0]))*(interp_lon1 - interp_lon0)\n",
    "# #     print(density)\n",
    "#     return(density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a1580a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.243123Z",
     "start_time": "2021-08-31T16:33:44.934Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from numpy import array\n",
    "import sys\n",
    "sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "from SingleSatelliteFlythrough import SingleModelFlythrough\n",
    "\n",
    "sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "from SatelliteFlythrough import ModelFlythrough\n",
    "\n",
    "\n",
    "model          = 'TIEGCM'\n",
    "file_dir       = '/data/data_geodyn/atmos_models_data/tiegcm/2003/'\n",
    "variable_list  = ['rho','psi_O2', 'psi_O', 'psi_N2', 'psi_He', 'T_n']\n",
    "c3             = DEN_csv['Height (meters)'].astype(float)[:]\n",
    "sat_time       = DEN_csv['sattime_utctimestamp'].astype(float)[:]\n",
    "c1             = DEN_csv['Lon'].astype(float)[:]\n",
    "c2             = DEN_csv['Lat'].astype(float)[:]\n",
    "coord_type      = 'SPH'  # zach left this as sph because need lon to be mapped to -180-180   \n",
    "coord_grid      = 'sph'    \n",
    "high_res       = 1.\n",
    "verbose        = False  \n",
    "csv_output      ='' \n",
    "plot_output     =''\n",
    "\n",
    "\n",
    "results = ModelFlythrough(model, file_dir, variable_list, sat_time, c1, c2, c3, \n",
    "                    coord_type, coord_grid, high_res=20., verbose=False, \n",
    "                    csv_output='', plot_output='')\n",
    "\n",
    "# print(results['c3'])\n",
    "# print( results['rho'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06150a6",
   "metadata": {},
   "source": [
    "### Read Maually by directly indexing TIEGCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d1701f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.244222Z",
     "start_time": "2021-08-31T16:33:44.938Z"
    }
   },
   "outputs": [],
   "source": [
    "variables =['lon','lat' ,'ut','ilev','f107d','f107a','Kp', 'O2', 'O1', 'N2', 'HE', 'DEN', 'TN', 'Z', 'ZG', 'ZGMID']\n",
    "MANUAL_list = []\n",
    "\n",
    "alts = np.linspace(100, 1000, num=500)\n",
    "\n",
    "for i,val in enumerate(DEN_csv['sattime_utctimestamp'].astype(float)[:500]) :  #calls_csv['Num'][:2]):\n",
    "    kamodo_program_path = '/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/SingleSatelliteFlythrough.py'\n",
    "    model     =  \"4\" #'4' #'TIEGCM'\n",
    "    file_dir  = '/data/data_geodyn/atmos_models_data/tiegcm/2003/'\n",
    "    sat_time1 = DEN_csv['YYMMDD'][i]  #str(calls_csv['YYMMDD'][i])   \n",
    "    sat_time2 = DEN_csv['HHMMSS'][i]  #1068897600         #str(calls_csv['HHMMSS'][i])   \n",
    "    c1        = DEN_csv['Lon'][i]  #'100.0'         #str(calls_csv['lon'][i])    # lon\n",
    "    c2        = DEN_csv['Lat'][i]  #'32.5'         #str(calls_csv['lat'][i])   # lat\n",
    "    c3        = DEN_csv['Height (meters)'][i]  #'400'   # alt\n",
    "    \n",
    "    tiegcm_file = '/data/data_geodyn/atmos_models_data/tiegcm/' + '%d/' % 2003  +'s%03d.nc' % 319   \n",
    "    tiegcm = read_tiegcm(tiegcm_file, variables)\n",
    "    tiegcm  = tiegcm[0]\n",
    "\n",
    "    lon  = float(c1)\n",
    "    lat  = float(c2)\n",
    "    alt  = float(c3)\n",
    "    time_hour = datetime.strptime(sat_time1+sat_time2, '%y%m%d%H%M%S').hour\n",
    "    MANUAL_list.append(interpolate_tiegcm(tiegcm, lon, lat, time_hour, alt, 'DEN'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72c2c8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.245143Z",
     "start_time": "2021-08-31T16:33:44.942Z"
    }
   },
   "outputs": [],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9942302d",
   "metadata": {},
   "source": [
    "### Read MSIS2 with DEN_csv indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5f6bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T18:37:46.543667Z",
     "start_time": "2021-08-25T18:37:46.497714Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd13e1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.245980Z",
     "start_time": "2021-08-31T16:33:44.948Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import pandas as pd\n",
    "msisin_den_file = '/data/data_geodyn/results/st/msis2/msis2_acceloffSLR_kamodo_interface/DENSITY/' + \"st031109_2wk.goco05s_msisin\"\n",
    "\n",
    "DEN1_csv = pd.read_csv(msisin_den_file, \n",
    "                    skiprows = 1, \n",
    "                    names = ['IYYDDD',\n",
    "                             'IYR',\n",
    "                              'DAY',\n",
    "                             'UTSEC',\n",
    "                             'ALTKM',\n",
    "                             'GLAT',\n",
    "                             'GLON',\n",
    "                             'STLOC', \n",
    "                             'AVGFLX',\n",
    "                             'FLUX',\n",
    "                             'AP1',\n",
    "                             'AP2',\n",
    "                             'AP3',\n",
    "                             'AP4',\n",
    "                             'AP5',\n",
    "                             'AP6',\n",
    "                             'AP7',\n",
    "                            ],\n",
    "                    sep = '\\s+',\n",
    "                    )\n",
    "\n",
    "\n",
    "DEN1_csv['Date'] = (pd.to_datetime('0'+ ((DEN1_csv['IYR'].astype(int).astype(str))),  format='%y') \n",
    "                    +  pd.to_timedelta(DEN1_csv['DAY'], unit='days'))\n",
    "\n",
    "\n",
    "\n",
    "SWI_option = [1.0]*25\n",
    "SWI_option[8] = -1.0\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pymsis import msis\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "msis2_df= pd.DataFrame(data={'Rho'   :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "#                               'N2'    :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "#                               'O2'    :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "#                               'O'     :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "#                               'He'    :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "#                               'H'     :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "#                               'Ar'    :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "#                               'N'     :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "#                               'AnomO' :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "#                               'NO'    :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "#                               'Temp'  :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "                            })\n",
    "\n",
    "\n",
    "for index, row in DEN1_csv[:500].iterrows():\n",
    "\n",
    "    lon = DEN_csv['Lon'][index] #row['GLON']\n",
    "    lat = DEN_csv['Lat'][index] #row['GLAT']\n",
    "    alts = DEN_csv['Height (meters)'][index] #row['ALTKM']\n",
    "    f107 = DEN_csv['flux_daily'][index] # row['FLUX'] \n",
    "    f107a = DEN_csv['flux_avg'][index] # row['AVGFLX']\n",
    "\n",
    "    aps = [[row['AP1'],row['AP2'],row['AP3'],row['AP4'],row['AP5'],row['AP6'],row['AP7']]]\n",
    "    date = DEN_csv['Date'][index]  #row['Date']\n",
    "\n",
    "    msis_data2 =  msis.run(date, lon, lat, alts, f107, f107a, aps, version=2,  options = SWI_option)\n",
    "    msis_data2  = np.squeeze(msis_data2)\n",
    "\n",
    "\n",
    "    msis2_df.loc[index, 'Rho'] = msis_data2[0]\n",
    "#     msis2_df.loc[index, 'N2'] = msis_data2[1]\n",
    "#     msis2_df.loc[index, 'O2'] = msis_data2[2]\n",
    "#     msis2_df.loc[index, 'O'] = msis_data2[3]\n",
    "#     msis2_df.loc[index, 'He'] = msis_data2[4]\n",
    "#     msis2_df.loc[index, 'H'] = msis_data2[5]\n",
    "#     msis2_df.loc[index, 'Ar'] = msis_data2[6]\n",
    "#     msis2_df.loc[index, 'N'] = msis_data2[7]\n",
    "#     msis2_df.loc[index, 'AnomO'] = msis_data2[8]\n",
    "#     msis2_df.loc[index, 'NO'] = msis_data2[9]\n",
    "#     msis2_df.loc[index, 'Temp'] = msis_data2[10]\n",
    "    msis2_df.loc[index, 'Date'] = row['Date']\n",
    "\n",
    "#     return(msis00_df, msis2_df)\n",
    "\n",
    "#################### MAKE PLOT ####################\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot, iplot\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "config = dict({\n",
    "                'displayModeBar': True,\n",
    "                'responsive': False,\n",
    "                'staticPlot': False,\n",
    "                'displaylogo': False,\n",
    "                'showTips': False,\n",
    "                })\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1,\n",
    "                   )\n",
    "fig.add_trace(go.Scatter(x=msis2_df['Date'][:500],\n",
    "                         y=msis2_df['Rho'][:500],\n",
    "                         name= 'MSIS2 direct read',\n",
    "                         mode='markers',\n",
    "                         marker=dict(size=8)),\n",
    "                         )\n",
    "fig.add_trace(go.Scatter(y=DEN_csv['rho (kg/m**3)'][:500],\n",
    "                         x=DEN_csv['Date'][:500],\n",
    "                         name= 'Density File (GEODYN_msis2)',\n",
    "                         mode='markers',\n",
    "                        marker=dict(size=4)),\n",
    "                         )\n",
    "                        \n",
    "# fig.add_trace(go.Scatter(y=results['max_height']*1e-3, x=results['rho'], mode='markers'))\n",
    "\n",
    "fig.update_yaxes(type=\"log\", exponentformat= 'power', row=1, col=1, title ='Den')\n",
    "fig.update_xaxes(title ='Date')\n",
    "fig.update_layout(title=\"MSIS2 Direct Read, Comparison of Values\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a77b5ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.246775Z",
     "start_time": "2021-08-31T16:33:44.951Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot, iplot\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "config = dict({\n",
    "                'displayModeBar': True,\n",
    "                'responsive': False,\n",
    "                'staticPlot': False,\n",
    "                'displaylogo': False,\n",
    "                'showTips': False,\n",
    "                })\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1,\n",
    "                   )\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(y=results['rho'],\n",
    "                         x=results['utc_time'],\n",
    "                         name= 'Kamodo w/ Extrapolation',\n",
    "                         mode='markers+lines',\n",
    "                         ),\n",
    "                         )\n",
    "\n",
    "fig.add_trace(go.Scatter(x=DEN_csv['sattime_utctimestamp'][:500],\n",
    "                         y=msis2_df['Rho'][:500]*1e-3,\n",
    "                         name= 'MSIS2 direct read',\n",
    "                         mode='markers',\n",
    "                         marker=dict(size=3)),\n",
    "                         )\n",
    "\n",
    "# fig.add_trace(go.Scatter(y=results['max_height']*1e-3, x=results['rho'], mode='markers'))\n",
    "\n",
    "fig.update_yaxes(type=\"log\", exponentformat= 'power', row=1, col=1, title ='Density [g/cm^3]')\n",
    "fig.update_xaxes(type=\"linear\", exponentformat= 'power', row=1, col=1, title ='timestamp')\n",
    "fig.update_layout(title=\"(Orig Altitude) Comparing the Densities across the model options\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedc21f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-24T20:38:36.425542Z",
     "start_time": "2021-08-24T20:38:36.336370Z"
    }
   },
   "source": [
    "### Run the Kamodo and MSIS runs at a lower more reasonable altitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaa9b1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.247539Z",
     "start_time": "2021-08-31T16:33:44.954Z"
    }
   },
   "outputs": [],
   "source": [
    "subtract_alt = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59689126",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.248378Z",
     "start_time": "2021-08-31T16:33:44.958Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from numpy import array\n",
    "import sys\n",
    "sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "from SingleSatelliteFlythrough import SingleModelFlythrough\n",
    "\n",
    "sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "from SatelliteFlythrough import ModelFlythrough\n",
    "\n",
    "\n",
    "model          = 'TIEGCM'\n",
    "file_dir       = '/data/data_geodyn/atmos_models_data/tiegcm/2003/'\n",
    "variable_list  = ['rho','psi_O2', 'psi_O', 'psi_N2', 'psi_He', 'T_n']\n",
    "c3             = DEN_csv['Height (meters)'].astype(float)[:500]-subtract_alt\n",
    "sat_time       = DEN_csv['sattime_utctimestamp'].astype(float)[:500]\n",
    "c1             = DEN_csv['Lon'].astype(float)[:500]\n",
    "c2             = DEN_csv['Lat'].astype(float)[:500]\n",
    "coord_type      = 'SPH'  # zach left this as sph because need lon to be mapped to -180-180   \n",
    "coord_grid      = 'sph'    \n",
    "high_res       = 1.\n",
    "verbose        = False  \n",
    "csv_output      ='' \n",
    "plot_output     =''\n",
    "\n",
    "\n",
    "results = ModelFlythrough(model, file_dir, variable_list, sat_time, c1, c2, c3, \n",
    "                    coord_type, coord_grid, high_res=20., verbose=False, \n",
    "                    csv_output='', plot_output='')\n",
    "\n",
    "# print(results['c3'])\n",
    "# print( results['rho'])msisin_den_file = '/data/data_geodyn/results/st/msis2/msis2_acceloffSLR_kamodo_interface/DENSITY/' + \"st031109_2wk.goco05s_msisin\"\n",
    "\n",
    "DEN1_csv = pd.read_csv(msisin_den_file, \n",
    "                    skiprows = 1, \n",
    "                    names = ['IYYDDD',\n",
    "                             'IYR',\n",
    "                              'DAY',\n",
    "                             'UTSEC',\n",
    "                             'ALTKM',\n",
    "                             'GLAT',\n",
    "                             'GLON',\n",
    "                             'STLOC', \n",
    "                             'AVGFLX',\n",
    "                             'FLUX',\n",
    "                             'AP1',\n",
    "                             'AP2',\n",
    "                             'AP3',\n",
    "                             'AP4',\n",
    "                             'AP5',\n",
    "                             'AP6',\n",
    "                             'AP7',\n",
    "                            ],\n",
    "                    sep = '\\s+',\n",
    "                    )\n",
    "\n",
    "\n",
    "DEN1_csv['Date'] = (pd.to_datetime('0'+ ((DEN1_csv['IYR'].astype(int).astype(str))),  format='%y') \n",
    "                    +  pd.to_timedelta(DEN1_csv['DAY'], unit='days'))\n",
    "\n",
    "\n",
    "\n",
    "SWI_option = [1.0]*25\n",
    "SWI_option[8] = -1.0\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pymsis import msis\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "msis2_df= pd.DataFrame(data={'Rho'   :np.ones(np.shape(DEN1_csv['Date']))*np.nan,\n",
    "                            })\n",
    "\n",
    "for index, row in DEN1_csv[:500].iterrows():\n",
    "\n",
    "    lon = DEN_csv['Lon'][index] #row['GLON']\n",
    "    lat = DEN_csv['Lat'][index] #row['GLAT']\n",
    "    alts = DEN_csv['Height (meters)'][index]-subtract_alt\n",
    "    f107 = DEN_csv['flux_daily'][index] # row['FLUX'] \n",
    "    f107a = DEN_csv['flux_avg'][index] # row['AVGFLX']\n",
    "\n",
    "    aps = [[row['AP1'],row['AP2'],row['AP3'],row['AP4'],row['AP5'],row['AP6'],row['AP7']]]\n",
    "    date = DEN_csv['Date'][index]  #row['Date']\n",
    "\n",
    "    msis_data2 =  msis.run(date, lon, lat, alts, f107, f107a, aps, version=2,  options = SWI_option)\n",
    "    msis_data2  = np.squeeze(msis_data2)\n",
    "\n",
    "\n",
    "    msis2_df.loc[index, 'Rho'] = msis_data2[0]\n",
    "    msis2_df.loc[index, 'Date'] = row['Date']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf2cb1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.249170Z",
     "start_time": "2021-08-31T16:33:44.961Z"
    }
   },
   "outputs": [],
   "source": [
    "results['c3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da66689",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.249988Z",
     "start_time": "2021-08-31T16:33:44.964Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot, iplot\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "config = dict({\n",
    "                'displayModeBar': True,\n",
    "                'responsive': False,\n",
    "                'staticPlot': False,\n",
    "                'displaylogo': False,\n",
    "                'showTips': False,\n",
    "                })\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1,\n",
    "                   )\n",
    "\n",
    "fig.add_trace(go.Scatter(y=results['rho'],\n",
    "                         x=results['utc_time'],\n",
    "                         name= 'Kamodo w/ Extrapolation',\n",
    "                         mode='markers+lines',\n",
    "                         ),\n",
    "                         )\n",
    "fig.add_trace(go.Scatter(x=DEN_csv['sattime_utctimestamp'][:500],\n",
    "                         y=msis2_df['Rho'][:500]*1e-3,\n",
    "                         name= 'MSIS2 direct read',\n",
    "                         mode='markers',\n",
    "                         marker=dict(size=3)),\n",
    "                         )\n",
    "\n",
    "fig.update_yaxes(type=\"log\", exponentformat= 'power', row=1, col=1, title ='Density [g/cm^3]')\n",
    "fig.update_xaxes(type=\"linear\", exponentformat= 'power', row=1, col=1, title ='timestamp')\n",
    "fig.update_layout(title=\"(LOWER ALTITUDE by \"+str(subtract_alt)+\"km) Comparing the Densities across the model options\")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "#===================================================================================================\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot, iplot\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "config = dict({\n",
    "                'displayModeBar': True,\n",
    "                'responsive': False,\n",
    "                'staticPlot': False,\n",
    "                'displaylogo': False,\n",
    "                'showTips': False,\n",
    "                })\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1,\n",
    "                   )\n",
    "\n",
    "fig.add_trace(go.Scatter(y=results['c3'],\n",
    "                         x=results['rho'],\n",
    "                         name= 'Kamodo w/ Extrapolation',\n",
    "                         mode='markers+lines',\n",
    "                         ),\n",
    "                         )\n",
    "fig.add_trace(go.Scatter(y=DEN_csv['Height (meters)'][:500]-subtract_alt,\n",
    "                         x=msis2_df['Rho'][:500]*1e-3,\n",
    "                         name= 'MSIS2 direct read',\n",
    "                         mode='markers',\n",
    "                         marker=dict(size=3)),\n",
    "                         )\n",
    "\n",
    "fig.update_yaxes(type=\"log\", exponentformat= 'power', row=1, col=1, title ='Altitude')\n",
    "fig.update_xaxes(type=\"linear\", exponentformat= 'power', row=1, col=1, title ='Density')\n",
    "fig.update_layout(title=\"(LOWER ALTITUDE by  \"+str(subtract_alt)+\"km) Comparing the Densities across the model options\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d39c93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.250767Z",
     "start_time": "2021-08-31T16:33:44.967Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fb6cca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-24T19:18:00.916654Z",
     "start_time": "2021-08-24T19:18:00.882526Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555f688e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.251545Z",
     "start_time": "2021-08-31T16:33:44.972Z"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.semilogy(results['c3'] ,results['rho']  ,'.', ms=6)\n",
    "# # plt.semilogy(DEN_csv['sattime_utctimestamp'][:500] ,DEN_csv['rho (kg/m**3)'][:500],'.', ms=3)\n",
    "# plt.semilogy(alts ,MANUAL_list,'.', ms=3)\n",
    "# plt.legend(['Kamodo', 'manual'])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac96ab2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.252335Z",
     "start_time": "2021-08-31T16:33:44.974Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(results['utc_time'] ,results['c1'] ,'.', ms=6)\n",
    "plt.plot(DEN_csv['sattime_utctimestamp'][:500] ,DEN_csv['Lon'][:500],'.', ms=3)\n",
    "plt.legend(['Kamodo', 'DEN_csv'])\n",
    "plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(results['utc_time'] ,results['c2'],'.',ms=6 )\n",
    "plt.plot(DEN_csv['sattime_utctimestamp'][:500] ,DEN_csv['Lat'][:500],'.',ms=3)\n",
    "plt.legend(['Kamodo', 'DEN_csv'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(results['utc_time'] ,results['c3'],'.',ms=6 )\n",
    "plt.plot(DEN_csv['sattime_utctimestamp'][:500] ,DEN_csv['Height (meters)'][:500],'.',ms=3)\n",
    "plt.legend(['Kamodo', 'DEN_csv'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710a2d69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-24T20:24:04.976062Z",
     "start_time": "2021-08-24T20:18:35.417Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed55b165",
   "metadata": {},
   "source": [
    "## The below proves that we need to get the full satellite flythrough working for TIEGCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851b0286",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.253129Z",
     "start_time": "2021-08-31T16:33:44.979Z"
    }
   },
   "outputs": [],
   "source": [
    "# sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e2ea75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.259235Z",
     "start_time": "2021-08-31T16:33:44.982Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# from numpy import array\n",
    "# import sys\n",
    "\n",
    "# KAMODO_list = []\n",
    "\n",
    "\n",
    "# for i,val in enumerate(DEN_csv['Elapsed Secs'][:5]) :  #calls_csv['Num'][:2]):\n",
    "#     kamodo_program_path = '/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/SingleSatelliteFlythrough.py'\n",
    "#     model     =  \"4\" #'4' #'TIEGCM'\n",
    "#     file_dir  = '/data/data_geodyn/atmos_models_data/tiegcm/2003/'\n",
    "#     var_list  = \"['rho']\"\n",
    "#     dz_list   = \"['0']\"\n",
    "#     coordtype = 'SPH'     \n",
    "#     coordgrid = 'sph'    \n",
    "#     high_res  = '20.'\n",
    "#     sat_time1 = str(DEN_csv['YYMMDD'][i])  #\"031115\" #  \n",
    "#     sat_time2 = str(DEN_csv['HHMMSS'][i])  #\"120000\" #1068897600        \n",
    "#     utc_time  = str(datetime.timestamp(datetime.strptime(sat_time1+sat_time2, '%y%m%d%H%M%S').replace(tzinfo=timezone.utc)))\n",
    "#     c1        = str(DEN_csv['Lon'][i]) #                         '100.0'         # lon\n",
    "#     c2        = str(DEN_csv['Lat'][i]) #                         '32.5'          # lat\n",
    "#     c3        = str(DEN_csv['Height (meters)'][i]) # '400'           # alt\n",
    "# #     print(c3)\n",
    "    \n",
    "#     sys.path.insert(0,'/data/geodyn_proj/interface_kamodo_geodyn/Kamodo/kamodo/flythrough/')\n",
    "#     from SingleSatelliteFlythrough import SingleModelFlythrough\n",
    "\n",
    "#     ### Prepare input to the satellite Flythrough\n",
    "#     if len(model)==1: \n",
    "#         model = int(model)\n",
    "#     temp_str = var_list[1:-1].replace(\"'\",\"\").replace(' ','').replace('\"','')\n",
    "#     variable_list = temp_str.split(',')   #['rho','N_n']\n",
    "#     if array([len(item) for item in variable_list]).max()==1:\n",
    "#         variable_list = array(variable_list, dtype=int)\n",
    "#     temp_str = dz_list[1:-1].replace(\"'\",\"\").replace(' ','').replace('\"','')\n",
    "#     dz = list(array(temp_str.split(','),dtype=int))  #[1,0], later treated as a boolean\n",
    "#     sat_time = float(utc_time) #1426637500.0\n",
    "#     c1 = float(c1) #x[R_E] or lon[deg]\n",
    "#     c2 = float(c2) #y[R_E] or lat[deg]\n",
    "#     c3 = float(c3) #z[R_E] or radius[R_E] or altitude[km]\n",
    "#     coord_type = coordtype  #'SPH', 'GDZ', etc\n",
    "#     if len(coord_type)==1: coord_type=int(coord_type)\n",
    "#     coord_grid = coordgrid  #'car' or 'sph'\n",
    "#     if len(coord_grid)==1: coord_type=int(coord_grid)\n",
    "#     high_res = 20.      \n",
    " \n",
    "#     results = SingleModelFlythrough(model, \n",
    "#                           file_dir, \n",
    "#                           variable_list,\n",
    "#                           dz, \n",
    "#                           sat_time, \n",
    "#                           c1, \n",
    "#                           c2, \n",
    "#                           c3, \n",
    "#                           coordtype, \n",
    "#                           coordgrid, \n",
    "#                           high_res)\n",
    "    \n",
    "#     KAMODO_list.append(results['rho'])\n",
    "\n",
    "    \n",
    "# print('KAMODO_list',KAMODO_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5165ab5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.259988Z",
     "start_time": "2021-08-31T16:33:44.986Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# from numpy import vectorize\n",
    "\n",
    "# @vectorize\n",
    "# def VecSingleModelFlythrough(model, file_dir, variable_list, dz, sat_time, c1, \n",
    "#                              c2, c3, coord_type, coord_grid, high_res):\n",
    "    \n",
    "#     results = SingleModelFlythrough(model, \n",
    "#                       file_dir, \n",
    "#                       variable_list,\n",
    "#                       dz, \n",
    "#                       sat_time, \n",
    "#                       c1, \n",
    "#                       c2, \n",
    "#                       c3, \n",
    "#                       coordtype, \n",
    "#                       coordgrid, \n",
    "#                       high_res)\n",
    "\n",
    "#     return(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02093255",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T16:33:55.260715Z",
     "start_time": "2021-08-31T16:33:44.990Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# results = VecSingleModelFlythrough(model*np.ones(np.size(list(DEN_csv['Lon'])),dtype=int  )  ,\n",
    "#                          file_dir ,\n",
    "#                          variable_list ,\n",
    "#                          dz*np.ones(np.size(list(DEN_csv['Lon'])),dtype=int),\n",
    "#                          sattime*np.ones(np.size(list(DEN_csv['Lon'])) ),\n",
    "#                          list(DEN_csv['Lon']),\n",
    "#                          list(DEN_csv['Lat']), \n",
    "#                          list(DEN_csv['Height (meters)']),\n",
    "#                          coord_type, coord_grid, high_res\n",
    "#                             )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
