{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "serial-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys  \n",
    "sys.path.insert(0, '/data/geodyn_proj/pygeodyn/utils_pygeodyn/')\n",
    "from pygeodyn_Read import pyGeodyn_Readers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deadly-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ A dictionary containing the run parameters ------  \n",
    "run_params = {} \n",
    "run_params['run_ID']           =  'Run_Arc_1'  \n",
    "run_params['arc']              =  ['030914_2wk']  \n",
    "run_params['satellite']        =  'starlette'  \n",
    "run_params['den_model']        =  'msis2'  \n",
    "run_params['empirical_accels'] =  False  \n",
    "run_params['SpecialRun_name']  =  '_developer_test'  \n",
    "run_params['options_in']       =  {'DRHODZ_update':True}  \n",
    "run_params['verbose']          =  False  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "crucial-legislation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \n",
      "     File path: \n",
      "     Loading /data/data_geodyn/results/st/msis2/msis2_acceloff/.../st030914_2wk.goco05s \n",
      "Adjusted_params:  18.078218698501587\n"
     ]
    }
   ],
   "source": [
    "#### first chnage the data path to be actual data\n",
    "run_params['SpecialRun_name']  =  ''  \n",
    "\n",
    "\n",
    "# Obj_read_geodyn = pyGeodyn_Readers(run_params)\n",
    "# Obj_read_geodyn.getData_All()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "selective-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "_iieout_filename = '/data/data_geodyn/results/st/msis2/msis2_acceloff/IIEOUT/st030914_2wk.goco05s'\n",
    "empirical_accels = False\n",
    "SATID = '7501001'\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "    #### Computer function\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "    #### modules for reading and converting data\n",
    "import linecache\n",
    "from datetime import datetime,timedelta\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "split-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "iieout_fwf = pd.read_fwf(_iieout_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-lecture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-alfred",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "limiting-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iieout_fwf\n",
    "\n",
    "# for i,val in iieout_fwf[:1000].iterrows():\n",
    "#     print(i,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-tampa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "spare-houston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huh\n",
      "huh\n",
      "huh\n",
      "huh\n",
      "huh\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (<ipython-input-41-d4e3a7b6acc1>, line 109)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-41-d4e3a7b6acc1>\"\u001b[0;36m, line \u001b[0;32m109\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# def read_adjustedparams_iieout(self):\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "#         \n",
    "#------------------- SECTION 1 ----------------------------------└──\n",
    "#--|\n",
    "#--|   Prepare to loop over the adjusted parameters\n",
    "#--|        ├── find the line numbers of adjusted parameters\n",
    "#--|        ├── determine number of iterations\n",
    "#--|        ├── Prepare the dictionary to be saved to\n",
    "#--|        ├── make a list of dates for the Time Dependent params (CD and GA)\n",
    "#--|--------------------------------------------------------------\n",
    "\n",
    "#### find the line numbers of all the adjustment parameters in the iieout file\n",
    "#### this simplifies/speds up the task of searching thru the IIEOUT file becuase it is VERY large        \n",
    "text_param_lists = ['0XPOS',\n",
    "                    '0YPOS',\n",
    "                    '0ZPOS',\n",
    "                    '0XVEL',\n",
    "                    '0YVEL',\n",
    "                    '0ZVEL',]\n",
    "####\n",
    "#### Identify the lines where there are adjusted parameters and\n",
    "#### Make a list of the satellites that have changed parameters in the file\n",
    "####    ├── Only add satID's to list if they are unique in the loop\n",
    "\n",
    "sat_list = []\n",
    "lines_params = [] \n",
    "with open(_iieout_filename, 'r') as f:\n",
    "    for line_no, line_text in enumerate(f):\n",
    "\n",
    "        if '0XPOS' in line_text :\n",
    "            print('huh')\n",
    "\n",
    "            lines_params.append(line_no)\n",
    "            if int(linecache.getline(_iieout_filename,line_no+1)[10:18]) not in sat_list:\n",
    "                sat_list.append(int(linecache.getline(_iieout_filename,line_no+1)[10:18]))\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "####                \n",
    "#### determine number of iterations in the run (when run converges)           \n",
    "with open(_iieout_filename, 'r') as f:\n",
    "    for line_no, line in enumerate(f):\n",
    "        if 'CONVERGENCE' in line:\n",
    "            line_text = line\n",
    "num_iters = float(line_text[39:42])-1\n",
    "\n",
    "#### Build the dictionary to be index based on iteration number   \n",
    "#### and initialize each iteration number to also be a dictionary\n",
    "text_GA_list = [\"0GA 9P 11t1\",\n",
    "                \"0GA 9P 12t1\",\n",
    "                \"0GA 9P 21t1\",\n",
    "                \"0GA 9P 22t1\",\n",
    "                \"0GA 9P 11t2\",\n",
    "                \"0GA 9P 12t2\",\n",
    "                \"0GA 9P 21t2\",\n",
    "                \"0GA 9P 22t2\",\n",
    "                    ]    \n",
    "SatMain_AdjustedParams = {}\n",
    "for i_iter,iterval in enumerate(np.arange(1, int(num_iters)+1)):\n",
    "    SatMain_AdjustedParams[iterval] = {}\n",
    "    for isat, satval in enumerate(sat_list):\n",
    "        if empirical_accels == True:\n",
    "            for iga, ga_val in enumerate(text_GA_list):\n",
    "                SatMain_AdjustedParams[iterval][satval] = {}\n",
    "                SatMain_AdjustedParams[iterval][satval]['0CD'] = {}\n",
    "                SatMain_AdjustedParams[iterval][satval][ga_val] = {}\n",
    "        else:\n",
    "            SatMain_AdjustedParams[iterval][satval] = {}\n",
    "            SatMain_AdjustedParams[iterval][satval]['0CD'] = {}\n",
    "break\n",
    "#### \n",
    "#### Make a list of the dates for the time dependent drag option\n",
    "#### First, determine how many time dependent outputs there are:\n",
    "line_no_1 = [] \n",
    "line_no_2 = [] \n",
    "with open(_iieout_filename, 'r') as f:\n",
    "    for line_no, line_text in enumerate(f):\n",
    "        if ' ARC #    1   PARAMETERS' in line_text :\n",
    "            line_no_1.append(line_no)\n",
    "        elif '        GLOBAL PARAMETER SUMMARY' in line_text:\n",
    "            line_no_2.append(line_no)\n",
    "####            \n",
    "parameter_summary_section_range = np.arange(line_no_1[0], line_no_2[0]+1)\n",
    "####\n",
    "#### Count how many Time dep Cd's were processed\n",
    "\n",
    "timedep_Cd_count = []\n",
    "for i,val in enumerate(parameter_summary_section_range):\n",
    "        line = linecache.getline(_iieout_filename,val)            \n",
    "        if 'CD' in line:\n",
    "            check_sat = int(line[24:32])\n",
    "            if check_sat == int(SATID):    \n",
    "                if 'T' in line:\n",
    "                    #### save the list of T##s and strip of whitespaces\n",
    "                    timedep_Cd_count.append(line[18:24].strip()) \n",
    "\n",
    "#### Loop through the IIE cards to find the\n",
    "#### date inputs for the time dependent Cd option \n",
    "#### First isolate the input card section:\n",
    "line_no_1 = [] \n",
    "line_no_2 = [] \n",
    "with open(_iieout_filename, 'r') as f:\n",
    "    for line_no, line_text in enumerate(f):\n",
    "        if 'GEODYN IIE VERSION' in line_text :\n",
    "            line_no_1.append(line_no)\n",
    "        if 'OBSERVATION RESIDUALS FOR ARC' in line_text:\n",
    "            line_no_2.append(line_no)\n",
    "            break\n",
    "#### Make a list of the dates as determined by the DRAG input cards:            \n",
    "card_inputs_range = np.arange(line_no_1[0], line_no_2[0]-100)\n",
    "timedep_Cd_dates = []\n",
    "for i,val in enumerate(card_inputs_range):\n",
    "        line = linecache.getline(_iieout_filename,val)            \n",
    "        if 'DRAG' in line:\n",
    "            check_sat = int(line[18:26])\n",
    "            #print(check_sat)\n",
    "            if check_sat == int(SATID):\n",
    "                #print(line[45:57])\n",
    "                timedep_Cd_dates.append(line[45:56].strip())\n",
    "date_timedep_cds = pd.to_datetime(timedep_Cd_dates[1:], format='%y%m%d%H%M%S')  #YYMMDDHHMMSS\n",
    "\n",
    "#         \n",
    "#------------------- SECTION 2 ----------------------------------\n",
    "#--|\n",
    "#--|   - Loop thru the saved linenumbers and save out the data \n",
    "#--|        ├── save all stats for each param taking advantage of the fixed width format\n",
    "#--|        ├── do again for each time dependent Cd\n",
    "#--|        ├── The line placement of CD is inconsistent and needs to be read in as every other...\n",
    "#--|        ├── if accelerations are on, do again for each GA \n",
    "#--|        ├──  \n",
    "#--|        └──\n",
    "#--|--------------------------------------------------------------\n",
    "\n",
    "#### Search through the full file for the key words in the above list (text_param_lists)\n",
    "#### save the line numbers where those keywords occur\n",
    "lines = []\n",
    "for text_param_adjusts in text_param_lists: \n",
    "    with open(_iieout_filename, 'r') as f:\n",
    "        for line_no, line_text in enumerate(f):\n",
    "            if text_param_adjusts in line_text:\n",
    "                lines.append(line_no) \n",
    "\n",
    "    #### Loop thru the lines saved above and grab the data occording to its name \n",
    "    #### and location in the file\n",
    "    #Sat_main_lines = [] \n",
    "    i=0\n",
    "    for il,val_lines in enumerate(lines):\n",
    "        check_sat = int(linecache.getline(_iieout_filename,val_lines+1)[10:18])\n",
    "        try:\n",
    "            check_iter = int((linecache.getline(_iieout_filename,lines_params[i]-3))[57:60])\n",
    "        except:\n",
    "            check_iter = int((linecache.getline(_iieout_filename,lines_params[i]-27))[57:60])\n",
    "        #print('Iter: ', check_iter)\n",
    "\n",
    "        data_1stline = linecache.getline(_iieout_filename,val_lines+1) #\n",
    "        data_2ndtline = linecache.getline(_iieout_filename,val_lines+2) #\n",
    "        data_3rdline = linecache.getline(_iieout_filename,val_lines+3) #\n",
    "\n",
    "        apriorival = float(data_1stline[19:38])\n",
    "        prevval = float(data_2ndtline[19:38])\n",
    "        currentval  = float(data_3rdline[19:38])\n",
    "        totalDelta = float(data_2ndtline[42:62])\n",
    "        currentDelta =  float(data_3rdline[42:62])\n",
    "        AprioriSigma = float(data_2ndtline[63:78])\n",
    "        CurrentSigma =  float(data_3rdline[63:78])\n",
    "\n",
    "        SatMain_AdjustedParams[check_iter][check_sat][text_param_adjusts] = {'APRIORI_VALUE': apriorival,\n",
    "                                             'PREVIOUS_VALUE': prevval,\n",
    "                                             'CURRENT_VALUE': currentval,\n",
    "                                              'TOTAL_DELTA':totalDelta,\n",
    "                                             'CURRENT_DELTA': currentDelta,\n",
    "                                             'APRIORI_SIGMA': AprioriSigma,\n",
    "                                             'CURRENT_SIGMA': CurrentSigma }\n",
    "        i+=1\n",
    "        #### this makes it so that you can properly index the iterations\n",
    "        i = np.mod(i,np.shape(lines_params)[0])  \n",
    "\n",
    "#### Create a list of the number TimeDep drag coeffiecient headers\n",
    "text_cd_list = [\"0CD   T%02d\" %i for i in np.arange(1,np.size(timedep_Cd_count)+1 )]\n",
    "\n",
    "lines = []\n",
    "for itt,text_param_adjusts in enumerate(text_cd_list): \n",
    "    #print(itt, text_param_adjusts)\n",
    "    with open(_iieout_filename, 'r') as f:\n",
    "        for line_no, line_text in enumerate(f):\n",
    "            if text_param_adjusts in line_text:\n",
    "                lines.append(line_no) \n",
    "\n",
    "    #### Loop thru the lines saved above and grab the data occording to its name \n",
    "    #### and location in the file\n",
    "    for il,val_lines in enumerate(lines):\n",
    "        check_sat = int(linecache.getline(_iieout_filename,val_lines+1)[10:18])\n",
    "        #check_iter = int((linecache.getline(iieout_file,val_lines+1-28))[57:60])\n",
    "\n",
    "        #### Read the lines backwars until you hit a header\n",
    "        find_last_header_range = np.arange(val_lines, val_lines-1000, -1)\n",
    "        for iiline, iivaline in enumerate(find_last_header_range):\n",
    "            line_find_header = linecache.getline(_iieout_filename,iivaline)\n",
    "            if 'PARAMETER ADJUSTMENT SUMMARY' in line_find_header:\n",
    "                check_iter =int(line_find_header[57:60])\n",
    "                break\n",
    "        data_1stline = linecache.getline(_iieout_filename,val_lines+1) #\n",
    "        data_2ndtline = linecache.getline(_iieout_filename,val_lines+2) #\n",
    "        data_3rdline = linecache.getline(_iieout_filename,val_lines+3) #\n",
    "\n",
    "        apriorival = float(data_1stline[19:38])\n",
    "        prevval = float(data_2ndtline[19:38])\n",
    "        currentval  = float(data_3rdline[19:38])\n",
    "        totalDelta = float(data_2ndtline[42:62])\n",
    "        currentDelta =  float(data_3rdline[42:62])\n",
    "        AprioriSigma = float(data_2ndtline[63:78])\n",
    "        CurrentSigma =  float(data_3rdline[63:78])\n",
    "\n",
    "        #print('Sat:  ', check_sat)\n",
    "        #print('Iter: ', check_iter)\n",
    "        #print('Val:  ', currentval)\n",
    "        #print('Time: ', date_timedep_cds[itt])\n",
    "        #print(date_timedep_cds[itt])\n",
    "        SatMain_AdjustedParams[check_iter][check_sat]['0CD'][date_timedep_cds[itt]] = {'APRIORI_VALUE': apriorival,\n",
    "                                                                'PREVIOUS_VALUE': prevval,\n",
    "                                                                'CURRENT_VALUE': currentval,\n",
    "                                                                'TOTAL_DELTA':totalDelta,\n",
    "                                                                'CURRENT_DELTA': currentDelta,\n",
    "                                                                'APRIORI_SIGMA': AprioriSigma,\n",
    "                                                                'CURRENT_SIGMA': CurrentSigma }\n",
    "if empirical_accels == True:\n",
    "    print('There are some weird things here for Gen.Acc. Not done yet.')\n",
    "\n",
    "    if DATA_TYPE == 'GPS':\n",
    "        print('There are some weird things here for Gen.Acc. Not done yet.')\n",
    "#         break\n",
    "    else:\n",
    "        print('There are some weird things here for Gen.Acc. Not done yet.')\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print('Adjusted_params: ',elapsed)\n",
    "# return(SatMain_AdjustedParams)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ignored-butterfly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GDYN2S: MAXCOR              30000000    S(   39,   21)=   -0.6030882920000000E-12  acs...\n",
       "Name: 180346, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# line_no\n",
    "line_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-dealing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-guess",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-processing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
