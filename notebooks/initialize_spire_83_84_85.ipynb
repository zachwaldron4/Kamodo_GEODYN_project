{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95dc1ca2",
   "metadata": {},
   "source": [
    "# Initialize a timeperiod\n",
    "\n",
    "This function will go through the provided time period and necessary files to run GEODYN:\n",
    "  - external attitude\n",
    "  - PCE (if not constructed)\n",
    "  - initial conditions (raw from PCE)\n",
    "  - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b95d413d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:13:47.712764Z",
     "start_time": "2023-03-01T00:13:47.347482Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pygeodyn.PYGEODYN import Pygeodyn\n",
    "from gc import collect as gc_collect\n",
    "\n",
    "# ## Initialization timeperiod\n",
    "### Satellites:\n",
    "Sat_List = ['spire083',\n",
    "            #,'spire084',\n",
    "            #'spire085',\n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9787f53",
   "metadata": {},
   "source": [
    "## Stage 1- EXAT and PCE/Raw ICs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7ca7357",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.252488Z",
     "start_time": "2023-03-01T00:13:47.715193Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "spire083\n",
      "----------------------------------------------------------------------------\n",
      "Initializing the time period from 2018-11-08 00:00:00 to 2018-11-14 00:00:00\n",
      "     overwriting the epoch start and stop to match\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "spire083\n",
      "Step 0: Make directory structure for satellite input data\n",
      "Directory Exists:  /data/SatDragModelValidation/data/inputs/sat_spire083\n",
      "Directory Exists:  /data/SatDragModelValidation/data/inputs/sat_spire083/setups\n",
      "Directory Exists:  /data/SatDragModelValidation/data/inputs/sat_spire083/external_attitude\n",
      "Directory Exists:  /data/SatDragModelValidation/data/inputs/sat_spire083/g2b\n",
      "Step 1: Construct daily external Attitude files\n",
      "   Making an external attitude file: EXAT01.2018.312\n",
      "        - converting dates from GPS to TDT.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Addition/subtraction of integers and integer-arrays with Timestamp is no longer supported.  Instead of adding/subtracting `n`, use `n * obj.freq`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8f455ce18b6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0msat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPygeodyn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings_SPIRE_pce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     sat.initialize_timeperiod_stage1(startdate, enddate,\n\u001b[0m\u001b[1;32m     48\u001b[0m                                  \u001b[0moverwrite_exat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                                  overwrite_g2b=True)\n",
      "\u001b[0;32m/data/SatDragModelValidation/pygeodyn/pygeodyn/PYGEODYN.py\u001b[0m in \u001b[0;36minitialize_timeperiod_stage1\u001b[0;34m(self, startdate, enddate, overwrite_exat, overwrite_g2b)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 self.prep_exat_check(self.raw_satinput,             \\\n\u001b[0m\u001b[1;32m    269\u001b[0m                                  \u001b[0mbool_overwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverwrite_exat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                                  verbose=self.verbose)\n",
      "\u001b[0;32m/data/SatDragModelValidation/pygeodyn/pygeodyn/prep_inputs.py\u001b[0m in \u001b[0;36mprep_exat_check\u001b[0;34m(self, raw_satinput, bool_overwrite, verbose)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.tab} Making an external attitude file: {self.filename_exat}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_write_exat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_satinput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/SatDragModelValidation/pygeodyn/pygeodyn/prep_inputs.py\u001b[0m in \u001b[0;36mmake_write_exat\u001b[0;34m(self, raw_satinput, verbose)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdate_ref\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"date_gps\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.tabtab} - converting dates from GPS to TDT.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             SpireDF['date_tdt'] = [time_gps_to_tdt(tim, leap_sec=37) \n\u001b[0m\u001b[1;32m    122\u001b[0m                                         for tim in SpireDF[date_ref]  ]\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/SatDragModelValidation/pygeodyn/pygeodyn/prep_inputs.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdate_ref\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"date_gps\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.tabtab} - converting dates from GPS to TDT.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             SpireDF['date_tdt'] = [time_gps_to_tdt(tim, leap_sec=37) \n\u001b[0m\u001b[1;32m    122\u001b[0m                                         for tim in SpireDF[date_ref]  ]\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/SatDragModelValidation/pygeodyn/pygeodyn/util_dir/time_systems.py\u001b[0m in \u001b[0;36mtime_gps_to_tdt\u001b[0;34m(tim_gps, leap_sec)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;31m### UTC to TDT---utc ahead of tdt by 32.184\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;31m#    TT =         TAI          +       32.184\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     \u001b[0mtim_tdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtim_utc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mleap_sec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_timedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32.184\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m     \u001b[0;31m#### Checked on Feb 28,2023\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtim_tdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/timestamps.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.timestamps._Timestamp.__add__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Addition/subtraction of integers and integer-arrays with Timestamp is no longer supported.  Instead of adding/subtracting `n`, use `n * obj.freq`"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pygeodyn.PYGEODYN import Pygeodyn\n",
    "from gc import collect as gc_collect\n",
    "\n",
    "startdate = \"2018-11-08\"\n",
    "enddate   = \"2018-11-13\"  #24\n",
    "\n",
    "for sat in Sat_List:\n",
    "\n",
    "    settings_SPIRE_pce= {# Basic input settings\n",
    "                 'satellite'      : {'input': sat},\n",
    "                 'den_model'      : {'input': 'jb2008'},\n",
    "                 'run_type'       : {'input': 'DataReduction_PCE'},\n",
    "                 'run_specifier'  : {'input': '_test_infrastruc'},\n",
    "                 'cd_model'       : {'input': 'BWDRAG'},\n",
    "                 'file_string'    : {'input': 'CD_2p3'},\n",
    "               # Force Model settings\n",
    "                  'cd_type'               : {'input':\"Fixed_CD\"},\n",
    "                  'cd_value'              : {'input':2.300000},\n",
    "                  'scaling_factor'        : {'input':False},\n",
    "                  'cd_adjustment_boolean' : {'input':False },\n",
    "                  'hours_between_cd_adj'  : {'input':6 },\n",
    "               # Run\n",
    "                  'step'           : {'input': 60.},\n",
    "                  'orbfil_step'    : {'input': 120.},    \n",
    "                  #\n",
    "                  'arc'    : {'input':[\"2018.324\"]},\n",
    "                  'epoch_start'    : {'input':[\"2018-11-20 00:00:00\"]},\n",
    "                  'epoch_stop'     : {'input':[\"2018-11-21 00:00:00\"]},\n",
    "                  #                  \n",
    "                  'global_options': {'input':'pso_2018'},\n",
    "               # Request read on raw outputs\n",
    "                  'request_data'   : {'input': ['Trajectory_orbfil',\n",
    "                                                'Density',\n",
    "                                                'DragFile',\n",
    "                                                'Residuals_summary',\n",
    "                                               ]},\n",
    "              #end dict\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    sat = Pygeodyn(settings_SPIRE_pce, use_file=False)\n",
    "    sat.initialize_timeperiod_stage1(startdate, enddate,\n",
    "                                 overwrite_exat=True, \n",
    "                                 overwrite_g2b=True)\n",
    "    sat = 0\n",
    "    \n",
    "    \n",
    "\n",
    "import sys\n",
    "sys.exit(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8ecf44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b74cbe3",
   "metadata": {},
   "source": [
    "## Stage 2: Setup files + Raw ICs and Update ICs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec168978",
   "metadata": {},
   "source": [
    "At this stage, the external attitude and G2B files for the time period of interest should be constructed for each satellite.\n",
    "\n",
    "Check that the g2b and raw initial conditions are named according the the constructed files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7dbe28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.261609Z",
     "start_time": "2023-03-01T00:13:45.724Z"
    }
   },
   "outputs": [],
   "source": [
    "from  datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import linecache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5453cee2",
   "metadata": {},
   "source": [
    "### Find earliest daily start time to match data\n",
    "\n",
    "Use the earliest instance of data in a day as the starting epoch/IC and set the end epoch to midnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091e25d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.262988Z",
     "start_time": "2023-03-01T00:13:45.726Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dates(test_timeperiod, file_raw_ICs):\n",
    "\n",
    "    start_0ut = []\n",
    "    end___0ut = []\n",
    "    arcs = []\n",
    "    start_update = []\n",
    "    #\n",
    "    dt_1days = pd.to_timedelta(24, 'h') \n",
    "    #\n",
    "\n",
    "\n",
    "    startdate = pd.to_datetime(test_timeperiod[0])\n",
    "    enddate   = pd.to_datetime(test_timeperiod[-1])\n",
    "    startdate_dt = pd.to_datetime(startdate, format='%Y-%m-%d')\n",
    "    enddate_dt   = pd.to_datetime(enddate,   format='%Y-%m-%d')\n",
    "    starts_linspace_dt = pd.date_range(start=startdate_dt ,\n",
    "                                         end=enddate_dt   ,\n",
    "                                        freq=str(1)+\"D\")\n",
    "\n",
    "    ### Make a list of the initial conditions for daily epoch start times that match\n",
    "    ### the first instance of pce data for that day\n",
    "    for iday, day in enumerate(starts_linspace_dt):\n",
    "\n",
    "        epoch_start =  f\"{day.strftime('%Y-%m-%d %H:%M:%S')}\" #f\"2018-11-{dayval:02d} 00:00:00\"\n",
    "        print(epoch_start)\n",
    "        epoch_startDT = pd.to_datetime(epoch_start,format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "\n",
    "        datetype = 'datetime_string'\n",
    "        date_in_file_flag = False\n",
    "\n",
    "        # Only need to use accuracy to within 1 second (ignore the microseconds in the file)\n",
    "\n",
    "        if datetype == 'datetime_string':\n",
    "            date_str = str(epoch_startDT)\n",
    "        elif datetype == 'YYMMDDHHMMSS':\n",
    "            date_str = datetime.strftime(epoch_startDT, '%y%m%d%H%M%S')\n",
    "\n",
    "        with open(file_raw_ICs, 'r') as f:\n",
    "            for line_no, line_text in enumerate(f):\n",
    "                if date_str in line_text:\n",
    "                    date_in_file_flag = True\n",
    "                    #                 print('    ','xyzline',line_no,line_text)\n",
    "                    break\n",
    "        if date_in_file_flag == False:\n",
    "            #         print(date_str,'not found in file.')\n",
    "\n",
    "            # Find the dates that have the same hour\n",
    "            if datetype == 'datetime_string':\n",
    "                date_roundhour_str = str(epoch_startDT)[:10]\n",
    "            elif datetype == 'YYMMDDHHMMSS':\n",
    "                date_roundhour_str = datetime.strftime(epoch_startDT, '%y%m%d')\n",
    "#             print(\"date_roundhour_str\", date_roundhour_str)\n",
    "            # Scan through IC file and append a list of dates within the same hour\n",
    "            line_no_list = []\n",
    "            line_list = []\n",
    "            with open(file_raw_ICs, 'r') as f:\n",
    "                for line_no, line_text in enumerate(f):\n",
    "                    if date_roundhour_str in line_text:\n",
    "                        line_no_list.append(line_no)\n",
    "            \n",
    "            \n",
    "            ### If data does not contains this day, don't append it\n",
    "            if len(line_no_list) ==0:\n",
    "                print(\"** no data for \", date_roundhour_str)\n",
    "                continue\n",
    "                \n",
    "                \n",
    "            # print(line_no_list)\n",
    "            for i in np.arange(line_no_list[2], line_no_list[-1]):\n",
    "                line = linecache.getline(file_raw_ICs, i)\n",
    "                line_list.append(line)\n",
    "            dates = []\n",
    "            for i, val in enumerate(line_list):\n",
    "                if datetype == 'datetime_string':\n",
    "                    dates.append(\n",
    "                        pd.to_datetime(line_list[i][:19],\n",
    "                                       format='%Y-%m-%d %H:%M:%S'))\n",
    "                elif datetype == 'YYMMDDHHMMSS':\n",
    "                    dates.append(\n",
    "                        pd.to_datetime(line_list[i][:19],\n",
    "                                       format='%y%m%d%H%M%S.%f'))\n",
    "\n",
    "            start_update.append(dates[1])\n",
    "\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            #         print('Found date in IC file:', str(epoch_startDT))\n",
    "            xyzline = pd.read_csv(\n",
    "                file_raw_ICs,\n",
    "                skiprows=line_no,\n",
    "                nrows=1,\n",
    "                sep='\\s+',\n",
    "                dtype=str,\n",
    "                names=[\n",
    "                    'DateYMD',\n",
    "                    'DateHMS',\n",
    "                    'X',\n",
    "                    'Y',\n",
    "                    'Z',\n",
    "                    'X_dot',\n",
    "                    'Y_dot',\n",
    "                    'Z_dot',\n",
    "                ],\n",
    "            )\n",
    "            start_update.append(\n",
    "                pd.to_datetime(xyzline['DateYMD'] + xyzline['DateHMS'],\n",
    "                               format='%Y-%m-%d%H:%M:%S')[0])\n",
    "\n",
    "#         print(epoch_start[:10], \"earliest time is:\",\n",
    "#               start_update[iday])\n",
    "\n",
    "        print(\"---appending dates for \", day)\n",
    "        start_0ut.append(f\"{day.strftime('%Y-%m-%d')} 00:00:00\")#f\"2018-11-{dayval:02d} 00:00:00\")\n",
    "        end___0ut.append(\n",
    "            pd.to_datetime(epoch_startDT +\n",
    "                           dt_1days).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        arcs.append(epoch_startDT.strftime('%Y.%j'))\n",
    "\n",
    "#     del date_roundhour_str\n",
    "#     del line_no_list\n",
    "#     del line_list\n",
    "#     del dates\n",
    "#     del xyzline\n",
    "\n",
    "    start_update = [datetime.strftime(idate, '%Y-%m-%d %H:%M:%S') for idate in start_update]\n",
    "    \n",
    "    return(start_0ut,end___0ut,arcs,start_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8613a131",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.263806Z",
     "start_time": "2023-03-01T00:13:45.728Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sat_List = ['spire083', 'spire084', 'spire085']  \n",
    "Sat_List = ['spire083']  \n",
    "# test_timeperiod = [\"2018-11-02 00:00:00\", \"2018-11-29 00:00:00\"]  # 4 days\n",
    "test_timeperiod = [\"2018-11-07 00:00:00\", \"2018-11-08 00:00:00\"]  # 4 days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102764cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.264624Z",
     "start_time": "2023-03-01T00:13:45.730Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pygeodyn.PYGEODYN import Pygeodyn\n",
    "from gc import collect as gc_collect\n",
    "\n",
    "\n",
    "obj = {}\n",
    "\n",
    "for isat,satval in enumerate(Sat_List):\n",
    "    satnum = int(satval[5:])\n",
    "\n",
    "    file_raw_ICs = f\"/data/SatDragModelValidation/data/inputs/\"\\\n",
    "              +f\"sat_spire{satnum:03d}/g2b/Spire{satnum:03d}_RawEphem_20181101_20181130.txt\"\n",
    "\n",
    "    start_0ut, end___0ut, arcs, start_update = get_dates(test_timeperiod, file_raw_ICs)\n",
    "\n",
    "    ### Run GEODYN with earliest start time to midnight\n",
    "    ###      Runnning GEODYN in this configuration, with the rawephem file as the IC \n",
    "    print()\n",
    "    print(\"start_0ut\",start_0ut )\n",
    "    print(\"end___0ut\",end___0ut )\n",
    "    print(\"arcs\",arcs )\n",
    "    print(\"start_update\",start_update )\n",
    "    print()\n",
    "\n",
    "\n",
    "    settings_SPIRE= {# Basic input settings\n",
    "                     'satellite'      : {'input': f'spire{satnum:03d}'},\n",
    "                     'den_model'      : {'input': 'jb2008'},\n",
    "                     'run_type'       : {'input': 'DataReduction_PCE'},\n",
    "                     'run_specifier'  : {'input': '_updateICs_1'},\n",
    "                     'cd_model'       : {'input': 'BWDRAG'},\n",
    "                     'file_string'    : {'input': 'CD_2p3'},\n",
    "                     # Force Model settings\n",
    "                      'cd_type'               : {'input':\"Fixed_CD\"},\n",
    "                      'cd_value'              : {'input':2.300000},\n",
    "                      'scaling_factor'        : {'input':False},\n",
    "                      'cd_adjustment_boolean' : {'input':False },\n",
    "                      'hours_between_cd_adj'  : {'input':6 },\n",
    "                     # Run\n",
    "                      'step'           : {'input': 60.},\n",
    "                      'orbfil_step'    : {'input': 120.},\n",
    "                      'which_ICfile'   : {'input':file_raw_ICs},\n",
    "                       #\n",
    "                      'arc'            : {'input':arcs},\n",
    "                      'epoch_start'    : {'input':start_update},\n",
    "                       #\n",
    "                      'epoch_stop'     : {'input':end___0ut},       \n",
    "                       #\n",
    "                      'global_options' : {'input':'pso_2018'},\n",
    "                     # Request read on raw outputs\n",
    "                      'request_data'   : {'input': ['Trajectory_orbfil', \n",
    "                                                   'Density', \n",
    "                                                   'Residuals_summary',\n",
    "                                                   'RunSummary',\n",
    "                                                   'DragFile',\n",
    "                                                   ]},\n",
    "                  #end dict\n",
    "                  }\n",
    "    sat = Pygeodyn(settings_SPIRE, use_file=False)\n",
    "    sat.run_arcs()\n",
    "    obj[satval] = sat.getData()\n",
    "#     obj[satval] =  sat.getData_BigData_lowmemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd23af14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.265450Z",
     "start_time": "2023-03-01T00:13:45.732Z"
    }
   },
   "outputs": [],
   "source": [
    "obj[satval].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9526c50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.266230Z",
     "start_time": "2023-03-01T00:13:45.734Z"
    }
   },
   "outputs": [],
   "source": [
    "obj[satval].__dict__['global_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f60c8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.267017Z",
     "start_time": "2023-03-01T00:13:45.736Z"
    }
   },
   "outputs": [],
   "source": [
    "obj[satval].__dict__['run_parameters2018.311']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87093a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.267815Z",
     "start_time": "2023-03-01T00:13:45.738Z"
    }
   },
   "outputs": [],
   "source": [
    "# obj[satval].__dict__['OrbitResids']['2018.313.01'].keys()\n",
    "# obj[satval].__dict__['OrbitResids']['2018.313.01']['data_PCE']\n",
    "# obj[satval].__dict__['OrbitResids']['2018.313.01']['data_orbfil']\n",
    "\n",
    "# obj[satval].__dict__.keys()\n",
    "\n",
    "# obj[satval].__dict__[\"Statistics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89de6b92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-13T21:20:51.498867Z",
     "start_time": "2023-02-13T21:20:07.127Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b716a34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-13T21:20:51.499655Z",
     "start_time": "2023-02-13T21:20:07.130Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa3e21e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-13T21:20:51.500425Z",
     "start_time": "2023-02-13T21:20:07.134Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e691f08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.268629Z",
     "start_time": "2023-03-01T00:13:45.742Z"
    }
   },
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "# from plotly.offline import plot, iplot\n",
    "# from plotly.subplots import make_subplots\n",
    "# import plotly.express as px\n",
    "\n",
    "# config = dict({\n",
    "#                 'displayModeBar': True,\n",
    "#                 'responsive': False,\n",
    "#                 'staticPlot': True,\n",
    "#                 'displaylogo': False,\n",
    "#                 'showTips': False,\n",
    "#                 })\n",
    "\n",
    "\n",
    "# fig = make_subplots(rows=3, cols=1)\n",
    "\n",
    "\n",
    "# arc = '2018.313.01'\n",
    "\n",
    "# orbfit = obj[satval].__dict__['OrbitResids'][arc]['data_orbfil']\n",
    "# pce = obj[satval].__dict__['OrbitResids'][arc]['data_PCE']\n",
    "\n",
    "# fig.add_trace(go.Scattergl(\n",
    "#             x=pd.to_datetime(pce['Date']),\n",
    "#             y=pce['N'],\n",
    "#                 mode='markers',\n",
    "#                 opacity=1,\n",
    "#                 marker=dict(size=3, color=\"blue\"),\n",
    "#                 showlegend=False),\n",
    "#                 secondary_y=False, row=1, col=1,)\n",
    "\n",
    "# fig.add_trace(go.Scattergl(\n",
    "#             x=pd.to_datetime(pce['Date']),\n",
    "#             y=pce['T'],\n",
    "#                 mode='markers',\n",
    "#                 opacity=1,\n",
    "#                 marker=dict(size=3, color=\"blue\"),\n",
    "#                 showlegend=False),\n",
    "#                 secondary_y=False, row=2, col=1,)\n",
    "\n",
    "# fig.add_trace(go.Scattergl(\n",
    "#             x=pd.to_datetime(pce['Date']),\n",
    "#             y=pce['W'],\n",
    "#                 mode='markers',\n",
    "#                 opacity=1,\n",
    "#                 marker=dict(size=3, color=\"blue\"),     \n",
    "#                 showlegend=False),\n",
    "#                 secondary_y=False, row=3, col=1,)\n",
    "\n",
    "# ### ==============================================================\n",
    "\n",
    "\n",
    "# fig.add_trace(go.Scattergl(\n",
    "#             x=pd.to_datetime(orbfit['Date']),\n",
    "#             y=orbfit['N'],\n",
    "#                 mode='markers',\n",
    "#                 opacity=1,\n",
    "#                 marker=dict(size=3, color='red'),\n",
    "#                 showlegend=False),\n",
    "#                 secondary_y=False, row=1, col=1,)\n",
    "\n",
    "# fig.add_trace(go.Scattergl(\n",
    "#             x=pd.to_datetime(orbfit['Date']),\n",
    "#             y=orbfit['T'],\n",
    "#                 mode='markers',\n",
    "#                 opacity=1,\n",
    "#                 marker=dict(size=3, color='red'),\n",
    "#                 showlegend=False),\n",
    "#                 secondary_y=False, row=2, col=1,)\n",
    "\n",
    "# fig.add_trace(go.Scattergl(\n",
    "#             x=pd.to_datetime(orbfit['Date']),\n",
    "#             y=orbfit['W'],\n",
    "#                 mode='markers',\n",
    "#                 opacity=1,\n",
    "#                 marker=dict(size=3, color='red'),     \n",
    "#                 showlegend=False),\n",
    "#                 secondary_y=False, row=3, col=1,)\n",
    "\n",
    "# fig.update_yaxes( title=\"N\",  exponentformat= 'power',row=1, col=1)\n",
    "# fig.update_yaxes( title=\"T\",  exponentformat= 'power',row=2, col=1)\n",
    "# fig.update_yaxes( title=\"W\",  exponentformat= 'power',row=3, col=1)\n",
    "\n",
    "\n",
    "# fig.update_layout(\n",
    "#         autosize=True\n",
    "# #         width=800,height=900,\n",
    "#                 )\n",
    "# fig.show(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa635a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7919f274",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.269386Z",
     "start_time": "2023-03-01T00:13:45.745Z"
    }
   },
   "outputs": [],
   "source": [
    "arc = '2018.311'\n",
    "obj[satval].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f191502d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.270347Z",
     "start_time": "2023-03-01T00:13:45.747Z"
    }
   },
   "outputs": [],
   "source": [
    "# obj[satval].__dict__[\"Trajectory_orbfil\"][arc]['data_record']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73868226",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-13T20:23:14.911570Z",
     "start_time": "2023-02-13T20:22:29.576Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7436e53c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.271173Z",
     "start_time": "2023-03-01T00:13:45.750Z"
    }
   },
   "outputs": [],
   "source": [
    "StateVector_PCE_datafile =    f\"/data/SatDragModelValidation/data/inputs/\"\\\n",
    "                              +f\"sat_spire{satnum:03d}/g2b/Spire{satnum:03d}_RawEphem_20181101_20181130.txt\"\n",
    "\n",
    "\n",
    "# self.__dict__['global_params']['file_statevector_ICs']\n",
    "StateVector_PCE_datafile\n",
    "arc_first_time  = obj[satval].__dict__['Trajectory_orbfil'][arc]['data_record']['Date_UTC'].iloc[0]\n",
    "arc_last_time   = obj[satval].__dict__['Trajectory_orbfil'][arc]['data_record']['Date_UTC'].iloc[-1]\n",
    "\n",
    "arc_first_time_str     =  str(arc_first_time)#.replace( \"'\",' ') \n",
    "arc_last_time_str      =  str(arc_last_time)#.replace( \"'\",' ') \n",
    "\n",
    "\n",
    "A=[]\n",
    "for i,val in enumerate(np.arange(-20,20)):\n",
    "    A.append(str(pd.to_datetime(arc_first_time)+pd.to_timedelta(val,'s')))\n",
    "B=[]\n",
    "for i,val in enumerate(np.arange(-20,20)):\n",
    "    B.append(str(pd.to_datetime(arc_last_time)+pd.to_timedelta(val,'s')))\n",
    "\n",
    "####---------------------------------------------------------\n",
    "last_line = False\n",
    "get_firstline = True\n",
    "with open(StateVector_PCE_datafile, 'r') as f:\n",
    "    for line_no, line_text in enumerate(f):\n",
    "        if any(times in line_text for times in A) and get_firstline==True:\n",
    "            first_line = line_no\n",
    "            get_firstline = False\n",
    "        if any(times in line_text for times in B):\n",
    "            last_line = line_no\n",
    "            break\n",
    "\n",
    "    if not last_line:\n",
    "        last_line = first_line +32220\n",
    "        print('No matching lastline time: ',arc_last_time_str, last_line )\n",
    "\n",
    "print(\"first_line\", first_line)\n",
    "print(\"last_line\" , last_line)\n",
    "print(\"arc_first_time\", arc_first_time)\n",
    "print(\"arc_last_time\", arc_last_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cadcab9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.271958Z",
     "start_time": "2023-03-01T00:13:45.752Z"
    }
   },
   "outputs": [],
   "source": [
    "PCE_data = pd.read_csv(StateVector_PCE_datafile, \n",
    "            skiprows = first_line, \n",
    "#             nrows=last_line - first_line,           \n",
    "            sep = '\\s+',\n",
    "            dtype=object,\n",
    "            names = [\n",
    "                'DateYMD',\n",
    "                'DateHMS',\n",
    "                'X_pce',\n",
    "                'Y_pce',\n",
    "                'Z_pce',\n",
    "                'Xdot_pce',\n",
    "                'Ydot_pce',\n",
    "                'Zdot_pce',\n",
    "    ],)\n",
    "\n",
    "PCE_data['Date_pd'] =  pd.to_datetime(PCE_data['DateYMD']+PCE_data['DateHMS'], format='%Y-%m-%d%H:%M:%S')\n",
    "del PCE_data['DateYMD'], PCE_data['DateHMS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f037fee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.272849Z",
     "start_time": "2023-03-01T00:13:45.754Z"
    }
   },
   "outputs": [],
   "source": [
    "PCE_data = PCE_data.query(f\"{arc_first_time.year}{arc_first_time.month:02d}{arc_first_time.day:02d}\"\\\n",
    "                     +f\" < Date_pd < \"\\\n",
    "                     +f\"{arc_last_time.year}{arc_last_time.month:02d}{arc_last_time.day+1:02d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09618d6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.273708Z",
     "start_time": "2023-03-01T00:13:45.756Z"
    }
   },
   "outputs": [],
   "source": [
    "# PCE_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2beb8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.274504Z",
     "start_time": "2023-03-01T00:13:45.758Z"
    }
   },
   "outputs": [],
   "source": [
    "# obj[satval].__dict__[\"Trajectory_orbfil\"][arc]['data_record']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2eab63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.275290Z",
     "start_time": "2023-03-01T00:13:45.761Z"
    }
   },
   "outputs": [],
   "source": [
    "CombinedOrbitsDF  = {}\n",
    "\n",
    "\n",
    "orbfil_arc1 = obj[satval].__dict__['Trajectory_orbfil'][arc]['data_record']\n",
    "orbfil_arc1['Date_pd'] = pd.to_datetime(orbfil_arc1['Date_UTC'])\n",
    "\n",
    "# del orbfil_arc1['Date_UTC']\n",
    "# del orbfil_arc1['MJDSEC ET']\n",
    "# del orbfil_arc1['Geodetic Latitude']\n",
    "# del orbfil_arc1['East Longitude']\n",
    "# del orbfil_arc1['Height']\n",
    "# del orbfil_arc1['MJDS_UTC']\n",
    "\n",
    "\n",
    "### CombinedOrbitsDF is a dataframe containing all data between the two files where the dates match\n",
    "CombinedOrbitsDF[arc] = pd.merge(\\\n",
    "                            left=orbfil_arc1, left_on='Date_pd',\n",
    "                            right=PCE_data, right_on='Date_pd')\n",
    "\n",
    "#             print(CombinedOrbitsDF[arc].columns)\n",
    "CombinedOrbitsDF[arc] = CombinedOrbitsDF[\\\n",
    "                                        arc].rename(\\\n",
    "                                            columns={\\\n",
    "                                        \"X j2000\" : \"X_orbfil\"   ,\n",
    "                                        \"Y j2000\" : \"Y_orbfil\"   ,\n",
    "                                        \"Z j2000\" : \"Z_orbfil\"   ,\n",
    "                                    \"X_dot j2000\" : \"Xdot_orbfil\",\n",
    "                                    \"Y_dot j2000\" : \"Ydot_orbfil\",\n",
    "                                    \"Z_dot j2000\" : \"Zdot_orbfil\",\n",
    "                                                                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af8a6f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.276122Z",
     "start_time": "2023-03-01T00:13:45.763Z"
    }
   },
   "outputs": [],
   "source": [
    "from pygeodyn.util_dir.coordinate_systems import Convert_cartesian_to_NTW_returnall\n",
    "rsw_bool= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8a7c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.276976Z",
     "start_time": "2023-03-01T00:13:45.765Z"
    }
   },
   "outputs": [],
   "source": [
    "OrbitResids = {} \n",
    "\n",
    "############--------------------------------------------------------------------------------------------------        \n",
    "#             OrbitResids = self.ResidInvestigation_get_residuals_coordsystems(CombinedOrbitsDF)\n",
    "\n",
    "data_orbfil = {}\n",
    "data_PCE    = {}\n",
    "resids      = {}\n",
    "### Convert the PCE data to NTW\n",
    "#             print('        Converting PCE data to other coordinates...')\n",
    "X = CombinedOrbitsDF[arc]['X_pce'].astype(float)\n",
    "Y = CombinedOrbitsDF[arc]['Y_pce'].astype(float)\n",
    "Z = CombinedOrbitsDF[arc]['Z_pce'].astype(float)\n",
    "Xdot = CombinedOrbitsDF[arc]['Xdot_pce'].astype(float)\n",
    "Ydot = CombinedOrbitsDF[arc]['Ydot_pce'].astype(float)\n",
    "Zdot = CombinedOrbitsDF[arc]['Zdot_pce'].astype(float)\n",
    "state_vector = np.transpose(np.array([CombinedOrbitsDF[arc]['X_pce'].astype(float),\n",
    "                                      Y,\n",
    "                                      Z,\n",
    "                                      Xdot,\n",
    "                                      Ydot,\n",
    "                                      Zdot]))\n",
    "data_PCE['Date'] = CombinedOrbitsDF[arc]['Date_pd']\n",
    "\n",
    "##### NTW Coordinate System\n",
    "#             NTW_PCE  = [Convert_cartesian_to_NTW_returnall(x) for x in state_vector]\n",
    "NTW_pce =  [Convert_cartesian_to_NTW_returnall(x_pce, 0, True) \\\n",
    "                        for x_pce in state_vector]\n",
    "Tmat_ntw         = []\n",
    "n_pce        = []\n",
    "t_pce        = []\n",
    "w_pce        = []\n",
    "for vec,matrix in NTW_pce:\n",
    "    Tmat_ntw.append(matrix)\n",
    "    n_pce.append( vec[0])\n",
    "    t_pce.append( vec[1])\n",
    "    w_pce.append( vec[2])        \n",
    "\n",
    "data_PCE['N'] = n_pce\n",
    "data_PCE['T'] = t_pce\n",
    "data_PCE['W'] = w_pce\n",
    "##### XYZ Coordinate System\n",
    "data_PCE['X'] = X\n",
    "data_PCE['Y'] = Y\n",
    "data_PCE['Z'] = Z\n",
    "data_PCE['Xdot'] = Xdot\n",
    "data_PCE['Ydot'] = Ydot\n",
    "data_PCE['Zdot'] = Zdot\n",
    "\n",
    "\n",
    "### Convert the ORBIT FILE data to NTW\n",
    "X = CombinedOrbitsDF[arc]['X_orbfil']\n",
    "Y = CombinedOrbitsDF[arc]['Y_orbfil']\n",
    "Z = CombinedOrbitsDF[arc]['Z_orbfil']\n",
    "Xdot = CombinedOrbitsDF[arc]['Xdot_orbfil']\n",
    "Ydot = CombinedOrbitsDF[arc]['Ydot_orbfil']\n",
    "Zdot = CombinedOrbitsDF[arc]['Zdot_orbfil']\n",
    "state_vector = np.transpose(np.array([X, Y, Z, Xdot, Ydot, Zdot]))\n",
    "data_orbfil['Date'] = CombinedOrbitsDF[arc]['Date_pd']\n",
    "\n",
    "##### NTW Coordinate System\n",
    "#             NTW_orbfil  = [Convert_cartesian_to_NTW_returnall(x) for x in state_vector]\n",
    "NTW_orb  = [Convert_cartesian_to_NTW_returnall(x_orb, Tmat_ntw_i, False) \\\n",
    "                    for x_orb, Tmat_ntw_i in zip(state_vector,Tmat_ntw)]\n",
    "n_orb        = []\n",
    "t_orb        = []\n",
    "w_orb        = []\n",
    "\n",
    "for vecorb,matrixorb in NTW_orb:\n",
    "    n_orb.append( vecorb[0])\n",
    "    t_orb.append( vecorb[1])\n",
    "    w_orb.append( vecorb[2])        \n",
    "\n",
    "data_orbfil['N'] = n_orb\n",
    "data_orbfil['T'] = t_orb\n",
    "data_orbfil['W'] = w_orb\n",
    "##### XYZ Coordinate System\n",
    "data_orbfil['X'] = X\n",
    "data_orbfil['Y'] = Y\n",
    "data_orbfil['Z'] = Z\n",
    "data_orbfil['Xdot'] = Xdot\n",
    "data_orbfil['Ydot'] = Ydot\n",
    "data_orbfil['Zdot'] = Zdot\n",
    "\n",
    "\n",
    "##### R theta phi Coordinate System\n",
    "#             data_orbfil['R']     = np.sqrt( np.square(X) + \n",
    "#                                             np.square(Y) +\n",
    "#                                             np.square(Z) )\n",
    "#             data_orbfil['theta'] = np.arctan(Y / X)\n",
    "#             data_orbfil['phi']   = np.arccos(Z / (np.sqrt( np.square(X) + \n",
    "#                                             np.square(Y) +\n",
    "#                                             np.square(Z) )))\n",
    "\n",
    "\n",
    "### RESIDUALS:\n",
    "resids['Date'] = CombinedOrbitsDF[arc]['Date_pd']\n",
    "\n",
    "##### NTW Coordinate System\n",
    "resids['N'] = (np.array(data_PCE['N']) - np.array(data_orbfil['N']))\n",
    "resids['T'] = (np.array(data_PCE['T']) - np.array(data_orbfil['T']))\n",
    "resids['W'] = (np.array(data_PCE['W']) - np.array(data_orbfil['W']))\n",
    "\n",
    "\n",
    "OrbitResids[arc] = {}\n",
    "OrbitResids[arc]['data_orbfil'] = data_orbfil\n",
    "OrbitResids[arc]['data_PCE']    = data_PCE\n",
    "OrbitResids[arc]['resids']      = resids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f173eba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T19:40:16.974972Z",
     "start_time": "2023-02-15T19:40:16.933221Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067736a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.277869Z",
     "start_time": "2023-03-01T00:13:45.768Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot, iplot\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "config = dict({\n",
    "                'displayModeBar': True,\n",
    "                'responsive': True,\n",
    "                'staticPlot': False,\n",
    "                'displaylogo': False,\n",
    "                'showTips': False,\n",
    "                })\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=3, cols=1)\n",
    "\n",
    "\n",
    "arc = '2018.311.01'\n",
    "\n",
    "\n",
    "orbfit = data_orbfil\n",
    "pce =data_PCE\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=pd.to_datetime(pce['Date']),\n",
    "            y=pce['N'],\n",
    "            name=f\"PCE, Spire {satnum}\",\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color=\"blue\"),\n",
    "                showlegend=True),\n",
    "                secondary_y=False, row=1, col=1,)\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=pd.to_datetime(pce['Date']),\n",
    "            y=pce['T'],\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color=\"blue\"),\n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=2, col=1,)\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=pd.to_datetime(pce['Date']),\n",
    "            y=pce['W'],\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color=\"blue\"),     \n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=3, col=1,)\n",
    "\n",
    "### ==============================================================\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=pd.to_datetime(orbfit['Date']),\n",
    "            y=orbfit['N'],\n",
    "                name=f\"Orbit Fit, Spire {satnum}\",\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color='red'),\n",
    "                showlegend=True),\n",
    "                secondary_y=False, row=1, col=1,)\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=pd.to_datetime(orbfit['Date']),\n",
    "            y=orbfit['T'],\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color='red'),\n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=2, col=1,)\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=pd.to_datetime(orbfit['Date']),\n",
    "            y=orbfit['W'],\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color='red'),     \n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=3, col=1,)\n",
    "\n",
    "fig.update_yaxes( title=\"N\",  exponentformat= 'power',row=1, col=1)\n",
    "fig.update_yaxes( title=\"T\",  exponentformat= 'power',row=2, col=1)\n",
    "fig.update_yaxes( title=\"W\",  exponentformat= 'power',row=3, col=1)\n",
    "\n",
    "\n",
    "# fig.update_layout(f\"Spire {satnum} NTW, direct comparison\",\n",
    "#         autosize=True,\n",
    "#         width=800,height=900,\n",
    "#                 )\n",
    "fig.show(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e463d7f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.278706Z",
     "start_time": "2023-03-01T00:13:45.770Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = make_subplots(rows=3, cols=1)\n",
    "\n",
    "\n",
    "# arc = '2018.313.01'\n",
    "\n",
    "# orbfit = obj[satval].__dict__['OrbitResids'][arc]['data_orbfil']\n",
    "# pce = obj[satval].__dict__['OrbitResids'][arc]['data_PCE']\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=resids['Date'],\n",
    "            y=resids['N'],\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color=\"blue\"),\n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=1, col=1,)\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=resids['Date'],\n",
    "            y=resids['T'],\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color=\"blue\"),\n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=2, col=1,)\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=resids['Date'],\n",
    "            y=resids['W'],\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color=\"blue\"),     \n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=3, col=1,)\n",
    "\n",
    "### ==============================================================\n",
    "\n",
    "\n",
    "# fig.add_trace(go.Scattergl(\n",
    "#             x=CombinedOrbitsDF[arc]['Date_pd'],\n",
    "#             y=CombinedOrbitsDF[arc]['X_pce'],\n",
    "#                 mode='markers',\n",
    "#                 opacity=1,\n",
    "#                 marker=dict(size=3, color='red'),\n",
    "#                 showlegend=False),\n",
    "#                 secondary_y=False, row=1, col=1,)\n",
    "\n",
    "# fig.add_trace(go.Scattergl(\n",
    "#             x=CombinedOrbitsDF[arc]['Date_pd'],\n",
    "#             y=CombinedOrbitsDF[arc]['Y_pce'],\n",
    "#                 mode='markers',\n",
    "#                 opacity=1,\n",
    "#                 marker=dict(size=3, color='red'),\n",
    "#                 showlegend=False),\n",
    "#                 secondary_y=False, row=2, col=1,)\n",
    "\n",
    "# fig.add_trace(go.Scattergl(\n",
    "#             x=CombinedOrbitsDF[arc]['Date_pd'],\n",
    "#             y=CombinedOrbitsDF[arc]['Z_pce'],\n",
    "#                 mode='markers',\n",
    "#                 opacity=1,\n",
    "#                 marker=dict(size=3, color='red'),     \n",
    "#                 showlegend=False),\n",
    "#                 secondary_y=False, row=3, col=1,)\n",
    "\n",
    "fig.update_yaxes( title=\"N-residual (m)\",  exponentformat= 'power',row=1, col=1)\n",
    "fig.update_yaxes( title=\"T-residual (m)\",  exponentformat= 'power',row=2, col=1)\n",
    "fig.update_yaxes( title=\"W-residual (m)\",  exponentformat= 'power',row=3, col=1)\n",
    "\n",
    "\n",
    "fig.update_layout(title=f\"Spire {satnum} Residuals for PCE-Orbfil, NTW\",\n",
    "                  \n",
    "        autosize=True\n",
    "#         width=800,height=900,\n",
    "                )\n",
    "fig.show(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa73840",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.279529Z",
     "start_time": "2023-03-01T00:13:45.773Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = make_subplots(rows=3, cols=1)\n",
    "\n",
    "\n",
    "arc = '2018.311'\n",
    "\n",
    "# orbfit = obj[satval].__dict__['OrbitResids'][arc]['data_orbfil']\n",
    "# pce = obj[satval].__dict__['OrbitResids'][arc]['data_PCE']\n",
    "CombinedOrbitsDF[arc]\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=CombinedOrbitsDF[arc]['Date_pd'],\n",
    "            y=CombinedOrbitsDF[arc]['X_pce'].values.astype(float) - CombinedOrbitsDF[arc]['X_orbfil'],\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color=\"blue\"),\n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=1, col=1,)\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=CombinedOrbitsDF[arc]['Date_pd'],\n",
    "            y=CombinedOrbitsDF[arc]['Y_pce'].values.astype(float) - CombinedOrbitsDF[arc]['Y_orbfil'],\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color=\"blue\"),\n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=2, col=1,)\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=CombinedOrbitsDF[arc]['Date_pd'],\n",
    "            y=CombinedOrbitsDF[arc]['Z_pce'].values.astype(float) - CombinedOrbitsDF[arc]['Z_orbfil'],\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color=\"blue\"),     \n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=3, col=1,)\n",
    "\n",
    "### ==============================================================\n",
    "\n",
    "\n",
    "# fig.add_trace(go.Scattergl(\n",
    "#             x=CombinedOrbitsDF[arc]['Date_pd'],\n",
    "#             y=CombinedOrbitsDF[arc]['X_pce'],\n",
    "#                 mode='markers',\n",
    "#                 opacity=1,\n",
    "#                 marker=dict(size=3, color='red'),\n",
    "#                 showlegend=False),\n",
    "#                 secondary_y=False, row=1, col=1,)\n",
    "\n",
    "# fig.add_trace(go.Scattergl(\n",
    "#             x=CombinedOrbitsDF[arc]['Date_pd'],\n",
    "#             y=CombinedOrbitsDF[arc]['Y_pce'],\n",
    "#                 mode='markers',\n",
    "#                 opacity=1,\n",
    "#                 marker=dict(size=3, color='red'),\n",
    "#                 showlegend=False),\n",
    "#                 secondary_y=False, row=2, col=1,)\n",
    "\n",
    "# fig.add_trace(go.Scattergl(\n",
    "#             x=CombinedOrbitsDF[arc]['Date_pd'],\n",
    "#             y=CombinedOrbitsDF[arc]['Z_pce'],\n",
    "#                 mode='markers',\n",
    "#                 opacity=1,\n",
    "#                 marker=dict(size=3, color='red'),     \n",
    "#                 showlegend=False),\n",
    "#                 secondary_y=False, row=3, col=1,)\n",
    "\n",
    "fig.update_yaxes( title=\"X\",  exponentformat= 'power',row=1, col=1)\n",
    "fig.update_yaxes( title=\"Y\",  exponentformat= 'power',row=2, col=1)\n",
    "fig.update_yaxes( title=\"Z\",  exponentformat= 'power',row=3, col=1)\n",
    "\n",
    "\n",
    "fig.update_layout(title='Residuals for PCE-Orbfil, XYZ',\n",
    "                  \n",
    "        autosize=True\n",
    "#         width=800,height=900,\n",
    "                )\n",
    "fig.show(config=config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4fbf3f",
   "metadata": {},
   "source": [
    " Test by converting these to NTW, check the units, check the coordinate systems.......... yikes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8625fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.280329Z",
     "start_time": "2023-03-01T00:13:45.775Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = make_subplots(rows=3, cols=1)\n",
    "\n",
    "\n",
    "# arc = '2018.313.01'\n",
    "\n",
    "# orbfit = obj[satval].__dict__['OrbitResids'][arc]['data_orbfil']\n",
    "# pce = obj[satval].__dict__['OrbitResids'][arc]['data_PCE']\n",
    "CombinedOrbitsDF[arc]\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=CombinedOrbitsDF[arc]['Date_pd'],\n",
    "            y=CombinedOrbitsDF[arc]['Xdot_pce'].values.astype(float),\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color=\"blue\"),\n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=1, col=1,)\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=CombinedOrbitsDF[arc]['Date_pd'],\n",
    "            y=CombinedOrbitsDF[arc]['Ydot_pce'].values.astype(float),\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color=\"blue\"),\n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=2, col=1,)\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=CombinedOrbitsDF[arc]['Date_pd'],\n",
    "            y=CombinedOrbitsDF[arc]['Zdot_pce'].values.astype(float),\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color=\"blue\"),     \n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=3, col=1,)\n",
    "\n",
    "### ==============================================================\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=CombinedOrbitsDF[arc]['Date_pd'],\n",
    "            y=CombinedOrbitsDF[arc]['Xdot_orbfil'],\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color='red'),\n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=1, col=1,)\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=CombinedOrbitsDF[arc]['Date_pd'],\n",
    "            y=CombinedOrbitsDF[arc]['Ydot_orbfil'],\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color='red'),\n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=2, col=1,)\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=CombinedOrbitsDF[arc]['Date_pd'],\n",
    "            y=CombinedOrbitsDF[arc]['Zdot_orbfil'],\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color='red'),     \n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=3, col=1,)\n",
    "\n",
    "fig.update_yaxes( title=\"Xdot\",  exponentformat= 'power',row=1, col=1)\n",
    "fig.update_yaxes( title=\"Ydot\",  exponentformat= 'power',row=2, col=1)\n",
    "fig.update_yaxes( title=\"Zdot\",  exponentformat= 'power',row=3, col=1)\n",
    "\n",
    "\n",
    "fig.update_layout(title='PCE vs Orbfil, VEL-XYZ',\n",
    "                  \n",
    "        autosize=True\n",
    "#         width=800,height=900,\n",
    "                )\n",
    "fig.show(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999ba0a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.281118Z",
     "start_time": "2023-03-01T00:13:45.777Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43450f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee48d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aef6952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bde820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f671832f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T00:14:02.281996Z",
     "start_time": "2023-03-01T00:13:45.783Z"
    }
   },
   "outputs": [],
   "source": [
    "#     obj = sat.getData()\n",
    "\n",
    "\n",
    "\n",
    "#     print()\n",
    "#     ### Load the data, grab the final trajectory point from the previous day, use this value as initial condition.\n",
    "#     IC_update_0ut=[]\n",
    "#     for iarc, valarc in enumerate(obj.__dict__['global_params']['arc_input']):\n",
    "#         print('Writing values for', valarc)\n",
    "#         IC_update_0ut.append([\\\n",
    "#                 obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['X j2000'].values[-1],\n",
    "#                 obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['Y j2000'].values[-1],\n",
    "#                 obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['Z j2000'].values[-1],\n",
    "#                 obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['X_dot j2000'].values[-1],\n",
    "#                 obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['Y_dot j2000'].values[-1],\n",
    "#                 obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['Z_dot j2000'].values[-1]\n",
    "#                             ])\n",
    "#     print(IC_update_0ut)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     ### Run with 0ut to 0ut\n",
    "#     ###    Run for the standard full day using the state vector \n",
    "#     ###    values from midnight of the previous day as the epoch\n",
    "#     ###    start initial conditions.  This method truncates the \n",
    "#     ###    first day in the original epoch list.\n",
    "\n",
    "#     settings_SPIRE= {# Basic input settings\n",
    "#                      'satellite'      : {'input': f'spire{satnum:03d}'},\n",
    "#                      'den_model'      : {'input': 'jb2008'},\n",
    "#                      'run_type'       : {'input': 'DataReduction_PCE'},\n",
    "#                      'run_specifier'  : {'input': '_updateICs_2'},\n",
    "#                      'cd_model'       : {'input': 'BWDRAG'},\n",
    "#                      'file_string'    : {'input': 'CD_2p3'},\n",
    "#                    # Force Model settings\n",
    "#                       'cd_type'               : {'input':\"Fixed_CD\"},\n",
    "#                       'cd_value'              : {'input':2.300000},\n",
    "#                       'scaling_factor'        : {'input':False},\n",
    "#                       'cd_adjustment_boolean' : {'input':False },\n",
    "#                       'hours_between_cd_adj'  : {'input':6 },\n",
    "#                    # Run\n",
    "#                       'step'           : {'input': 60.},\n",
    "#                       'orbfil_step'    : {'input': 60.},    \n",
    "\n",
    "#                       #\n",
    "#                       'arc'            : {'input':arcs[1:]},\n",
    "#                       'epoch_start'    : {'input':start_0ut[1:]},\n",
    "#                       'epoch_stop'     : {'input':end___0ut[1:]},       \n",
    "#                       'initial_conditions':{'input':IC_update_0ut[:-1]},\n",
    "\n",
    "#                       'global_options' : {'input':'pso_2018'},\n",
    "#                    # Request read on raw outputs\n",
    "#                       'request_data'   : {'input': ['Trajectory_orbfil', \n",
    "#                                                     'RunSummary']},\n",
    "#                   #end dict\n",
    "#                   }\n",
    "#     sat = Pygeodyn(settings_SPIRE, use_file=False)\n",
    "#     sat.run_arcs()\n",
    "#     obj = sat.getData()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     ### Make updated IC file\n",
    "#     ### Write to an ascii text file. \n",
    "#     file_save = f\"/data/SatDragModelValidation/data/inputs/sat_spire{satnum:03d}/setups/\" \\\n",
    "#                +f\"Spire{satnum:03d}_initialconditions_{start_0ut[1:][0][:10]}_{end___0ut[1:][-1][:10]}.txt\"\n",
    "\n",
    "#     f = open(file_save, \"w+\")\n",
    "#     f.write(\"\\n\")\n",
    "#     f.close()\n",
    "#     #                     filemodels = open(\"/data/geodyn_proj/pygeodyn/temp_runfiles/geodyn_modelpaths.txt\",\"w+\")\n",
    "#     #                     filemodels.write(self.model_data_path+'\\n')\n",
    "#     #                     filemodels.write(self.orbitcloud_csv_file+  '\\n')\n",
    "#     #                     filemodels.close()\n",
    "\n",
    "\n",
    "#     arc0 = settings_SPIRE['arc']['input'][0]\n",
    "#     with open(file_save, 'r+') as file:\n",
    "#         #### Manually write the header units\n",
    "#         header_units =\\\n",
    "#                     f\"{'UTC'.rjust(len(str(obj.__dict__['Trajectory_orbfil'][arc0]['data_record']['Date_UTC'][1]))-1,' ') }\"\\\n",
    "#                 +f\"  {'(m)'.rjust(15,' ')}\"\\\n",
    "#                 +f\"  {'(m)'.rjust(15,' ')}\"\\\n",
    "#                 +f\"  {'(m)'.rjust(15,' ')}\"\\\n",
    "#                 +f\"  {'(m/s)'.rjust(15,' ')}\"\\\n",
    "#                 +f\"  {'(m/s)'.rjust(15,' ')}\"\\\n",
    "#                 +f\"  {'(m/s)'.rjust(15,' ')}\"\\\n",
    "\n",
    "#         #### Manually write the header field names\n",
    "#         header_names =\\\n",
    "#                     f\"{'Date'.rjust(len(str(obj.__dict__['Trajectory_orbfil'][arc0]['data_record']['Date_UTC'][1]))-1,' ') }\"\\\n",
    "#                 +f\"  {'X'.rjust(15,' ')}\"\\\n",
    "#                 +f\"  {'Y'.rjust(15,' ')}\"\\\n",
    "#                 +f\"  {'Z'.rjust(15,' ')}\"\\\n",
    "#                 +f\"  {'X_dot'.rjust(15,' ')}\"\\\n",
    "#                 +f\"  {'Y_dot'.rjust(15,' ')}\"\\\n",
    "#                 +f\"  {'Z_dot'.rjust(15,' ')}\"\\\n",
    "\n",
    "\n",
    "#     #---+----1----+----2----+----3----+----4----+----5----+----6----+----7----+----8\n",
    "#         #### Manually write the detailed header description\n",
    "#         header_meta = \\\n",
    "#         f'''### Initial conditions file\n",
    "# ### -----------------------\n",
    "# ###     Satellite: Spire_{satnum:03d}\n",
    "# ###     Last modified: {datetime.now()-timedelta(hours=7)}\n",
    "# ###\n",
    "# ### Source\n",
    "# ### -------\n",
    "# ###     Initial conditions from Converged Solutions of GEODYN data reduction.\n",
    "# ###     Constructed as follows:\n",
    "# ###        Stage 1\n",
    "# ###           - for each day of interest, find the earliest epoch time in that\n",
    "# ###             day that matches the raw data (PCE)\n",
    "# ###           - set epoch_start value to be that time for each day, respectively\n",
    "# ###           - run GEODYN with the earliest time of day until midnight.\n",
    "# ###           - Collect the trajectory outputs into a file, saving just\n",
    "# ###             state vector of the starttime and endtime\n",
    "# ###        Stage 2  \n",
    "# ###           - Set the epoch start time to midnight\n",
    "# ###           - Use the final state vector values from the previous day\n",
    "# ###             (should be within 1 minute of midnight) as the new\n",
    "# ###             initial condition\n",
    "# ###           - Run geodyn for each daily arc from 0 UT to 0 UT\n",
    "# ###        Stage 3 \n",
    "# ###           - correct any failed convergences\n",
    "# ###           - use the output orbit solutions from the converged solutions\n",
    "# ###             as the updated initial conditions\n",
    "# ###      note-- Orbits were fit to PCE (SpireLeoOrb 'POD' from RTOrb) \n",
    "# ###             using Jb2008 density model.\n",
    "# ###\n",
    "# ### Contents\n",
    "# ### --------\n",
    "# ###     Date: (YYYY-MM-DD hh:mm:ss.ssssss) (UTC)\n",
    "# ###     pvi: Position and velocity (X, Y, Z, X_dot, Y_dot, Z_dot)\n",
    "# ###          coordinate: ECI-J2000\n",
    "# ###          unit: m and m/s\n",
    "# ###\n",
    "# #{header_units}\n",
    "# #{header_names}\n",
    "# ### %eoh\n",
    "# '''\n",
    "#         file.write(header_meta)\n",
    "\n",
    "\n",
    "#         for iarc, valarc in enumerate(obj.__dict__['global_params']['arc_input']):\n",
    "#             print('Writing values for', valarc)\n",
    "#         #     update_0ut_sv.append([\\\n",
    "#         #             obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['X j2000'].values[-1],\n",
    "#         #             obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['Y j2000'].values[-1],\n",
    "#         #             obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['Z j2000'].values[-1],\n",
    "#         #             obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['X_dot j2000'].values[-1],\n",
    "#         #             obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['Y_dot j2000'].values[-1],\n",
    "#         #             obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['Z_dot j2000'].values[-1]\n",
    "#         #                         ])\n",
    "#             orbit_data = obj.__dict__['Trajectory_orbfil'][valarc]['data_record']\n",
    "\n",
    "#             for ii, val in enumerate(orbit_data['Date_UTC']):\n",
    "#                 ### Only print the hourly values (when the minute value is 0)\n",
    "#     #             if orbit_data['Date_UTC'][ii].minute==0:\n",
    "#                 row =   f\"{orbit_data['Date_UTC'][ii]}\"         \\\n",
    "#                        +f\"  {orbit_data['X j2000'][ii]:15.5f}\"    \\\n",
    "#                        +f\"  {orbit_data['Y j2000'][ii]:15.5f}\"    \\\n",
    "#                        +f\"  {orbit_data['Z j2000'][ii]:15.5f}\"    \\\n",
    "#                        +f\"  {orbit_data['X_dot j2000'][ii]:15.5f}\"\\\n",
    "#                        +f\"  {orbit_data['Y_dot j2000'][ii]:15.5f}\"\\\n",
    "#                        +f\"  {orbit_data['Z_dot j2000'][ii]:15.5f}\"\\\n",
    "#                        + f\"\\n\"\n",
    "#             #     print(row)\n",
    "#                 file.write(row)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "184px",
    "width": "547px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "205.875px",
    "left": "915px",
    "top": "110.525px",
    "width": "158.6px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "382.85px",
    "left": "645.4px",
    "right": "20px",
    "top": "119px",
    "width": "687px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
