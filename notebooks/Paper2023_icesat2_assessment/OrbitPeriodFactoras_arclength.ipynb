{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c56c198f",
   "metadata": {},
   "source": [
    "1. find the 1st ascending node of first day\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bc4d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ecb5a01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.661598Z",
     "start_time": "2023-08-01T19:59:46.956937Z"
    }
   },
   "outputs": [],
   "source": [
    "from pygeodyn.PYGEODYN import Pygeodyn\n",
    "from pygeodyn.pygeodyn_plot import *\n",
    "\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc31f02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.672398Z",
     "start_time": "2023-08-01T19:59:47.664284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'msis2': {'num': 5, 'model_path': None}, 'jb2008': {'num': 1, 'model_path': None}, 'dtm2020_o': {'num': 3, 'model_path': None}}\n"
     ]
    }
   ],
   "source": [
    "run_list = [\n",
    "                'msis2',\n",
    "                'jb2008',\n",
    "                'dtm2020_o',\n",
    "#                 'tiegcm_oc',\n",
    "#                 'ctipe_oc',\n",
    "#####                 'hasdm_oc',\n",
    "           ]\n",
    "\n",
    "\n",
    "yaxis_range = [-13.7 -.55 ,  -12.6+.25]# ] #full_fig.layout.yaxis2.range\n",
    "\n",
    "\n",
    "CD_type = '2Parc_3hScaled'\n",
    "\n",
    "\n",
    "plot_dir='/data/SatDragModelValidation/notebooks/Paper2023_icesat2_assessment/plots/'\n",
    "\n",
    "\n",
    "dir_modeldat='/data/SatDragModelValidation/data/inputs/atmos_models'\n",
    "run_dict={}\n",
    "for i in run_list:\n",
    "    if i =='msis2':\n",
    "        run_dict[i]={}\n",
    "        run_dict[i]['num'] = 5 \n",
    "        run_dict[i]['model_path'] = None\n",
    "\n",
    "    if i =='dtm2020_o':\n",
    "        run_dict[i]={}\n",
    "        run_dict[i]['num'] = 3 \n",
    "        run_dict[i]['model_path'] = None\n",
    "\n",
    "    if i =='jb2008':\n",
    "        run_dict[i]={}\n",
    "        run_dict[i]['num'] = 1 \n",
    "        run_dict[i]['model_path'] = None\n",
    "\n",
    "    ### PHYSICAL MODELS\n",
    "    if i =='tiegcm_oc':\n",
    "        run_dict[i]={}\n",
    "        run_dict[i]['num'] = 0 \n",
    "        run_dict[i]['model_path'] = dir_modeldat+'/tiegcm/icesat2_oct2018_jan2019'\n",
    "    if i =='ctipe_oc':\n",
    "        run_dict[i]={}\n",
    "        run_dict[i]['num'] = 4 \n",
    "        run_dict[i]['model_path'] = dir_modeldat+'/ctipe/icesat2_oct2018_jan2019'\n",
    "    if i =='gitm':\n",
    "        run_dict[i]={}\n",
    "        run_dict[i]['num'] = 6 \n",
    "        run_dict[i]['model_path'] = dir_modeldat+'/gitm/icesat2_oct2018_jan2019'\n",
    "    if i =='hasdm_oc':\n",
    "        run_dict[i]={}\n",
    "        run_dict[i]['num'] = 2 \n",
    "        run_dict[i]['model_path'] = dir_modeldat+'/hasdm/vishal_icesat2_oct2018_jan2019' #HASDM_OrbitCloud_2018313.01.csv\n",
    "\n",
    "\n",
    "print(run_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c924aeb",
   "metadata": {},
   "source": [
    "## Construct Arc Times\n",
    "\n",
    " - Change the file naming conventions for all file types:\n",
    "     - Input files, and output\n",
    "     - file construction will get messy\n",
    "     - manual input settings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be5958a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.696227Z",
     "start_time": "2023-08-01T19:59:47.673927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2018.313 2018-11-09 00:00:00  to  2018-11-10 00:00:00\n",
      "  2018.314 2018-11-10 00:00:00  to  2018-11-11 00:00:00\n",
      "  2018.315 2018-11-11 00:00:00  to  2018-11-12 00:00:00\n",
      "  2018.316 2018-11-12 00:00:00  to  2018-11-13 00:00:00\n",
      "  2018.317 2018-11-13 00:00:00  to  2018-11-14 00:00:00\n",
      "  2018.318 2018-11-14 00:00:00  to  2018-11-15 00:00:00\n",
      "  2018.319 2018-11-15 00:00:00  to  2018-11-16 00:00:00\n",
      "  2018.320 2018-11-16 00:00:00  to  2018-11-17 00:00:00\n",
      "  2018.321 2018-11-17 00:00:00  to  2018-11-18 00:00:00\n",
      "  2018.322 2018-11-18 00:00:00  to  2018-11-19 00:00:00\n",
      "  2018.323 2018-11-19 00:00:00  to  2018-11-20 00:00:00\n",
      "  2018.324 2018-11-20 00:00:00  to  2018-11-21 00:00:00\n",
      "  2018.325 2018-11-21 00:00:00  to  2018-11-22 00:00:00\n",
      "  2018.326 2018-11-22 00:00:00  to  2018-11-23 00:00:00\n"
     ]
    }
   ],
   "source": [
    "timestart = pd.to_datetime('2018-11-09 00:00:00', format='%Y-%m-%d %H:%M:%S')\n",
    "timeend   = pd.to_datetime('2018-11-23 00:00:00', format='%Y-%m-%d %H:%M:%S')\n",
    "# timeend   = pd.to_datetime('2018-11-11 00:00:00', format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "arc_list         = []\n",
    "epoch_start_24hcenter = []\n",
    "epoch_end_24hcenter   = []\n",
    "\n",
    "itime = timestart\n",
    "while itime < timeend:\n",
    "               \n",
    "    itime_0 = itime\n",
    "    itime = itime + pd.to_timedelta(24,'h')\n",
    "    \n",
    "    arc_list.append(itime_0.strftime('%Y.%j'))\n",
    "    epoch_start_24hcenter.append(itime_0.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    epoch_end_24hcenter.append(itime.strftime(  '%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "    print(' ',itime_0.strftime('%Y.%j'),itime_0, ' to ', itime)        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "152cf0cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.707312Z",
     "start_time": "2023-08-01T19:59:47.697975Z"
    }
   },
   "outputs": [],
   "source": [
    "##### update the epoch start to be 3-hours before and epoch end to be 3 hours later\n",
    "\n",
    "epoch_start_list = []\n",
    "epoch_end_list   = []\n",
    "\n",
    "\n",
    "for i in epoch_start_24hcenter:\n",
    "    itime = pd.to_datetime(i) - pd.to_timedelta(3,'h')\n",
    "    epoch_start_list.append(itime.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "for i in epoch_end_24hcenter:\n",
    "    itime = pd.to_datetime(i) + pd.to_timedelta(3,'h')\n",
    "    epoch_end_list.append(itime.strftime('%Y-%m-%d %H:%M:%S'))\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "355d710c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.716302Z",
     "start_time": "2023-08-01T19:59:47.709157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018.313', '2018.314', '2018.315', '2018.316', '2018.317', '2018.318', '2018.319', '2018.320', '2018.321', '2018.322', '2018.323', '2018.324', '2018.325', '2018.326']\n",
      "\n",
      "['2018-11-08 21:00:00', '2018-11-09 21:00:00', '2018-11-10 21:00:00', '2018-11-11 21:00:00', '2018-11-12 21:00:00', '2018-11-13 21:00:00', '2018-11-14 21:00:00', '2018-11-15 21:00:00', '2018-11-16 21:00:00', '2018-11-17 21:00:00', '2018-11-18 21:00:00', '2018-11-19 21:00:00', '2018-11-20 21:00:00', '2018-11-21 21:00:00']\n",
      "\n",
      "['2018-11-10 03:00:00', '2018-11-11 03:00:00', '2018-11-12 03:00:00', '2018-11-13 03:00:00', '2018-11-14 03:00:00', '2018-11-15 03:00:00', '2018-11-16 03:00:00', '2018-11-17 03:00:00', '2018-11-18 03:00:00', '2018-11-19 03:00:00', '2018-11-20 03:00:00', '2018-11-21 03:00:00', '2018-11-22 03:00:00', '2018-11-23 03:00:00']\n"
     ]
    }
   ],
   "source": [
    "print(arc_list)\n",
    "print()\n",
    "print(epoch_start_list)\n",
    "print()\n",
    "print(epoch_end_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad69903",
   "metadata": {},
   "source": [
    "## Run Orbit Fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80453eab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.723077Z",
     "start_time": "2023-08-01T19:59:47.718508Z"
    }
   },
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3445: UserWarning:\n",
      "\n",
      "To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63649a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.731772Z",
     "start_time": "2023-08-01T19:59:46.701Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from gc import collect as gc_collect\n",
    "import pickle \n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file_raw_ICs = f\"/data/SatDragModelValidation/data/inputs/sat_icesat2/g2b/\"\\\n",
    "          +\"ICESat2_RawEphem_20181108_20181124.txt\"\n",
    "\n",
    "\n",
    "dir_save    =  '/data/SatDragModelValidation/data/outputs_clean/'\\\n",
    "             + 'icesat2/Paper2023_icesat2_assessment/results_2weeks_2Parc_3hScaled/'\n",
    "\n",
    "\n",
    "    \n",
    "if CD_type == '2Parc_3hScaled':\n",
    "    cd_adjustment_boolean = True \n",
    "    hours_between_cd_adj  = 3\n",
    "    file_string           = '2Parc_3hScaled'\n",
    "\n",
    "    pickleName = '_2weeks_2Parc_3hScaled.pkl'\n",
    "    \n",
    "obj = {}\n",
    "for i,den in enumerate(run_list):\n",
    "    settings_icesat2= {\n",
    "                 ### Basic input settings\n",
    "                 'satellite'      : {'input': 'icesat2'},\n",
    "                 'den_model'      : {'input': den},\n",
    "                 'run_type'       : {'input': 'DataReduction_PCE'},\n",
    "                 'run_specifier'  : {'input': '_2Parc_3hScaled'},\n",
    "                 'cd_model'       : {'input': 'BWDRAG'},\n",
    "                 'file_string'    : {'input': file_string},\n",
    "                 'model_data_path': {'input': run_dict[den]['model_path']},\n",
    "                 ### Force Model settings\n",
    "                  'cd_type'               : {'input':\"Fixed_CD\"},\n",
    "                  'cd_value'              : {'input': 2.500000},\n",
    "                  'scaling_factor'        : {'input': False},  # (dria)\n",
    "                  #### Comment for unadjusted run:\n",
    "                  'cd_adjustment_boolean' : {'input':cd_adjustment_boolean },\n",
    "                  'hours_between_cd_adj'  : {'input':hours_between_cd_adj  },\n",
    "                  ### ---------------------------------------\n",
    "                  ### Run\n",
    "                  'step'           : {'input': 10.},\n",
    "                  'orbfil_step'    : {'input': 120.},\n",
    "                  'which_ICfile'   : {'input':file_raw_ICs},\n",
    "                  ###\n",
    "                  'arc'            : {'input':arc_list},\n",
    "                  'epoch_start'    : {'input':epoch_start_list},\n",
    "                  'epoch_stop'     : {'input':epoch_end_list},  \n",
    "                                \n",
    "                  'global_options' : {'input':'pso_2018'},\n",
    "                  ### Request read on raw outputs\n",
    "                  'request_data'   : {'input': ['Trajectory_orbfil', \n",
    "                                               'Density', \n",
    "                                               'Residuals_summary',\n",
    "                                               'DragFile',\n",
    "                                               'AdjustedParams'\n",
    "                                               ]},\n",
    "              ### end dict\n",
    "              }\n",
    "\n",
    "    \n",
    "#     sat = Pygeodyn(settings_icesat2, use_file=False)\n",
    "#     sat.run_arcs()\n",
    "# #     obj[den] =  sat.getData_BigData_lowmemory()\n",
    "#     gc_collect()\n",
    "\n",
    "\n",
    "\n",
    "    pickle_file = dir_save+den+pickleName\n",
    "    if not os.path.exists(pickle_file):\n",
    "        print('Must create pickle file...')\n",
    "        print('   ',  pickle_file)\n",
    "        print('   ', 'Reading Geodyn Data')\n",
    "\n",
    "        ### Load the data into an object\n",
    "        sat = Pygeodyn(settings_icesat2, use_file=False)\n",
    "        obj = sat.getData_BigData_lowmemory()\n",
    "        gc_collect()\n",
    "\n",
    "        #### Pickle the object to save it\n",
    "        print('   ', 'Saving pickle')\n",
    "        filehandler = open(pickle_file, 'wb') \n",
    "        pickle.dump(vars(obj), filehandler)\n",
    "        filehandler.close()\n",
    "        obj = 0\n",
    "        print('   ', 'Saved pickle')\n",
    "\n",
    "obj = {}\n",
    "for i,model in enumerate(run_list):     \n",
    "    ### Load the data if the pickles exist\n",
    "    print()\n",
    "    print()\n",
    "    gc_collect()\n",
    "\n",
    "    pickle_file = dir_save+model+pickleName\n",
    "\n",
    "    filehandler = open(pickle_file, 'rb') \n",
    "    obj[model] = pickle.load(filehandler)\n",
    "    filehandler.close()\n",
    "    print('Loaded data from pickle... ', model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee7976a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.732810Z",
     "start_time": "2023-08-01T19:59:46.704Z"
    }
   },
   "outputs": [],
   "source": [
    "print(arc_list)\n",
    "print(epoch_start_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c675fba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T20:02:22.043291Z",
     "start_time": "2023-07-31T20:02:21.910221Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5b2e78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T20:09:37.370531Z",
     "start_time": "2023-07-31T20:09:37.352044Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ecd52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.733554Z",
     "start_time": "2023-08-01T19:59:46.710Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "choose_model = 'dtm2020_o'\n",
    "\n",
    "for ii,arc in enumerate(obj[choose_model]['global_params']['arc_input'][:2]):\n",
    "    epochstart = obj[choose_model]['global_params']['prms']['epoch_start'][ii]\n",
    "    hrs        = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "    frachours  =(hrs/24)\n",
    "    #\n",
    "    arc_name =arc+('%.3f'%frachours).lstrip('0')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa3e30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T20:02:22.063166Z",
     "start_time": "2023-07-31T20:02:20.915Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c8a9d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.734355Z",
     "start_time": "2023-08-01T19:59:46.713Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_continuous_densities(OBJECT, model_dict, choose_model):\n",
    "    den_dict            =   {}\n",
    "    den_dict['dates']   =   []\n",
    "    den_dict['lat'  ]   =   []\n",
    "    den_dict['den'  ]   =   []\n",
    "    \n",
    "    for ii,arc in enumerate(OBJECT[choose_model]['global_params']['arc_input']):\n",
    "        epochstart = OBJECT[choose_model]['global_params']['prms']['epoch_start'][ii]\n",
    "        hrs        = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "        frachours  =(hrs/24)\n",
    "        #\n",
    "        arc_name =arc+('%.3f'%frachours).lstrip('0')\n",
    "        start_arc = pd.to_datetime(arc, format='%Y.%j')\n",
    "        end_arc = pd.to_datetime(arc, format='%Y.%j')+ pd.to_timedelta(24,'h')\n",
    "        print('arc',arc)\n",
    "        print('start_arc', start_arc)\n",
    "        print('end_arc', end_arc)\n",
    "        print()\n",
    "        ### SELECT ONLY THE MIDDLE 24-HOURS\n",
    "        A = obj[choose_model]['Density'][arc_name].query( \\\n",
    "                f\"{start_arc.year}\"         \\\n",
    "               +f\"{start_arc.month:02d}\"    \\\n",
    "               +f\"{start_arc.day:02d}\"      \\\n",
    "               +f\"{start_arc.hour:02d}\"     \\\n",
    "               +f\"{start_arc.minute:02d}\"   \\\n",
    "               +f\"{start_arc.second:02d}\"   \\\n",
    "               +f\" <= Date < \"                     \\\n",
    "               +f\"{end_arc.year}\"       \\\n",
    "               +f\"{end_arc.month:02d}\"  \\\n",
    "               +f\"{end_arc.day:02d}\"    \\\n",
    "               +f\"{end_arc.hour:02d}\"   \\\n",
    "               +f\"{end_arc.minute:02d}\" \\\n",
    "               +f\"{end_arc.second:02d}\" \\\n",
    "            )\n",
    "\n",
    "        \n",
    "        len_dates = np.shape(A['rho (kg/m**3)'])[0]\n",
    "\n",
    "        for it in np.arange(0,len_dates):\n",
    "            den_dict['den'].append(A['rho (kg/m**3)'].iloc[it])\n",
    "            den_dict['lat'].append(A['Lat'].iloc[it])\n",
    "            den_dict['dates'].append(A['Date'].iloc[it])\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "    return(den_dict)\n",
    "\n",
    "\n",
    "def orbit_avg_generic(Dates, rho, Lats ):\n",
    "\n",
    "    lat     = np.asarray(Lats[:])\n",
    "    time_pd = pd.to_datetime(Dates[:])\n",
    "    # identify ascending equatorial pass as start of orbit\n",
    "    a     = np.logical_and( lat[1:]*lat[0:-1]  < 0 , lat[1:] > lat[0:-1] )\n",
    "    tup_i = a.ravel().nonzero( )\n",
    "    i     = np.squeeze(tup_i)\n",
    "    # initialize arrays\n",
    "    d_avg      = np.zeros(np.size(i))\n",
    "    time_avg   = []  \n",
    "    for j in range(np.size(i)-1):\n",
    "        # average density over orbital passes\n",
    "        d_avg[j]      = np.mean(rho[i[j] : i[j+1]-1  ]  )\n",
    "        # average dates\n",
    "        t1 = pd.to_datetime(time_pd[ i[j]    ])\n",
    "        t2 = pd.to_datetime(time_pd[ i[j+1]-1])\n",
    "        datemiddle = pd.Timestamp(t1) + (pd.Timestamp(t2) - pd.Timestamp(t1)) / 2\n",
    "        time_avg.append(datemiddle)\n",
    "        \n",
    "    return(time_avg, d_avg )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc4b128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad33785e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.735174Z",
     "start_time": "2023-08-01T19:59:46.718Z"
    }
   },
   "outputs": [],
   "source": [
    "# models_dens = {}\n",
    "# for model in run_dict.keys():\n",
    "#     print('getting continuous densities for ', model)\n",
    "#     models_dens[model] = get_continuous_scaled_densities(obj, run_dict, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd5dfbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.735910Z",
     "start_time": "2023-08-01T19:59:46.721Z"
    }
   },
   "outputs": [],
   "source": [
    "models_dens = {}\n",
    "\n",
    "for model in run_dict.keys():\n",
    "    \n",
    "    print('---Getting continuous densities for ', model)\n",
    "    models_dens[model] = get_continuous_densities(obj, run_dict, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefcff48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.736640Z",
     "start_time": "2023-08-01T19:59:46.725Z"
    }
   },
   "outputs": [],
   "source": [
    "models_dens[model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109c6979",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.737522Z",
     "start_time": "2023-08-01T19:59:46.728Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "###--------------------------------------------------\n",
    "\n",
    "# if CD_type == 'fixed_CD':\n",
    "#     title_text = 'Orbit Fits using CD=2.5'\n",
    "#     fig_file   = '3hrArcs_fixedCD_2p5.jpg'\n",
    "# if CD_type == 'scale3hr':\n",
    "#     title_text = '3-hour Debiased Orbit Fits'\n",
    "#     fig_file   = '3hrArcs_3hrScaled.jpg'\n",
    "if CD_type == 'scale6hr':\n",
    "    title_text = '6-hour Debiased Orbit Fits'\n",
    "    fig_file   = '6hrArcs_6hrScaled.jpg'\n",
    "\n",
    "###--------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_all_nokp(fig, obj_m1, plot_num, den_dict ):\n",
    "\n",
    "    ####  Get plot Parameters for this model\n",
    "    model_m1 = obj_m1['global_params']['prms']['den_model']\n",
    "    col = get_plot_params( model_m1)\n",
    "\n",
    "    if model!='hasdm_oc':\n",
    "        opac_val = 1\n",
    "    else:\n",
    "        opac_val = 1\n",
    "\n",
    "    dateplot   = []\n",
    "    rms_totals = []\n",
    "\n",
    "#### Arc Background \n",
    "    for ii,arc in enumerate(obj_m1['global_params']['arc_input']):\n",
    "        epochstart = obj_m1['global_params']['prms']['epoch_start'][ii]\n",
    "        hrs = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "        frachours =(hrs/24)\n",
    "        #\n",
    "        arc =arc+('%.3f'%frachours).lstrip('0')\n",
    "        dateplot.append(pd.to_datetime(datetime.datetime( int(arc.split('.')[0]), 1, 1) \n",
    "                                     + datetime.timedelta(int(arc.split('.')[1]))\n",
    "                                     - datetime.timedelta(days=1) \n",
    "                                     + datetime.timedelta(hours=hrs) ))\n",
    "        rms_totals.append(obj_m1['Statistics'][arc]['T_RMS'].values[0])\n",
    "\n",
    "\n",
    "        ### -----------------------------------------------------------------------------------------------------\n",
    "        ###     In Track Residuals\n",
    "        data_resids = obj_m1['OrbitResids'][arc]['resids']\n",
    "        fig.add_trace(go.Scattergl(x=data_resids['Date'][::5],\n",
    "                                   y=data_resids['T'][::5],\n",
    "                                   ###   name= model_m1,\n",
    "                                     mode='markers+lines',\n",
    "                                     opacity=opac_val,\n",
    "                                         marker=dict(color=col,size=2),\n",
    "                                         line = dict( color = col, width=2),\n",
    "                                     showlegend=False),\n",
    "                                     secondary_y=False, row=2, col=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    ### -----------------------------------------------------------------------------------------------------\n",
    "    ###     TOTAL RMS\n",
    "#             print(rms_totals)\n",
    "    if ii == 14:\n",
    "        print(model_m1, \"mean rms_totals\",np.mean(rms_totals))\n",
    "\n",
    "    fig.add_trace(go.Scattergl(x=dateplot,\n",
    "                               y=rms_totals,\n",
    "                                   ###e= 'NTW '+model_m1,\n",
    "                               mode='markers+lines',\n",
    "                                     opacity=opac_val,\n",
    "                                     marker=dict(color=col,size=6),\n",
    "                                     line = dict(shape='hvh', dash ='solid', color = col, width=2),\n",
    "                               showlegend=False),row=3, col=1)\n",
    "\n",
    "    (time_avg, d_avg ) = orbit_avg_generic(den_dict['dates'],\n",
    "                                       den_dict['den'],\n",
    "                                       den_dict['lat'])\n",
    "\n",
    "    ### -----------------------------------------------------------------------------------------------------\n",
    "    ###     Orbit Averaged Density\n",
    "    fig.add_trace(go.Scattergl(x=time_avg,\n",
    "                               y=d_avg,\n",
    "                               ### name= model_m1,\n",
    "                               mode='markers+lines',\n",
    "                               opacity=opac_val,\n",
    "                                   marker=dict(color=col,size=2),\n",
    "                                   line = dict(dash ='solid', color = col, width=2),\n",
    "                               showlegend=False), row=1, col=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# full_fig = fig.full_figure_for_development()\n",
    "\n",
    "#     if plot_num == 1 or plot_num == 0:\n",
    "\n",
    "\n",
    "\n",
    "    return(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=3, cols=1,\n",
    "#                     subplot_titles=([ ' ', ]),\n",
    "                    #                     \n",
    "                    specs=[#[ {\"secondary_y\": True} ],\n",
    "                           [ {\"secondary_y\": False} ],\n",
    "                           [ {\"secondary_y\": False} ],\n",
    "                           [ {\"secondary_y\": False} ]],\n",
    "                    #\n",
    "                    vertical_spacing = 0.08,\n",
    "                    shared_xaxes=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for model in run_dict.keys():\n",
    "    fig = plot_all_nokp(fig, obj[model],  run_dict[model], models_dens[model])\n",
    "\n",
    "\n",
    "#######################################################\n",
    "font_dict=dict(family='Arial',size=15,color='black')\n",
    "#######################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in [1,2,3]:\n",
    "    fig.update_xaxes(### LINE at axis border\n",
    "                      showline=True,\n",
    "                      showticklabels=True,\n",
    "                      linecolor='black',\n",
    "                      linewidth=1,\n",
    "                     ### Major ticks\n",
    "                      ticks='inside',\n",
    "                      tickfont=font_dict,\n",
    "                      mirror=True,\n",
    "                      tickwidth=2,\n",
    "                      ticklen=9,\n",
    "                      tickcolor='grey',\n",
    "                      tick0=\"2018-11-9\" ,\n",
    "                      dtick=86400000.0*1,    # milliseconds in a day, every 7 days\n",
    "#                       tickformat='%m/%d',\n",
    "                    ticklabelstep=2,\n",
    "                      #### Minor Ticks\n",
    "                       minor=dict(\n",
    "                         dtick=86400000.0, # milliseconds in a day\n",
    "                         tickwidth=1,\n",
    "                         ticklen=4,\n",
    "                         tickcolor='grey',\n",
    "                         ticks='inside'),\n",
    "                      ### GRID\n",
    "                       gridcolor='gainsboro',\n",
    "                       gridwidth=1,\n",
    "                       layer='above traces',\n",
    "                       tickangle=0,\n",
    "                       row=i, col=1)\n",
    "    fig.update_yaxes(showline=True,      # add line at x=0\n",
    "                         showticklabels=True,\n",
    "                         linecolor='black',  # line color\n",
    "                         linewidth=1,        # line size\n",
    "                     ticks='inside',     # ticks outside axis\n",
    "                     tickfont=font_dict, # tick label font\n",
    "                     mirror='allticks',  # add ticks to top/right axes\n",
    "                     tickwidth=1,      # tick width\n",
    "                     tickcolor='black',  # tick color\n",
    "                     gridcolor='gainsboro',\n",
    "                     gridwidth=1,\n",
    "                     layer='above traces',\n",
    "                     row=i, col=1)\n",
    "\n",
    "###\n",
    "### DENSITY AXIS\n",
    "fig.update_yaxes(title_text=r\"$\\text{Orbit Avg. Density } (\\frac{kg}{m^3})$\", \n",
    "                 type=\"log\", \n",
    "#                          range=yaxis2_range, \n",
    "                 exponentformat= 'power',row=1, col=1)\n",
    "###\n",
    "### InTrack Residual Axis\n",
    "fig.update_yaxes( title=r\"$\\text{In-Track Residuals (m)}$\",\n",
    "#                          range=yaxis3_range, \n",
    "                 exponentformat= 'power',row=2, col=1)\n",
    "###\n",
    "### RMS AXIS\n",
    "fig.update_yaxes( title=r\"$\\text{In-Track RMSe (m)}$\" ,type=\"linear\" , exponentformat= 'power',\n",
    "#                           range=yaxis4_range, \n",
    "                 row=3, col=1)\n",
    "###\n",
    "###  DATE on Final x-Axis only\n",
    "fig.update_xaxes(#title=r\"$\\text{Date}$\", \n",
    "                 range=[pd.to_datetime( \"181108-160000\", format='%y%m%d-%H%M%S'),\n",
    "                        pd.to_datetime( \"181123-120000\", format='%y%m%d-%H%M%S')],\n",
    "                 row=3, col=1)\n",
    "modelnames=[]\n",
    "modelcolors = []\n",
    "#### LEGEND ####\n",
    "for model in run_dict.keys():\n",
    "    if model == 'msis2':\n",
    "        modelnames.append(\"MSISe2\")\n",
    "        modelcolors.append(col_msis2)\n",
    "\n",
    "    elif model == 'dtm2020_o':\n",
    "        modelnames.append(\"DTM2020\")\n",
    "        modelcolors.append(col_dtm2020)\n",
    "\n",
    "    elif model == 'jb2008':\n",
    "        modelnames.append(\"JB2008\")\n",
    "        modelcolors.append(col_jb2008)\n",
    "\n",
    "    elif model == 'tiegcm_oc':\n",
    "        modelnames.append(\"TIEGCM\")\n",
    "        modelcolors.append(col_tiegcm_oc)\n",
    "\n",
    "    elif model == 'hasdm_oc':\n",
    "        modelnames.append(\"HASDM\")\n",
    "        modelcolors.append(col_hasdm_oc)\n",
    "\n",
    "    elif model == 'ctipe_oc':\n",
    "        modelnames.append(\"CTIPe\")\n",
    "        modelcolors.append(col_ctipe_oc)\n",
    "\n",
    "    elif model == 'gitm':\n",
    "        modelnames.append(\"GITM\")\n",
    "        modelcolors.append(col_gitm)\n",
    "df = pd.DataFrame({\"starts_colors\": modelcolors\n",
    "                                    })\n",
    "fig.update_traces(showlegend=False).add_traces(\n",
    "    [   go.Scattergl(name=modelnames[i], \n",
    "               x=[pd.to_datetime( \"181107-000000\", format='%y%m%d-%H%M%S')],\n",
    "               mode='lines',\n",
    "               line = dict(shape = 'hv',  width=10),\n",
    "               marker_color=c, \n",
    "               showlegend=True)\n",
    "        for i,c in enumerate((df.loc[:,[\"starts_colors\"]].values.ravel()))])\n",
    "## Legend Control\n",
    "fig.update_layout(legend=dict(\n",
    "    yanchor=\"top\",\n",
    "    y=1.05,\n",
    "    xanchor=\"center\",\n",
    "    x=.7,\n",
    "    orientation=\"h\",\n",
    "        font=font_dict      ,\n",
    "        bgcolor=\"white\",\n",
    "        bordercolor=\"darkgrey\",\n",
    "        borderwidth=0.8,\n",
    "    )  )\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "#                   title = '',\n",
    "                  autosize=False,    width=1000,    height=500,\n",
    "                  legend= {'itemsizing': 'trace'},\n",
    "                  font=font_dict,\n",
    "                  plot_bgcolor='white', \n",
    "                 )\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        #'text': title_text,\n",
    "        'y':0.935,\n",
    "        'x':0.22,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "\n",
    "    \n",
    "    \n",
    "fig.update_layout(\n",
    "                  autosize=False,    width=1000,    height=950,\n",
    "                  legend= {'itemsizing': 'trace'},\n",
    "                  font=font_dict,\n",
    "                  plot_bgcolor='white', \n",
    "                 )\n",
    "fig.update_annotations(font_size=14)  # Increase size of subplot title\n",
    "\n",
    "fig.show(#renderer=\"jpg\",\n",
    "         config=dict({\n",
    "            'displayModeBar': False,\n",
    "            'responsive': False,\n",
    "            'staticPlot': False,\n",
    "            'displaylogo': False,\n",
    "            'showTips': False,\n",
    "            }))\n",
    "\n",
    "\n",
    "# pio.write_image(fig, plot_dir+fig_file, scale=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478d5602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c81d0b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.738263Z",
     "start_time": "2023-08-01T19:59:46.732Z"
    }
   },
   "outputs": [],
   "source": [
    "if CD_type == 'fixed_CD':\n",
    "    import sys\n",
    "    \n",
    "    print('The below plots only apply to the scaling factors.')\n",
    "    sys.exit(0)\n",
    "    \n",
    "else:\n",
    "    print('proceed to scaling factors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9458eea7",
   "metadata": {},
   "source": [
    "# Scaling Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a160c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.739000Z",
     "start_time": "2023-08-01T19:59:46.736Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_percent_change(a, b):\n",
    "    from numpy import absolute as np_abs\n",
    "        \n",
    "    return(  ( (b-a)/np_abs(a) )*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4168504",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.739799Z",
     "start_time": "2023-08-01T19:59:46.739Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "def plot__ScalingFactor(fig, obj_m1, model_dict ):\n",
    "\n",
    "    cd_apriori  = 2.5\n",
    "\n",
    "    ####  Get plot Parameters for this model\n",
    "    model_m1 = obj_m1['global_params']['prms']['den_model']\n",
    "    col = get_plot_params( model_m1)\n",
    "    dateplot = []\n",
    "    rms_totals = []\n",
    "\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=model_dict['ScalingFactor_times'],\n",
    "                           y=model_dict['percent_change'],\n",
    "                           name= model,\n",
    "                           mode='markers+lines',\n",
    "                           opacity=1,\n",
    "                               marker=dict(color=col, size=6 ),\n",
    "                           line = dict(shape = 'hvh', color = col, width=2),\n",
    "                           showlegend=False),\n",
    "                           secondary_y=False,row=1, col=1)\n",
    "\n",
    "# full_fig = fig.full_figure_for_development()\n",
    "\n",
    "    if model_m1 == 'jb2008':\n",
    "\n",
    "        fig.update_yaxes( title=r\"Scaling Factor as % change\",\n",
    "                 exponentformat= 'power',row=1, col=1)\n",
    "\n",
    "    return(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### -----------------------------------------------------------------------------------------------------\n",
    "### -----------------------------------------------------------------------------------------------------\n",
    "### -----------------------------------------------------------------------------------------------------\n",
    "### -----------------------------------------------------------------------------------------------------\n",
    "### -----------------------------------------------------------------------------------------------------\n",
    "\n",
    "ROWS_NUM = 1\n",
    "fig = make_subplots(rows=ROWS_NUM, cols=1,\n",
    "                    #                     \n",
    "                    shared_xaxes=True)\n",
    "\n",
    "# obj[den] = vars(obj[den])\n",
    "# satid = int(obj['jb2008']['global_params']['prms']['sat_ID'])\n",
    "satid = int(obj[den]['global_params']['prms']['sat_ID'])\n",
    "for plot_num, model in enumerate(run_list):\n",
    "    ScalingFactors      = []\n",
    "    ScalingFactor_times = []\n",
    "    PercChange          = []\n",
    "    \n",
    "    for ii,arc in enumerate(obj[den]['global_params']['arc_input']):\n",
    "        epochstart = obj[den]['global_params']['prms']['epoch_start'][ii]\n",
    "        hrs = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "        frachours =(hrs/24)\n",
    "        #\n",
    "        arc =arc+('%.3f'%frachours).lstrip('0')\n",
    "#         dateplot.append(pd.to_datetime(datetime.datetime( int(arc.split('.')[0]), 1, 1) \n",
    "#                                      + datetime.timedelta(int(arc.split('.')[1]))\n",
    "#                                      - datetime.timedelta(days=1) \n",
    "#                                      + datetime.timedelta(hours=hrs) ))\n",
    "    \n",
    "        iters = int(obj[model]['run_parameters'+arc]['total_iterations'])\n",
    "        for iit, itime in enumerate(obj[model]['AdjustedParams'][arc][iters][satid]['0CD'].keys()):\n",
    "#             print(iit)\n",
    "            if iit == 0 or iit==9:\n",
    "                pass\n",
    "            else:\n",
    "                CURRENT_VALUE = obj[model]['AdjustedParams'][arc][iters][satid]['0CD'][itime]['CURRENT_VALUE']\n",
    "                APRIORI_VALUE = obj[model]['AdjustedParams'][arc][iters][satid]['0CD'][itime]['APRIORI_VALUE']\n",
    "                ScalingFactors.append(CURRENT_VALUE/APRIORI_VALUE)\n",
    "                ScalingFactor_times.append(itime - datetime.timedelta(hours=3) )\n",
    "                PercChange.append(calc_percent_change(APRIORI_VALUE, CURRENT_VALUE))\n",
    "            \n",
    "    run_dict[model]['ScalingFactor_times'] = ScalingFactor_times\n",
    "    run_dict[model]['ScalingFactors']      = ScalingFactors\n",
    "\n",
    "    run_dict[model]['percent_change']      = PercChange\n",
    "\n",
    "# for model in run_dict.keys():\n",
    "#     fig = plot__ScalingFactor(fig, obj[model],  run_dict[model] )\n",
    "\n",
    "\n",
    "#######################################################\n",
    "font_dict=dict(family='Arial',size=16,color='black')\n",
    "#######################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for i in [1]:\n",
    "#     fig.update_xaxes(### LINE at axis border\n",
    "#                       showline=True,\n",
    "#                       showticklabels=True,\n",
    "#                       linecolor='black',\n",
    "#                       linewidth=1,\n",
    "#                      ### Major ticks\n",
    "#                       ticks='inside',\n",
    "#                       tickfont=font_dict,\n",
    "#                       mirror=True,\n",
    "#                       tickwidth=2,\n",
    "#                       ticklen=9,\n",
    "#                       tickcolor='grey',\n",
    "#                       tick0=\"2018-11-9\" ,\n",
    "#                       dtick=86400000.0*1,    # milliseconds in a day, every 7 days\n",
    "# #                       tickformat='%m/%d',\n",
    "#                     ticklabelstep=2,\n",
    "#                       #### Minor Ticks\n",
    "#                        minor=dict(\n",
    "#                          dtick=86400000.0, # milliseconds in a day\n",
    "#                          tickwidth=1,\n",
    "#                          ticklen=4,\n",
    "#                          tickcolor='grey',\n",
    "#                          ticks='inside'),\n",
    "#                       ### GRID\n",
    "#                        gridcolor='gainsboro',\n",
    "#                        gridwidth=1,\n",
    "#                        layer='above traces',\n",
    "#                        tickangle=0,\n",
    "#                        row=i, col=1)\n",
    "#     fig.update_yaxes(showline=True,      # add line at x=0\n",
    "#                          showticklabels=True,\n",
    "#                          linecolor='black',  # line color\n",
    "#                          linewidth=1,        # line size\n",
    "#                      ticks='inside',     # ticks outside axis\n",
    "#                      tickfont=font_dict, # tick label font\n",
    "#                      mirror='allticks',  # add ticks to top/right axes\n",
    "#                      tickwidth=1,      # tick width\n",
    "#                      tickcolor='black',  # tick color\n",
    "#                      gridcolor='gainsboro',\n",
    "#                      gridwidth=1,\n",
    "#                      layer='above traces',\n",
    "#                      row=i, col=1)\n",
    "\n",
    "\n",
    "\n",
    "# fig.update_layout(\n",
    "# #                   title = '',\n",
    "#                   autosize=False,    width=1000,    height=450,\n",
    "#                   legend= {'itemsizing': 'trace'},\n",
    "#                   font=font_dict,\n",
    "#                   plot_bgcolor='white', \n",
    "#                  )\n",
    "# fig.update_annotations(font_size=14)  # Increase size of subplot title\n",
    "\n",
    "# fig.show(#renderer=\"jpg\",\n",
    "#          config=dict({\n",
    "#             'displayModeBar': False,\n",
    "#             'responsive': False,\n",
    "#             'staticPlot': True,\n",
    "#             'displaylogo': False,\n",
    "#             'showTips': False,\n",
    "#             }))\n",
    "\n",
    "### pio.write_image(fig, plot_dir+'24hourScalingFactors.jpg', scale=5)\n",
    "\n",
    "for model in run_dict.keys():\n",
    "    print(f\"{model}   {np.mean(run_dict[model]['percent_change'])}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963070a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.740527Z",
     "start_time": "2023-08-01T19:59:46.743Z"
    }
   },
   "outputs": [],
   "source": [
    "obj[model]['AdjustedParams'][arc][iters][satid]['0CD'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e6c34f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.741254Z",
     "start_time": "2023-08-01T19:59:46.746Z"
    }
   },
   "outputs": [],
   "source": [
    "ScalingFactor_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac28f12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.741982Z",
     "start_time": "2023-08-01T19:59:46.749Z"
    }
   },
   "outputs": [],
   "source": [
    "obj[model]['AdjustedParams'][arc][iters][satid]['0CD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c6f6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.742830Z",
     "start_time": "2023-08-01T19:59:46.753Z"
    }
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "def read_nc_file( filename, variables):\n",
    "    ''' This function reads the TIEGCM .nc files and saves the given input variables to a dictionary.\n",
    "        The breakloop feature is here so that if the file doesn't exist the code can still continue.  '''\n",
    "    status = os.path.exists(filename)\n",
    "    \n",
    "    if status == True:\n",
    "        data = {}\n",
    "        for i, var_names in enumerate(variables):\n",
    "            ncid =  Dataset(filename,\"r+\", format=\"NETCDF4\")# filename must be a string\n",
    "            varData = ncid.variables\n",
    "            data[var_names] = np.array(varData[var_names])  \n",
    "    elif status == False:\n",
    "        print('No File Found', filename )\n",
    "        breakloop = True\n",
    "        data = 0\n",
    "        return( data , breakloop)\n",
    "    breakloop = False\n",
    "    return(data,breakloop )\n",
    "\n",
    "\n",
    "arc_list_nc = []\n",
    "\n",
    "arc_list_18 = np.arange(292,366)\n",
    "for i in arc_list_18:\n",
    "    val = '2018'+str(i)\n",
    "    arc_list_nc.append(int(val))\n",
    "    \n",
    "    #     print(val)\n",
    "    \n",
    "arc_list_19 = np.arange(1,10)\n",
    "for i in arc_list_19:\n",
    "    val = '201900'+str(i)\n",
    "    arc_list_nc.append(int(val))\n",
    "\n",
    "path =  \"/data/SatDragModelValidation/data/inputs/atmos_models/geo_phys_indicies/\"\n",
    "path_to_f107 = path+ 'gpi_1960001-2021243_f107aDaily.nc'\n",
    "variables = ['year_day', 'f107d', 'f107a', 'kp']\n",
    "f107_data = read_nc_file(path_to_f107, variables)\n",
    "\n",
    "date = []\n",
    "kp_list = []\n",
    "f107d_list = []\n",
    "f107a_list  = []\n",
    "date_3hr = []\n",
    "doy_list    = []\n",
    "\n",
    "\n",
    "\n",
    "for i,val in enumerate(arc_list_nc):\n",
    "    \n",
    "    index = f107_data[0]['year_day']==val\n",
    "    kp_list.append(f107_data[0]['kp'][index][0])\n",
    "    f107d_list.append(f107_data[0]['f107d'][index][0])\n",
    "    f107a_list.append(f107_data[0]['f107a'][index][0])\n",
    "    doy_list.append(str(f107_data[0]['year_day'][index][0])[-3:])\n",
    "\n",
    "    date.append(pd.to_datetime( str(val), format='%Y%j'))\n",
    "\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=0))\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=3))\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=6))\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=9))\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=12))\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=15))\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=18))\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=21))\n",
    "#     date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=24))\n",
    "    \n",
    "kp_expand = []\n",
    "for i in kp_list:\n",
    "    for ii in i:\n",
    "        kp_expand.append(ii)\n",
    "        \n",
    "        \n",
    "        \n",
    "solar_fluxes = {}\n",
    "solar_fluxes['f107d_list'] = f107d_list\n",
    "solar_fluxes['f107a_list'] = f107a_list\n",
    "solar_fluxes['date']       = date\n",
    "solar_fluxes['date_3hr']   = date_3hr\n",
    "solar_fluxes['kp_expand']  = kp_expand\n",
    "\n",
    "f107d_earth = []\n",
    "f107a_earth = []\n",
    "######################################################################### \n",
    "##### Account for the F10.7 at earth (instead of referenced at 1AU) #####\n",
    "######################################################################### \n",
    "\n",
    "for i_doy,val_doy in enumerate(doy_list):\n",
    "    iday = int(val_doy)\n",
    "    theta0 = 2 * np.pi * (iday)/365.\n",
    "    sfeps = 1.000110 + 0.034221*np.cos(theta0)+0.001280* np.sin(theta0) +0.000719*np.cos(2.*theta0)+0.000077*np.sin(2.*theta0)\n",
    "\n",
    "    f107d_earth.append(sfeps * solar_fluxes['f107d_list'][i_doy])\n",
    "    f107a_earth.append(sfeps * solar_fluxes['f107a_list'][i_doy])\n",
    "\n",
    "solar_fluxes['f107d_earth'] = f107d_earth\n",
    "solar_fluxes['f107a_earth'] = f107a_earth\n",
    "\n",
    "\n",
    "\n",
    "### Prepare RMS total Plot arrays\n",
    "\n",
    "arc_listlist=[  ['2018.292', '2018.293', '2018.294', '2018.295', '2018.296', \n",
    "                 '2018.297', '2018.298', '2018.299' ],                  \n",
    "                #\n",
    "                ['2018.304', '2018.305', '2018.306', '2018.307', '2018.308' ],  \n",
    "                #\n",
    "                ['2018.313', '2018.314', '2018.315', '2018.316', '2018.317',\n",
    "                 '2018.318', '2018.319', '2018.320', '2018.321', '2018.322',\n",
    "                 '2018.323', '2018.324', '2018.325', '2018.326', '2018.327' ],  \n",
    "                #\n",
    "                ['2018.335', '2018.336', '2018.337' ],  \n",
    "                #\n",
    "                ['2018.349', '2018.350', '2018.351', '2018.352' ],  \n",
    "                #\n",
    "                ['2018.356', '2018.357', '2018.358' ],  \n",
    "                #\n",
    "                ['2018.365', '2019.001', '2019.002', '2019.003', '2019.004', \n",
    "                 '2019.005', '2019.006', '2019.007', '2019.008',\n",
    "                '2019.009'],  \n",
    "                ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d53393e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.743652Z",
     "start_time": "2023-08-01T19:59:46.756Z"
    }
   },
   "outputs": [],
   "source": [
    "#### SCALE THE DENSITIES:\n",
    "\n",
    "model_fill = 'dtm2020_o'\n",
    "\n",
    "\n",
    "\n",
    "def get_continuous_scaled_densities(OBJECT, model_dict, choose_model):\n",
    "    den_dict                =   {}\n",
    "    den_dict['dates'    ]   =   []\n",
    "    den_dict['lat'      ]   =   []\n",
    "#     den_dict['denscaled']   =   []\n",
    "    den_dict['dens']   =   []\n",
    "    \n",
    "    for ii,arc in enumerate(OBJECT[choose_model]['global_params']['arc_input']):\n",
    "        epochstart = OBJECT[choose_model]['global_params']['prms']['epoch_start'][ii]\n",
    "        hrs        = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "        frachours  =(hrs/24)\n",
    "        #\n",
    "        arc_name =arc+('%.3f'%frachours).lstrip('0')\n",
    "        start_arc = pd.to_datetime(arc, format='%Y.%j')\n",
    "        end_arc = pd.to_datetime(arc, format='%Y.%j')+ pd.to_timedelta(24,'h')\n",
    "        print('arc',arc)\n",
    "        print('start_arc', start_arc)\n",
    "        print('end_arc', end_arc)\n",
    "        print()\n",
    "        ### SELECT ONLY THE MIDDLE 24-HOURS\n",
    "        A = OBJECT[choose_model]['Density'][arc_name].query( \\\n",
    "                f\"{start_arc.year}\"         \\\n",
    "               +f\"{start_arc.month:02d}\"    \\\n",
    "               +f\"{start_arc.day:02d}\"      \\\n",
    "               +f\"{start_arc.hour:02d}\"     \\\n",
    "               +f\"{start_arc.minute:02d}\"   \\\n",
    "               +f\"{start_arc.second:02d}\"   \\\n",
    "               +f\" <= Date < \"                     \\\n",
    "               +f\"{end_arc.year}\"       \\\n",
    "               +f\"{end_arc.month:02d}\"  \\\n",
    "               +f\"{end_arc.day:02d}\"    \\\n",
    "               +f\"{end_arc.hour:02d}\"   \\\n",
    "               +f\"{end_arc.minute:02d}\" \\\n",
    "               +f\"{end_arc.second:02d}\" \\\n",
    "            )\n",
    "        len_dates = np.shape(A['rho (kg/m**3)'])[0]\n",
    "\n",
    "        #24hour period\n",
    "        for it in np.arange(0,len_dates):\n",
    "#             den_dict['denscaled'].append(\\\n",
    "#                     OBJECT[choose_model]['Density'][arc]['rho (kg/m**3)'].iloc[it]\\\n",
    "#                     *model_dict[choose_model]['ScalingFactors'][ii])\n",
    "            den_dict['dens'].append(\\\n",
    "                    A['rho (kg/m**3)'].iloc[it])\n",
    "            den_dict['lat'].append(\\\n",
    "                    A['Lat'].iloc[it])\n",
    "            den_dict['dates'].append(A['Date'].iloc[it])\n",
    "\n",
    "            \n",
    "            \n",
    "    sfdate_list = model_dict[choose_model]['ScalingFactor_times']\n",
    "    sf_list     = model_dict[choose_model]['ScalingFactors']\n",
    "    df          = pd.DataFrame.from_dict(den_dict)\n",
    "\n",
    "\n",
    "    scaled_densities = []\n",
    "    for isf, valsf in enumerate(sfdate_list):\n",
    "    #     print(isf)\n",
    "        if isf == 0:\n",
    "            A=df.query(f\" dates <= \"              \\\n",
    "                 +f\"{sfdate_list[isf].year}\"       \\\n",
    "                 +f\"{sfdate_list[isf].month:02d}\"  \\\n",
    "                 +f\"{sfdate_list[isf].day:02d}\"    \\\n",
    "                 +f\"{sfdate_list[isf].hour:02d}\"   \\\n",
    "                 +f\"{sfdate_list[isf].minute:02d}\" \\\n",
    "                 +f\"{sfdate_list[isf].second:02d}\" \\\n",
    "                )\n",
    "            print('First index:', A)\n",
    "\n",
    "        elif isf == len(sfdate_list)-1:\n",
    "            A=df.query( f\"{sfdate_list[isf-1].year}\"       \\\n",
    "                       +f\"{sfdate_list[isf-1].month:02d}\"  \\\n",
    "                       +f\"{sfdate_list[isf-1].day:02d}\"    \\\n",
    "                       +f\"{sfdate_list[isf-1].hour:02d}\"   \\\n",
    "                       +f\"{sfdate_list[isf-1].minute:02d}\" \\\n",
    "                       +f\"{sfdate_list[isf-1].second:02d}\" \\\n",
    "                       +f\" <= dates \"                     \\\n",
    "                )\n",
    "            print('Last index:', A)\n",
    "        else:\n",
    "\n",
    "            # select the values of density corresponding to SF datetimes\n",
    "            A=df.query( f\"{sfdate_list[isf].year}\"         \\\n",
    "                       +f\"{sfdate_list[isf].month:02d}\"    \\\n",
    "                       +f\"{sfdate_list[isf].day:02d}\"      \\\n",
    "                       +f\"{sfdate_list[isf].hour:02d}\"     \\\n",
    "                       +f\"{sfdate_list[isf].minute:02d}\"   \\\n",
    "                       +f\"{sfdate_list[isf].second:02d}\"   \\\n",
    "                       +f\" <= dates <= \"                     \\\n",
    "                       +f\"{sfdate_list[isf+1].year}\"       \\\n",
    "                       +f\"{sfdate_list[isf+1].month:02d}\"  \\\n",
    "                       +f\"{sfdate_list[isf+1].day:02d}\"    \\\n",
    "                       +f\"{sfdate_list[isf+1].hour:02d}\"   \\\n",
    "                       +f\"{sfdate_list[isf+1].minute:02d}\" \\\n",
    "                       +f\"{sfdate_list[isf+1].second:02d}\" \\\n",
    "                    )\n",
    "\n",
    "        ## Apply the scaling factor\n",
    "        scaled_densities.extend(A['dens'].values*sf_list[isf])\n",
    "           \n",
    "    den_dict['denscaled'] = scaled_densities\n",
    "            \n",
    "    return(den_dict)\n",
    "\n",
    "\n",
    "\n",
    "models_dens = {}\n",
    "for model in run_dict.keys():\n",
    "    print(model)\n",
    "    models_dens[model] = get_continuous_scaled_densities(obj, run_dict, model)\n",
    "\n",
    "    \n",
    "        \n",
    "print('dates    ',   np.shape(models_dens[model]['dates']))\n",
    "print('dens     ',   np.shape(models_dens[model]['dens']))\n",
    "print('denscaled',   np.shape(models_dens[model]['denscaled']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda302cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.744366Z",
     "start_time": "2023-08-01T19:59:46.759Z"
    }
   },
   "outputs": [],
   "source": [
    "# run_dict[model]['ScalingFactor_times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e48181",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.745095Z",
     "start_time": "2023-08-01T19:59:46.763Z"
    }
   },
   "outputs": [],
   "source": [
    "# models_dens[model]['dates'][-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071e26b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.745820Z",
     "start_time": "2023-08-01T19:59:46.766Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.shape(models_dens[model]['dates'])\n",
    "# np.shape(models_dens[model]['dens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81723564",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T20:14:00.082594Z",
     "start_time": "2023-07-20T20:14:00.054367Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2a58908",
   "metadata": {},
   "source": [
    "# factors and densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd71c45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.746526Z",
     "start_time": "2023-08-01T19:59:46.771Z"
    }
   },
   "outputs": [],
   "source": [
    "# models_dens[model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934655e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.747475Z",
     "start_time": "2023-08-01T19:59:46.774Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "def plot_RhoScaled_andFactors(fig, den_dict, choose_model, model_dict ):\n",
    "\n",
    "    cd_apriori  = 2.5\n",
    "\n",
    "    ####  Get plot Parameters for this model\n",
    "    model_m1 = choose_model\n",
    "    col = get_plot_params( model_m1)\n",
    "    \n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=model_dict['ScalingFactor_times'],\n",
    "                           y=model_dict['percent_change'],\n",
    "                           name= model,\n",
    "                           mode='markers+lines',\n",
    "                           opacity=1,\n",
    "                               marker=dict(color=col, size=6 ),\n",
    "                           line = dict(shape = 'hvh', color = col, width=2),\n",
    "                           showlegend=False),\n",
    "                           secondary_y=False,row=1, col=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    time_avg,dscale_avg = orbit_avg_generic(den_dict['dates'], den_dict['denscaled'], den_dict['lat'])\n",
    "    ### -----------------------------------------------------------------------------------------------------\n",
    "    ###     Orbit Averaged Density\n",
    "    fig.add_trace(go.Scattergl(x=time_avg,\n",
    "                               y=dscale_avg,\n",
    "                               ### name= model_m1,\n",
    "                               mode='markers+lines',\n",
    "                               opacity=1,\n",
    "                                   marker=dict(color=col,size=2),\n",
    "                                   line = dict(dash ='solid', color = col, width=2),\n",
    "                               showlegend=False), row=2, col=1)\n",
    "\n",
    "    time_avg,d_avg = orbit_avg_generic(den_dict['dates'], den_dict['dens'], den_dict['lat'])\n",
    "    ### -----------------------------------------------------------------------------------------------------\n",
    "    ###     Orbit Averaged Density\n",
    "    fig.add_trace(go.Scattergl(x=time_avg,\n",
    "                               y=d_avg,\n",
    "                               ### name= model_m1,\n",
    "                               mode='markers+lines',\n",
    "                               opacity=0.5,\n",
    "                                   marker=dict(color=col,size=1),\n",
    "                                   line = dict(dash ='solid', color = col, width=1),\n",
    "                               showlegend=False), row=2, col=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if model_m1 == 'jb2008':\n",
    "        fig.update_yaxes(title_text=r\"$\\text{Scaled OrbAvg rho } (\\frac{kg}{m^3})$\", \n",
    "                         type=\"log\", \n",
    "                         range=yaxis_range,\n",
    "                         exponentformat= 'power',row=2, col=1)\n",
    "        ###\n",
    "        ###  DATE on Final x-Axis only\n",
    "        fig.update_xaxes(#title=r\"$\\text{Date}$\", \n",
    "                         range=[pd.to_datetime( \"181108-160000\", format='%y%m%d-%H%M%S'),\n",
    "                                pd.to_datetime( \"181123-120000\", format='%y%m%d-%H%M%S')],\n",
    "                         row=1, col=1)\n",
    "\n",
    "\n",
    "    return(fig)\n",
    "\n",
    "\n",
    "### -----------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1,\n",
    "                    #                     \n",
    "                    vertical_spacing = 0.08,\n",
    "                    shared_xaxes=True)\n",
    "\n",
    "for model in run_dict.keys():\n",
    "    fig = plot_RhoScaled_andFactors(fig, models_dens[model], model, run_dict[model] )\n",
    "\n",
    "\n",
    "#######################################################\n",
    "font_dict=dict(family='Arial',size=16,color='black')\n",
    "#######################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in [1,2]:\n",
    "    fig.update_xaxes(### LINE at axis border\n",
    "                      showline=True,\n",
    "                      showticklabels=True,\n",
    "                      linecolor='black',\n",
    "                      linewidth=1,\n",
    "                     ### Major ticks\n",
    "                      ticks='inside',\n",
    "                      tickfont=font_dict,\n",
    "                      mirror=True,\n",
    "                      tickwidth=2,\n",
    "                      ticklen=9,\n",
    "                      tickcolor='grey',\n",
    "                      tick0=\"2018-11-9\" ,\n",
    "                      dtick=86400000.0*2,    # milliseconds in a day, every 7 days\n",
    "                      #### Minor Ticks\n",
    "                       minor=dict(\n",
    "                         dtick=86400000.0, # milliseconds in a day\n",
    "                         tickwidth=1,\n",
    "                         ticklen=4,\n",
    "                         tickcolor='grey',\n",
    "                         ticks='inside'),\n",
    "                      ### GRID\n",
    "                       gridcolor='gainsboro',\n",
    "                       gridwidth=1,\n",
    "                       layer='above traces',\n",
    "                       tickangle=0,\n",
    "                       row=i, col=1)\n",
    "    fig.update_yaxes(showline=True,      # add line at x=0\n",
    "                         showticklabels=True,\n",
    "                         linecolor='black',  # line color\n",
    "                         linewidth=1,        # line size\n",
    "                     ticks='inside',     # ticks outside axis\n",
    "                     tickfont=font_dict, # tick label font\n",
    "                     mirror='allticks',  # add ticks to top/right axes\n",
    "                     tickwidth=1,      # tick width\n",
    "                     tickcolor='black',  # tick color\n",
    "                     gridcolor='gainsboro',\n",
    "                     gridwidth=1,\n",
    "                     layer='above traces',\n",
    "                     row=i, col=1)\n",
    "\n",
    "\n",
    "modelnames=[]\n",
    "modelcolors = []\n",
    "#### LEGEND ####\n",
    "for model in run_dict.keys():\n",
    "    if model == 'msis2':\n",
    "        modelnames.append(\"MSISe2\")\n",
    "        modelcolors.append(col_msis2)\n",
    "\n",
    "    elif model == 'dtm2020_o':\n",
    "        modelnames.append(\"DTM2020\")\n",
    "        modelcolors.append(col_dtm2020)\n",
    "\n",
    "    elif model == 'jb2008':\n",
    "        modelnames.append(\"JB2008\")\n",
    "        modelcolors.append(col_jb2008)\n",
    "\n",
    "    elif model == 'tiegcm_oc':\n",
    "        modelnames.append(\"TIEGCM\")\n",
    "        modelcolors.append(col_tiegcm_oc)\n",
    "\n",
    "    elif model == 'hasdm_oc':\n",
    "        modelnames.append(\"HASDM\")\n",
    "        modelcolors.append(col_hasdm_oc)\n",
    "\n",
    "    elif model == 'ctipe_oc':\n",
    "        modelnames.append(\"CTIPe\")\n",
    "        modelcolors.append(col_ctipe_oc)\n",
    "\n",
    "    elif model == 'gitm':\n",
    "        modelnames.append(\"GITM\")\n",
    "        modelcolors.append(col_gitm)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"starts_colors\": modelcolors\n",
    "                                    })\n",
    "\n",
    "fig.update_traces(showlegend=False).add_traces(\n",
    "    [   go.Scattergl(name=modelnames[i], \n",
    "               x=[pd.to_datetime( \"181107-000000\", format='%y%m%d-%H%M%S')],\n",
    "               mode='lines',\n",
    "               line = dict(shape = 'hv',  width=10),\n",
    "               marker_color=c, \n",
    "               showlegend=True)\n",
    "        for i,c in enumerate((df.loc[:,[\"starts_colors\"]].values.ravel()))])\n",
    "\n",
    "fig.update_layout(legend=dict(\n",
    "    yanchor=\"middle\",\n",
    "    y=0.5,\n",
    "    xanchor=\"center\",\n",
    "    x=1.1,\n",
    "#     x=1.015,\n",
    "        font=font_dict      ,\n",
    "        bgcolor=\"white\",\n",
    "        bordercolor=\"darkgrey\",\n",
    "        borderwidth=0.8,\n",
    "    )  )\n",
    "\n",
    "fig.update_layout(\n",
    "#                   title = '',\n",
    "                  autosize=False,    width=1000,    height=800,\n",
    "                  legend= {'itemsizing': 'trace'},\n",
    "                  font=font_dict,\n",
    "                  plot_bgcolor='white', \n",
    "                 )\n",
    "fig.update_annotations(font_size=14)  # Increase size of subplot title\n",
    "\n",
    "\n",
    "\n",
    "fig.show(#renderer=\"jpg\",\n",
    "         config=dict({\n",
    "            'displayModeBar': False,\n",
    "            'responsive': True,\n",
    "            'staticPlot': False,\n",
    "            'displaylogo': False,\n",
    "            'showTips': False,\n",
    "            }))\n",
    "\n",
    "#     if save_plot_flag:\n",
    "#         pio.write_image(fig, plot_dir+'Assessment_CDAvgAdj.jpg', scale=3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0a6627",
   "metadata": {},
   "source": [
    "## view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac06bb1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.748242Z",
     "start_time": "2023-08-01T19:59:46.778Z"
    }
   },
   "outputs": [],
   "source": [
    "# index3h_1 = 168\n",
    "# index3h_2 = 289-9\n",
    "\n",
    "# ## -Calculate correlation coefficients\n",
    "# #####################################################\n",
    "# run_dict[model]['CorrCoeff']=[]\n",
    "\n",
    "# # dailyKp = []\n",
    "# # for i in kp_expand[index3h_1:index3h_2]:\n",
    "# #     dailyKp.append(np.mean(i))\n",
    "\n",
    "# corrcoeffs = {}\n",
    "# for model in run_dict.keys():\n",
    "#     sf_kplen = []\n",
    "#     for sf in run_dict[model]['ScalingFactors']:\n",
    "#         sf_kplen.append( sf )\n",
    "\n",
    "#     print(model,'----------------')\n",
    "#     corr = np.corrcoef(sf_kplen, kp_expand[index3h_1:index3h_2] ) \n",
    "#     print(f\"   R={corr[0,1]}\")\n",
    "#     run_dict[model]['CorrCoeff'] = corr[0,1]\n",
    "# ######################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91c28e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.749096Z",
     "start_time": "2023-08-01T19:59:46.781Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Simplify Plotting Schemes:\n",
    "# col_msis2     =  \"#2ca02c\"  # 'tab:green'\n",
    "# col_jb2008    =  \"#ff7f0e\"  # 'tab:orange'\n",
    "# col_dtm2020   =  \"#d62728\"  # 'tab:red'\n",
    "# col_tiegcm_oc =  \"#17becf\"  # 'tab:cyan'\n",
    "# col_hasdm_oc  =  \"#1f77b4\"  # 'tab:blue'\n",
    "# col_ctipe_oc  =  \"#9467bd\"  # 'tab:purple'\n",
    "# col_gitm      =  '#e377c2'  # 'tab:pink'\n",
    "\n",
    "# all_cols = [col_jb2008,\n",
    "#             col_dtm2020,\n",
    "#             col_ctipe_oc,\n",
    "#             col_tiegcm_oc,\n",
    "#             col_msis2,\n",
    "# #             col_gitm,\n",
    "#            ]\n",
    "\n",
    "# dailyKp = []\n",
    "\n",
    "# # for i in kp_list[21:37]:\n",
    "# #     dailyKp.append(np.mean(i))\n",
    "\n",
    "# fig = make_subplots(rows=2, cols=2,\n",
    "#                     subplot_titles=([None, \"Correlation with Kp\",\n",
    "#                                      None,  None ]),\n",
    "#                     vertical_spacing = 0.03,\n",
    "#                     horizontal_spacing = 0.02,\n",
    "#                         specs=[[{}, {}],\n",
    "#                                [{},  {}         ]],\n",
    "#                     column_widths=[0.8, 0.2],\n",
    "#                     shared_xaxes=True)\n",
    "\n",
    "# for model in run_dict.keys():\n",
    "#     fig = plot__ScalingFactor(fig, obj[model],  run_dict[model] )\n",
    "\n",
    "    \n",
    "    \n",
    "# fig.add_trace(go.Scatter(x=date_3hr[index3h_1:index3h_2],\n",
    "#                            y=kp_expand[index3h_1:index3h_2] ,\n",
    "# #                            name= 'F107d_1AU',\n",
    "#                            mode='lines',\n",
    "#                            opacity=1,\n",
    "# #                                marker=dict(color='cornflowerblue', size=2 ),\n",
    "#                            line = dict(shape = 'hv',dash='solid', color = 'black', width=2),\n",
    "#                            showlegend=False),\n",
    "#                            secondary_y=False,row=2, col=1)\n",
    "\n",
    "\n",
    "# fig.add_hline(y=0, line_width=1, line_dash=\"dash\", line_color=\"black\", row=1, col=1)\n",
    "\n",
    "# #######################################################\n",
    "# font_dict=dict(family='Arial',size=16,color='black')\n",
    "# #######################################################\n",
    "   \n",
    "\n",
    "# for i in [1,2]:\n",
    "#     if i ==1:\n",
    "#         xlabel=False\n",
    "#     else:\n",
    "#         xlabel=True\n",
    "    \n",
    "#     fig.update_xaxes(### LINE at axis border\n",
    "#                       showline=True,showticklabels=xlabel,\n",
    "#                       linecolor='black',linewidth=1,\n",
    "#                      ### Major ticks\n",
    "#                       ticks='inside',tickfont=font_dict,mirror=True,\n",
    "#                       tickwidth=2,ticklen=9,\n",
    "#                       tickcolor='grey',tick0=\"2018-11-9\" ,\n",
    "#                       dtick=86400000.0*1,    # milliseconds in a day, every 7 days\n",
    "# #                       tickformat='%m/%d',\n",
    "#                     ticklabelstep=2,\n",
    "#                       #### Minor Ticks\n",
    "#                        minor=dict(dtick=86400000.0, # milliseconds in a day\n",
    "#                          tickwidth=1,ticklen=4,\n",
    "#                          tickcolor='grey',ticks='inside'),\n",
    "#                       ### GRID\n",
    "#                        gridcolor='gainsboro',gridwidth=1,\n",
    "#                        layer='above traces',tickangle=0,\n",
    "#                        row=i, col=1)\n",
    "#     fig.update_yaxes(showline=True,      # add line at x=0\n",
    "#                      showticklabels=True,linecolor='black',  \n",
    "#                      linewidth=1,ticks='inside',tickfont=font_dict, \n",
    "#                      mirror='allticks',tickwidth=1,tickcolor='black',\n",
    "#                      gridcolor='gainsboro',gridwidth=1,layer='above traces',\n",
    "#                      row=i, col=1)\n",
    "\n",
    "# fig.update_yaxes( title=\"Kp Index\",\n",
    "#                  range=[-0.5,5],\n",
    "#                  exponentformat= 'power',row=2, col=1)\n",
    "\n",
    "\n",
    "\n",
    "# fig.add_trace(go.Bar(y=[\"JB2008\",\n",
    "#                         \"DTM2020\",\n",
    "#                         \"CTIPe\",\n",
    "#                         \"TIEGCM\",\n",
    "#                         \"MSIS2\",\n",
    "# #                         \"GITM\",\n",
    "#                         ],    \n",
    "#                      x=[run_dict[\"jb2008\"]['CorrCoeff'],\n",
    "#                         run_dict[\"dtm2020_o\"]['CorrCoeff'],\n",
    "#                         run_dict[\"ctipe_oc\"]['CorrCoeff'],\n",
    "#                         run_dict[\"tiegcm_oc\"]['CorrCoeff'],\n",
    "#                         run_dict[\"msis2\"]['CorrCoeff'],\n",
    "# #                         run_dict[\"gitm\"]['CorrCoeff'],\n",
    "#                        ] ,\n",
    "#                      text=[np.round(run_dict[\"jb2008\"]['CorrCoeff'],2)     ,\n",
    "#                            np.round(run_dict[\"dtm2020_o\"]['CorrCoeff'],2)  ,\n",
    "#                            np.round(run_dict[\"ctipe_oc\"]['CorrCoeff'],2)   ,\n",
    "#                            np.round(run_dict[\"tiegcm_oc\"]['CorrCoeff'],2)  ,\n",
    "#                            np.round(run_dict[\"msis2\"]['CorrCoeff'],2)      ,\n",
    "# #                            np.round(run_dict[\"gitm\"]['CorrCoeff'],2)       ,\n",
    "#                        ] ,\n",
    "#                     textposition='outside',\n",
    "#                      textfont=dict(family='Arial',size=13,color='black'),\n",
    "#                 marker_color=all_cols,\n",
    "#                 showlegend=False),row=1, col=2)\n",
    "# fig.update_traces(orientation=\"h\", selector=dict(type='bar'))\n",
    "\n",
    "# fig.add_annotation(x=-0.5,y='MSIS2',\n",
    "#         xref=\"x\",yref=\"y\",\n",
    "#         showarrow=False,\n",
    "#         text='MSIS2',\n",
    "#         font=dict(size=17,color=\"black\"),\n",
    "#         align=\"right\",\n",
    "#         row=1, col=2,\n",
    "#         )\n",
    "# fig.add_annotation(x=-0.5,y='TIEGCM',\n",
    "#         xref=\"x\",yref=\"y\",\n",
    "#         showarrow=False,\n",
    "#         text='TIEGCM',\n",
    "#         font=dict(size=17,color=\"black\"),\n",
    "#         align=\"right\",\n",
    "#         row=1, col=2,\n",
    "#         )\n",
    "# fig.add_annotation(x=-0.5,y='CTIPe',\n",
    "#         xref=\"x\",yref=\"y\",\n",
    "#         showarrow=False,\n",
    "#         text='CTIPe',\n",
    "#         font=dict(size=17,color=\"black\"),\n",
    "#         align=\"right\",\n",
    "#         row=1, col=2,\n",
    "#         )\n",
    "# fig.add_annotation(x=0.5,y='DTM2020',\n",
    "#         xref=\"x\",yref=\"y\",\n",
    "#         showarrow=False,\n",
    "#         text='DTM2020',\n",
    "#         font=dict(size=17,color=\"black\"),\n",
    "#         align=\"left\",\n",
    "#         row=1, col=2,\n",
    "#         )\n",
    "# fig.add_annotation(x=-0.5,y='JB2008',\n",
    "#         xref=\"x\",yref=\"y\",\n",
    "#         showarrow=False,\n",
    "#         text='JB2008',\n",
    "#         font=dict(size=17,color=\"black\"),\n",
    "#         align=\"right\",\n",
    "#         row=1, col=2,\n",
    "#         )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fig.update_xaxes(### LINE at axis border\n",
    "#                   showline=True,showticklabels=True,\n",
    "#                   linecolor='gainsboro',linewidth=1,\n",
    "#                  ### Major ticks\n",
    "#                   ticks='inside',tickfont=dict(family='Arial',size=14,color='black'),mirror=True,\n",
    "#                   tickwidth=2,ticklen=9,\n",
    "#                   tickcolor='white',\n",
    "#                   ### GRID\n",
    "#                    gridcolor='white',gridwidth=1,\n",
    "#                    layer='above traces',\n",
    "#                     row=1, col=2)\n",
    "# fig.update_yaxes(showline=True,      # add line at x=0\n",
    "#                  showticklabels=False,linecolor='gainsboro',  \n",
    "#                  linewidth=1,ticks='inside',tickfont=dict(family='Arial',size=14,color='black'), \n",
    "#                  mirror='allticks',tickwidth=1,tickcolor='gainsboro',\n",
    "#                  gridcolor='gainsboro',gridwidth=1,layer='above traces',\n",
    "#                                     row=1, col=2)\n",
    "\n",
    "# fig.update_xaxes(title=\"R, Pearson Corr. Coeff.\",\n",
    "#                  range=[-1,1.05],\n",
    "#                  titlefont=dict(family='Arial',size=14,color='black'),\n",
    "#                  row=1, col=2)\n",
    "\n",
    "# fig.update_layout(autosize=False,    width=1000,    height=600,\n",
    "#                   legend= {'itemsizing': 'trace'},\n",
    "#                   font=font_dict, plot_bgcolor='white', \n",
    "#                  )\n",
    "# annot = fig['layout']['annotations'][0]\n",
    "# annot['yanchor']='bottom'\n",
    "# annot['y']=1.015\n",
    "# annot['yref']='paper'\n",
    "\n",
    "# fig.update_xaxes(range=[pd.to_datetime( \"181109-000000\", format='%y%m%d-%H%M%S'),\n",
    "#                         pd.to_datetime( \"181123-000000\", format='%y%m%d-%H%M%S')],\n",
    "#                  row=1, col=1)\n",
    "\n",
    "\n",
    "# fig.update_annotations(font_size=17)  # Increase size of subplot title\n",
    "# fig.show(config=config)\n",
    "\n",
    "# ### pio.write_image(fig, plots_dir+'twoweek_fullresult.pdf')\n",
    "# # pio.write_image(fig, plots_dir+'f107_kp_twoweek.jpg', scale=3)\n",
    "\n",
    "# # pio.write_image(fig, plot_dir+'24hourScalingFactors_w_R.jpg', scale=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abdd96a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-31T18:32:55.339Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74e55be",
   "metadata": {},
   "source": [
    "# RETRIEVE DENSITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cb09c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.749857Z",
     "start_time": "2023-08-01T19:59:46.786Z"
    }
   },
   "outputs": [],
   "source": [
    "run_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f3f2de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.750662Z",
     "start_time": "2023-08-01T19:59:46.789Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# def calc_rho_ScaledEnsembleAvg(OBJECT, model_dict):\n",
    "#     dates   = []\n",
    "#     rho_scaledEnsembleAvg = []\n",
    "#     std_scaledEnsembleAvg = []\n",
    "#     avg_lat = []\n",
    "#     for ii,arc in enumerate(OBJECT['jb2008']['global_params']['arc_input']):\n",
    "#         epochstart = OBJECT['jb2008']['global_params']['prms']['epoch_start'][ii]\n",
    "#         hrs = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "#         frachours =(hrs/24)\n",
    "#         arc =arc+('%.3f'%frachours).lstrip('0')\n",
    "#         len_dates = np.shape(OBJECT['jb2008']['Density'][arc]['rho (kg/m**3)'])[0]\n",
    "\n",
    "#         for it in np.arange(0,len_dates):\n",
    "#             avg_it_models = []\n",
    "#             avg_it_lat = []\n",
    "\n",
    "#             for model in model_dict.keys():\n",
    "#                 ### SCALED ENSEMBLE AVERAGE\n",
    "#                 try:\n",
    "#                     avg_it_models.append(OBJECT[model]['Density'][arc]['rho (kg/m**3)'].iloc[it] \\\n",
    "#                                         *model_dict[model]['ScalingFactors'][ii])\n",
    "#                     avg_it_lat.append(OBJECT[model]['Density'][arc]['Lat'].iloc[it])\n",
    "#                 except:\n",
    "#     #                 print(f\"oops {model}, {arc} may not exist\")\n",
    "#                     continue\n",
    "#             dates.append(OBJECT['jb2008']['Density'][arc]['Date'].iloc[it])\n",
    "#             avg_lat.append(np.average(avg_it_lat))\n",
    "\n",
    "\n",
    "#             rho_scaledEnsembleAvg.append(np.average(avg_it_models))    \n",
    "#             std_scaledEnsembleAvg.append(np.std(avg_it_models))\n",
    "\n",
    "#     return(dates  , \n",
    "#            avg_lat,\n",
    "#            rho_scaledEnsembleAvg,\n",
    "#            std_scaledEnsembleAvg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_rho_ScaledEnsembleWgtAvg(OBJECT, model_dict):\n",
    "    \n",
    "    \n",
    "    \n",
    "    dates   = []\n",
    "    rho_scaledEnsembleAvg = []\n",
    "    std_scaledEnsembleAvg = []\n",
    "    list_lat = []\n",
    "    for ii,arc in enumerate(OBJECT[model_fill]['global_params']['arc_input']):\n",
    "        epochstart = OBJECT[model_fill]['global_params']['prms']['epoch_start'][ii]\n",
    "        hrs = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "        frachours =(hrs/24)\n",
    "        \n",
    "        arc_name =arc+('%.3f'%frachours).lstrip('0')\n",
    "        start_arc = pd.to_datetime(arc, format='%Y.%j')\n",
    "        end_arc = pd.to_datetime(arc, format='%Y.%j')+ pd.to_timedelta(24,'h')\n",
    "        print('arc',arc)\n",
    "        print('start_arc', start_arc)\n",
    "        print('end_arc', end_arc)\n",
    "        print()\n",
    "        ### SELECT ONLY THE MIDDLE 24-HOURS\n",
    "        A = OBJECT[model_fill]['Density'][arc_name].query( \\\n",
    "                f\"{start_arc.year}\"         \\\n",
    "               +f\"{start_arc.month:02d}\"    \\\n",
    "               +f\"{start_arc.day:02d}\"      \\\n",
    "               +f\"{start_arc.hour:02d}\"     \\\n",
    "               +f\"{start_arc.minute:02d}\"   \\\n",
    "               +f\"{start_arc.second:02d}\"   \\\n",
    "               +f\" <= Date < \"                     \\\n",
    "               +f\"{end_arc.year}\"       \\\n",
    "               +f\"{end_arc.month:02d}\"  \\\n",
    "               +f\"{end_arc.day:02d}\"    \\\n",
    "               +f\"{end_arc.hour:02d}\"   \\\n",
    "               +f\"{end_arc.minute:02d}\" \\\n",
    "               +f\"{end_arc.second:02d}\" \\\n",
    "            )\n",
    "        len_dates = np.shape(A['rho (kg/m**3)'])[0]\n",
    "\n",
    "        for it in np.arange(0,len_dates):\n",
    "            list_it_models = []\n",
    "            list_it_lat    = []\n",
    "            wgts           = []\n",
    "\n",
    "\n",
    "            for model in model_dict.keys():\n",
    "                A = OBJECT[model]['Density'][arc_name].query( \\\n",
    "                    f\"{start_arc.year}\"         \\\n",
    "                   +f\"{start_arc.month:02d}\"    \\\n",
    "                   +f\"{start_arc.day:02d}\"      \\\n",
    "                   +f\"{start_arc.hour:02d}\"     \\\n",
    "                   +f\"{start_arc.minute:02d}\"   \\\n",
    "                   +f\"{start_arc.second:02d}\"   \\\n",
    "                   +f\" <= Date < \"                     \\\n",
    "                   +f\"{end_arc.year}\"       \\\n",
    "                   +f\"{end_arc.month:02d}\"  \\\n",
    "                   +f\"{end_arc.day:02d}\"    \\\n",
    "                   +f\"{end_arc.hour:02d}\"   \\\n",
    "                   +f\"{end_arc.minute:02d}\" \\\n",
    "                   +f\"{end_arc.second:02d}\" \\\n",
    "                )\n",
    "\n",
    "                ### SCALED ENSEMBLE AVERAGE\n",
    "                try:\n",
    "                    list_it_models.append(A['rho (kg/m**3)'].iloc[it] \\\n",
    "                                          *model_dict[model]['ScalingFactors'][ii])\n",
    "                    list_it_lat.append(  A['Lat'].iloc[it])\n",
    "                    wgts.append(      model_dict[model]['Weight'][arc_name]    )\n",
    "                except:\n",
    "    #                 print(f\"oops {model}, {arc} may not exist\")\n",
    "                    continue\n",
    "            dates.append(A['Date'].iloc[it])\n",
    "            list_lat.append(np.average(list_it_lat))\n",
    "\n",
    "            print(\"list_it_models\",list_it_models)\n",
    "            print(\"wgts\",wgts)\n",
    "            x_bar_wgt  = np.average(list_it_models, weights=wgts)\n",
    "            M = np.count_nonzero(wgts)\n",
    "            rho_scaledEnsembleAvg.append(  x_bar_wgt   )    \n",
    "#             std_scaledEnsembleAvg.append(  np.std(list_it_models)       )\n",
    "            std_numerator  = sum([ wgts[i]*((list_it_models[i] - x_bar_wgt)**2) \\\n",
    "                                                 for i in range(len(wgts)) ])\n",
    "            std_denominator= ((M-1)/M)*sum(wgts)\n",
    "            std_scaledEnsembleAvg.append(  np.sqrt( std_numerator/std_denominator) )\n",
    "\n",
    "    return(dates, list_lat, rho_scaledEnsembleAvg, std_scaledEnsembleAvg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce5ceda",
   "metadata": {},
   "source": [
    "### get weights for the weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5713fd17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.751408Z",
     "start_time": "2023-08-01T19:59:46.793Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Calculate the weights\n",
    "wgts = {}\n",
    "# sum_wgts = np.sum(list_invrms)\n",
    "for model in run_dict.keys():\n",
    "    wgts[model] = {}\n",
    "\n",
    "    for ii,arc in enumerate(obj[model]['global_params']['arc_input']):\n",
    "        epochstart = obj[model]['global_params']['prms']['epoch_start'][ii]\n",
    "        hrs = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "        frachours =(hrs/24)\n",
    "        arc =arc+('%.3f'%frachours).lstrip('0')\n",
    "        \n",
    "        inv_rms          = 1/obj[model]['Statistics'][arc]['T_RMS'].values[0]\n",
    "        wgts[model][arc] = inv_rms#/sum_wgts\n",
    "\n",
    "\n",
    "satid = int(obj[model]['global_params']['prms']['sat_ID'])\n",
    "for plot_num, model in enumerate(run_list):\n",
    "    ScalingFactors  = []\n",
    "    ScalingFactor_times = []\n",
    "    for ii,arc in enumerate(obj[model]['global_params']['arc_input']):\n",
    "        epochstart = obj[model]['global_params']['prms']['epoch_start'][ii]\n",
    "        hrs = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "        frachours =(hrs/24)\n",
    "        #\n",
    "        arc =arc+('%.3f'%frachours).lstrip('0')\n",
    "        iters = int(obj[model]['run_parameters'+arc]['total_iterations'])\n",
    "        \n",
    "        for iit, itime in enumerate(obj[model]['AdjustedParams'][arc][iters][satid]['0CD'].keys()):\n",
    "            if iit == 0 or iit==9:\n",
    "                pass\n",
    "            else:\n",
    "                CURRENT_VALUE = obj[model]['AdjustedParams'][arc][iters][satid]['0CD'][itime]['CURRENT_VALUE']\n",
    "                APRIORI_VALUE = obj[model]['AdjustedParams'][arc][iters][satid]['0CD'][itime]['APRIORI_VALUE']\n",
    "                ScalingFactors.append(CURRENT_VALUE/APRIORI_VALUE)\n",
    "                ScalingFactor_times.append(itime - datetime.timedelta(hours=3) )\n",
    "        \n",
    "#         for itime in obj[model]['AdjustedParams'][arc][iters][satid]['0CD'].keys():\n",
    "#             CURRENT_VALUE = obj[model]['AdjustedParams'][arc][iters][satid]['0CD'][itime]['CURRENT_VALUE']\n",
    "#             APRIORI_VALUE = obj[model]['AdjustedParams'][arc][iters][satid]['0CD'][itime]['APRIORI_VALUE']\n",
    "#             ScalingFactors.append(CURRENT_VALUE/APRIORI_VALUE)\n",
    "#             ScalingFactor_times.append(itime)\n",
    "    run_dict[model]['ScalingFactor_times'] = ScalingFactor_times\n",
    "    run_dict[model]['ScalingFactors']      = ScalingFactors\n",
    "    run_dict[model]['Weight']              = wgts[model]\n",
    "#     run_dict[model]['Sum_weights'] = wgts[model]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb7b802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.752144Z",
     "start_time": "2023-08-01T19:59:46.796Z"
    }
   },
   "outputs": [],
   "source": [
    "wgts[model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88076a49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T20:43:52.870120Z",
     "start_time": "2023-07-31T20:43:52.852337Z"
    }
   },
   "source": [
    "### Calculate the densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad6f858",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.752913Z",
     "start_time": "2023-08-01T19:59:46.800Z"
    }
   },
   "outputs": [],
   "source": [
    "run_dict['dtm2020_o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c09bf06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.753733Z",
     "start_time": "2023-08-01T19:59:46.803Z"
    }
   },
   "outputs": [],
   "source": [
    "### Get the ensemble weighted average scaled densities and their orb avg\n",
    "\n",
    "(dates  , \n",
    "avg_lat ,\n",
    "rho_scaledEnsembleWgtAvg,\n",
    "std_scaledEnsembleWgtstd) = calc_rho_ScaledEnsembleWgtAvg(obj,run_dict, )\n",
    "\n",
    "(date_orbavg, den_ScaledEnsembleWgtAvg_orbavg ) = orbit_avg_generic(dates,                 \\\n",
    "                                                                 rho_scaledEnsembleWgtAvg, \\\n",
    "                                                                 avg_lat           )\n",
    "(date_orbavg, std_scaledEnsembleWgtstd_orbavg ) = orbit_avg_generic(dates,                 \\\n",
    "                                                                 std_scaledEnsembleWgtstd, \\\n",
    "                                                                 avg_lat           )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a3e5d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.754456Z",
     "start_time": "2023-08-01T19:59:46.806Z"
    }
   },
   "outputs": [],
   "source": [
    "# obj['dtm2020_o']['Density']['2018.313.000']['Date'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842b9e92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.755205Z",
     "start_time": "2023-08-01T19:59:46.809Z"
    }
   },
   "outputs": [],
   "source": [
    "# run_dict['dtm2020_o']['ScalingFactor_times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0f16b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c61c1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.755959Z",
     "start_time": "2023-08-01T19:59:46.813Z"
    }
   },
   "outputs": [],
   "source": [
    "# for idate,valdate in enumerate(models_dens['dtm2020_o']['dates']):\n",
    "#     for isf, valsf in enumerate(run_dict['dtm2020_o']['ScalingFactor_times']):\n",
    "#         dendate = models_dens['dtm2020_o']['dates'][idate]\n",
    "#         sfdate_list = run_dict['dtm2020_o']['ScalingFactor_times']\n",
    "        \n",
    "#         if dendate < sfdate_list[isf] and dendate > sfdate_list[isf-1]\n",
    "            \n",
    "    \n",
    "#     run_dict['dtm2020_o']['ScalingFactor_times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da75fde3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T20:00:56.432450Z",
     "start_time": "2023-07-20T20:00:56.254697Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abb8bb85",
   "metadata": {},
   "source": [
    "# ensemble average density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c0be67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:59:47.756819Z",
     "start_time": "2023-08-01T19:59:46.818Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "def plot_RHO_ScaledEnsembleAvg(fig, den_dict, choose_model, model_dict ):\n",
    "\n",
    "    cd_apriori  = 2.5\n",
    "\n",
    "    ####  Get plot Parameters for this model\n",
    "    model_m1 = choose_model\n",
    "    col = get_plot_params( model_m1)\n",
    "    \n",
    "    time_avg,d_avg = orbit_avg_generic(den_dict['dates'], den_dict['denscaled'], den_dict['lat'])\n",
    "    ### -----------------------------------------------------------------------------------------------------\n",
    "    ###     Orbit Averaged Density\n",
    "    fig.add_trace(go.Scattergl(x=time_avg,\n",
    "                               y=d_avg,\n",
    "                               ### name= model_m1,\n",
    "                               mode='markers+lines',\n",
    "                               opacity=0.5,\n",
    "                                   marker=dict(color=col,size=2),\n",
    "                                   line = dict(dash ='solid', color = col, width=2),\n",
    "                               showlegend=False), row=1, col=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if model_m1 == 'jb2008':\n",
    "        fig.update_yaxes(title_text=r\"$\\text{Orbit Avg. Density } (\\frac{kg}{m^3})$\", \n",
    "                         type=\"log\", \n",
    "                         exponentformat= 'power',row=1, col=1)\n",
    "        ###\n",
    "        ###  DATE on Final x-Axis only\n",
    "        fig.update_xaxes(#title=r\"$\\text{Date}$\", \n",
    "                         range=[pd.to_datetime( \"181108-160000\", format='%y%m%d-%H%M%S'),\n",
    "                                pd.to_datetime( \"181123-120000\", format='%y%m%d-%H%M%S')],\n",
    "                         row=1, col=1)\n",
    "\n",
    "\n",
    "    return(fig)\n",
    "\n",
    "\n",
    "### -----------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1,\n",
    "                    #                     \n",
    "                    vertical_spacing = 0.08,\n",
    "                    shared_xaxes=True)\n",
    "\n",
    "for model in run_dict.keys():\n",
    "    fig = plot_RHO_ScaledEnsembleAvg(fig, models_dens[model], model, run_dict[model] )\n",
    "\n",
    "\n",
    "#######################################################\n",
    "font_dict=dict(family='Arial',size=16,color='black')\n",
    "#######################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in [1]:\n",
    "    fig.update_xaxes(### LINE at axis border\n",
    "                      showline=True,\n",
    "                      showticklabels=True,\n",
    "                      linecolor='black',\n",
    "                      linewidth=1,\n",
    "                     ### Major ticks\n",
    "                      ticks='inside',\n",
    "                      tickfont=font_dict,\n",
    "                      mirror=True,\n",
    "                      tickwidth=2,\n",
    "                      ticklen=9,\n",
    "                      tickcolor='grey',\n",
    "                      tick0=\"2018-11-9\" ,\n",
    "                      dtick=86400000.0*2,    # milliseconds in a day, every 7 days\n",
    "                      #### Minor Ticks\n",
    "                       minor=dict(\n",
    "                         dtick=86400000.0, # milliseconds in a day\n",
    "                         tickwidth=1,\n",
    "                         ticklen=4,\n",
    "                         tickcolor='grey',\n",
    "                         ticks='inside'),\n",
    "                      ### GRID\n",
    "                       gridcolor='gainsboro',\n",
    "                       gridwidth=1,\n",
    "                       layer='above traces',\n",
    "                       tickangle=0,\n",
    "                       row=i, col=1)\n",
    "    fig.update_yaxes(showline=True,      # add line at x=0\n",
    "                         showticklabels=True,\n",
    "                         linecolor='black',  # line color\n",
    "                         linewidth=1,        # line size\n",
    "                     ticks='inside',     # ticks outside axis\n",
    "                     tickfont=font_dict, # tick label font\n",
    "                     mirror='allticks',  # add ticks to top/right axes\n",
    "                     tickwidth=1,      # tick width\n",
    "                     tickcolor='black',  # tick color\n",
    "                     gridcolor='gainsboro',\n",
    "                     gridwidth=1,\n",
    "                     layer='above traces',\n",
    "                     row=i, col=1)\n",
    "\n",
    "\n",
    "modelnames=[]\n",
    "modelcolors = []\n",
    "#### LEGEND ####\n",
    "for model in run_dict.keys():\n",
    "    if model == 'msis2':\n",
    "        modelnames.append(\"MSISe2\")\n",
    "        modelcolors.append(col_msis2)\n",
    "\n",
    "    elif model == 'dtm2020_o':\n",
    "        modelnames.append(\"DTM2020\")\n",
    "        modelcolors.append(col_dtm2020)\n",
    "\n",
    "    elif model == 'jb2008':\n",
    "        modelnames.append(\"JB2008\")\n",
    "        modelcolors.append(col_jb2008)\n",
    "\n",
    "    elif model == 'tiegcm_oc':\n",
    "        modelnames.append(\"TIEGCM\")\n",
    "        modelcolors.append(col_tiegcm_oc)\n",
    "\n",
    "    elif model == 'hasdm_oc':\n",
    "        modelnames.append(\"HASDM\")\n",
    "        modelcolors.append(col_hasdm_oc)\n",
    "\n",
    "    elif model == 'ctipe_oc':\n",
    "        modelnames.append(\"CTIPe\")\n",
    "        modelcolors.append(col_ctipe_oc)\n",
    "\n",
    "    elif model == 'gitm':\n",
    "        modelnames.append(\"GITM\")\n",
    "        modelcolors.append(col_gitm)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"starts_colors\": modelcolors\n",
    "                                    })\n",
    "\n",
    "fig.update_traces(showlegend=False).add_traces(\n",
    "    [   go.Scattergl(name=modelnames[i], \n",
    "               x=[pd.to_datetime( \"181107-000000\", format='%y%m%d-%H%M%S')],\n",
    "               mode='lines',\n",
    "               line = dict(shape = 'hv',  width=10),\n",
    "               marker_color=c, \n",
    "               showlegend=True)\n",
    "        for i,c in enumerate((df.loc[:,[\"starts_colors\"]].values.ravel()))])\n",
    "\n",
    "fig.update_layout(legend=dict(\n",
    "    yanchor=\"middle\",\n",
    "    y=0.5,\n",
    "    xanchor=\"center\",\n",
    "    x=1.1,\n",
    "#     x=1.015,\n",
    "        font=font_dict      ,\n",
    "        bgcolor=\"white\",\n",
    "        bordercolor=\"darkgrey\",\n",
    "        borderwidth=0.8,\n",
    "    )  )\n",
    "\n",
    "fig.update_layout(\n",
    "#                   title = '',\n",
    "                  autosize=False,    width=1000,    height=500,\n",
    "                  legend= {'itemsizing': 'trace'},\n",
    "                  font=font_dict,\n",
    "                  plot_bgcolor='white', \n",
    "                 )\n",
    "fig.update_annotations(font_size=14)  # Increase size of subplot title\n",
    "\n",
    "\n",
    "# date_orbavg\n",
    "# den_ScaledEnsembleAvg_orbavg\n",
    "# std_scaledEnsembleAvg\n",
    "\n",
    "fig.add_trace(go.Scattergl(x=date_orbavg,\n",
    "                           y=den_ScaledEnsembleWgtAvg_orbavg,\n",
    "                           ### name= model_m1,\n",
    "                           mode='markers+lines',\n",
    "                           opacity=1,\n",
    "                           marker=dict(color='black',size=5),\n",
    "                               line = dict(shape='hvh', dash ='solid', color = 'black', width=4),\n",
    "                           showlegend=False), row=1, col=1)\n",
    "# fig.add_trace(go.Scattergl(x=date_orbavg,\n",
    "#                            y=den_ScaledEnsembleMedian_orbavg,\n",
    "#                            ### name= model_m1,\n",
    "#                            mode='markers+lines',\n",
    "#                            opacity=1,\n",
    "#                            marker=dict(color='blue',size=5),\n",
    "#                                line = dict(shape='hvh', dash ='solid', color = 'black', width=4),\n",
    "#                            showlegend=False), row=1, col=1)\n",
    "#### ERRROR BARS\n",
    "fig.add_trace(go.Scattergl(x=date_orbavg,\n",
    "                           y=np.array(den_ScaledEnsembleWgtAvg_orbavg)\\\n",
    "                               +np.array(std_scaledEnsembleWgtstd_orbavg),\n",
    "                           ### name= model_m1,\n",
    "                           mode='lines',\n",
    "                           opacity=.8,\n",
    "                               line = dict(shape='hvh', dash ='dash', color = 'grey', width=3),\n",
    "                           showlegend=False), row=1, col=1)\n",
    "fig.add_trace(go.Scattergl(x=date_orbavg,\n",
    "                           y=np.array(den_ScaledEnsembleWgtAvg_orbavg)\\\n",
    "                              -np.array(std_scaledEnsembleWgtstd_orbavg),\n",
    "                           ### name= model_m1,\n",
    "                           mode='lines',\n",
    "                           opacity=.8,\n",
    "                               line = dict(shape='hvh', dash ='dash', color = 'grey', width=3),\n",
    "                           showlegend=False), row=1, col=1)\n",
    "\n",
    "\n",
    "fig.show(#renderer=\"jpg\",\n",
    "         config=dict({\n",
    "            'displayModeBar': False,\n",
    "            'responsive': True,\n",
    "            'staticPlot': False,\n",
    "            'displaylogo': False,\n",
    "            'showTips': False,\n",
    "            }))\n",
    "\n",
    "#     if save_plot_flag:\n",
    "#         pio.write_image(fig, plot_dir+'Assessment_CDAvgAdj.jpg', scale=3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a412a3e",
   "metadata": {},
   "source": [
    "## view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dd62f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "259.094px",
    "left": "940px",
    "top": "111.125px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
