{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbc22892",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35afb7be",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "492d8e8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-07T17:41:20.280699Z",
     "start_time": "2023-06-07T17:41:19.288790Z"
    }
   },
   "outputs": [],
   "source": [
    "from pygeodyn.PYGEODYN import Pygeodyn\n",
    "from pygeodyn.pygeodyn_plot import *\n",
    "\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17814aec",
   "metadata": {},
   "source": [
    "# Run settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2910f959",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-07T17:41:20.292951Z",
     "start_time": "2023-06-07T17:41:20.282786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'msis2': {'num': 5, 'model_path': None, 'CD': 1.236791}, 'tiegcm_oc': {'num': 0, 'model_path': '/data/SatDragModelValidation/data/inputs/atmos_models/tiegcm/icesat2_oct2018_jan2019', 'CD': 1.372949}, 'ctipe_oc': {'num': 4, 'model_path': '/data/SatDragModelValidation/data/inputs/atmos_models/ctipe/icesat2_oct2018_jan2019', 'CD': 4.368334}, 'jb2008': {'num': 1, 'model_path': None, 'CD': 1.908777}, 'dtm2020_o': {'num': 3, 'model_path': None, 'CD': 3.351462}, 'gitm': {'num': 4, 'model_path': '/data/SatDragModelValidation/data/inputs/atmos_models/gitm/icesat2_oct2018_jan2019', 'CD': 3.063949}, 'hasdm_oc': {'num': 2, 'model_path': '/data/SatDragModelValidation/data/inputs/atmos_models/hasdm/vishal_icesat2_oct2018_jan2019', 'CD': 2.076144}}\n"
     ]
    }
   ],
   "source": [
    "run_list = [    'msis2',\n",
    "                'tiegcm_oc',\n",
    "                'ctipe_oc',\n",
    "                'jb2008',\n",
    "                'dtm2020_o',\n",
    "                'gitm',\n",
    "                'hasdm_oc',\n",
    "           ]\n",
    "\n",
    "plot_dir='/data/SatDragModelValidation/notebooks/Paper2023_icesat2_assessment/plots/'\n",
    "\n",
    "dir_modeldat='/data/SatDragModelValidation/data/inputs/atmos_models'\n",
    "run_dict={}\n",
    "for i in run_list:\n",
    "    if i =='msis2':\n",
    "        run_dict[i]={}\n",
    "        run_dict[i]['num'] = 5\n",
    "        run_dict[i]['model_path'] = None\n",
    "        run_dict[i]['CD']         = 1.236791\n",
    "\n",
    "    if i =='dtm2020_o':\n",
    "        run_dict[i]={}\n",
    "        run_dict[i]['num'] = 3\n",
    "        run_dict[i]['model_path'] = None\n",
    "        run_dict[i]['CD']         = 3.351462\n",
    "\n",
    "    if i =='jb2008':\n",
    "        run_dict[i]={}\n",
    "        run_dict[i]['num'] = 1\n",
    "        run_dict[i]['model_path'] = None\n",
    "        run_dict[i]['CD']         = 1.908777\n",
    "        \n",
    "    ### PHYSICAL MODELS\n",
    "    if i =='tiegcm_oc':\n",
    "        run_dict[i]={}\n",
    "        run_dict[i]['num'] = 0\n",
    "        run_dict[i]['model_path'] = dir_modeldat+'/tiegcm/icesat2_oct2018_jan2019'\n",
    "        run_dict[i]['CD']         = 1.372949\n",
    "        \n",
    "    if i =='ctipe_oc':\n",
    "        run_dict[i]={}\n",
    "        run_dict[i]['num']=4\n",
    "        run_dict[i]['model_path'] = dir_modeldat+'/ctipe/icesat2_oct2018_jan2019'\n",
    "        run_dict[i]['CD']         = 4.368334\n",
    "        \n",
    "    if i =='gitm':\n",
    "        run_dict[i]={}\n",
    "        run_dict[i]['num']=4\n",
    "        run_dict[i]['model_path'] = dir_modeldat+'/gitm/icesat2_oct2018_jan2019'\n",
    "        run_dict[i]['CD']         = 3.063949\n",
    "        \n",
    "    if i =='hasdm_oc':\n",
    "        run_dict[i]={}\n",
    "        run_dict[i]['num'] = 2\n",
    "        run_dict[i]['model_path'] = dir_modeldat+'/hasdm/vishal_icesat2_oct2018_jan2019' #HASDM_OrbitCloud_2018313.01.csv\n",
    "        run_dict[i]['CD']         = 2.076144\n",
    "\n",
    "\n",
    "print(run_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59fa59b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-07T17:41:20.301172Z",
     "start_time": "2023-06-07T17:41:20.294231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num': 5, 'model_path': None, 'CD': 1.236791}\n",
      "{'num': 0, 'model_path': '/data/SatDragModelValidation/data/inputs/atmos_models/tiegcm/icesat2_oct2018_jan2019', 'CD': 1.372949}\n",
      "{'num': 4, 'model_path': '/data/SatDragModelValidation/data/inputs/atmos_models/ctipe/icesat2_oct2018_jan2019', 'CD': 4.368334}\n",
      "{'num': 1, 'model_path': None, 'CD': 1.908777}\n",
      "{'num': 3, 'model_path': None, 'CD': 3.351462}\n",
      "{'num': 4, 'model_path': '/data/SatDragModelValidation/data/inputs/atmos_models/gitm/icesat2_oct2018_jan2019', 'CD': 3.063949}\n",
      "{'num': 2, 'model_path': '/data/SatDragModelValidation/data/inputs/atmos_models/hasdm/vishal_icesat2_oct2018_jan2019', 'CD': 2.076144}\n"
     ]
    }
   ],
   "source": [
    "for i,den in enumerate(run_list):\n",
    "    print(run_dict[den])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7624f03e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:19.959Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the ICESat-2 Class\n",
      "Run #1     Current Time =      10:41:21  GMT-7\n",
      "Run #1\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "| Run #1 Parameters\n",
      "| —————————————————\n",
      "|  Run Specs\n",
      "|  --------- \n",
      "|    Satellite    icesat2\n",
      "|    Run Type     DataReduction_PCE\n",
      "|    CD Type      Fixed_CD\n",
      "|    CD Value     1.236791\n",
      "|    Density      msis2\n",
      "|\n",
      "|  Epoch Info \n",
      "|  ---------- \n",
      "|    Arc          2018.313\n",
      "|    Arc length   24.0 hours\n",
      "|    Epoch Start  2018-11-09 00:00:00\n",
      "|    Epoch End    2018-11-10 00:00:00\n",
      "|    Step Size    10.0 seconds\n",
      "|\n",
      "|  Files Info\n",
      "|  ---------- \n",
      "|    Arc Name    icesat2_2018313.01_msis2.CDmeanadj\n",
      "|\n",
      "|    IISSET      .../data/inputs/sat_icesat2/setups/iisset.2018.313\n",
      "|    EXAT        .../data/inputs/sat_icesat2/external_attitude/EXAT01.2018.313.gz\n",
      "|    Output Raw  .../data/outputs_raw/icesat2/msis2/msis2_BWDRAG_fixedscaledCD/\n",
      "|\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "\n",
      "Run #1          Running IIS\n",
      "Run #1          No errors in IIS\n",
      "Run #1 ---------End of IIS\n",
      "\n",
      "Run #1          Running IIE\n",
      "Run #1          Current Time = 10:41:57 GMT-7\n",
      " ------ Current DIR:  /data/SatDragModelValidation/data/tmp/msis2_BWDRAG_fixedscaledCD/icesat2_2018313.01_msis2.CDmeanadj\n",
      "Run #1          No errors in IIE\n",
      "Run #1 ---------End of IIE\n",
      "  - convergence achieved\n",
      "Run #1          Time of IIE:  379.3530876636505 secs ( 6.322551461060842  mins)\n",
      "Run #1          Current Time = 17:48:16\n",
      "Saving fort.103 as drag_file\n",
      "Saving fort.104 as SatGeometry_file\n",
      "Run #1                Finished renaming files\n",
      "Run #1                Finished copying files to outputdir\n",
      "        Deleting tmp/:  /data/SatDragModelValidation/data/tmp/msis2_BWDRAG_fixedscaledCD/icesat2_2018313.01_msis2.CDmeanadj\n",
      "Run #2     Current Time =      10:48:19  GMT-7\n",
      "Run #2\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "| Run #2 Parameters\n",
      "| —————————————————\n",
      "|  Run Specs\n",
      "|  --------- \n",
      "|    Satellite    icesat2\n",
      "|    Run Type     DataReduction_PCE\n",
      "|    CD Type      Fixed_CD\n",
      "|    CD Value     1.236791\n",
      "|    Density      msis2\n",
      "|\n",
      "|  Epoch Info \n",
      "|  ---------- \n",
      "|    Arc          2018.314\n",
      "|    Arc length   24.0 hours\n",
      "|    Epoch Start  2018-11-10 00:00:00\n",
      "|    Epoch End    2018-11-11 00:00:00\n",
      "|    Step Size    10.0 seconds\n",
      "|\n",
      "|  Files Info\n",
      "|  ---------- \n",
      "|    Arc Name    icesat2_2018314.01_msis2.CDmeanadj\n",
      "|\n",
      "|    IISSET      .../data/inputs/sat_icesat2/setups/iisset.2018.314\n",
      "|    EXAT        .../data/inputs/sat_icesat2/external_attitude/EXAT01.2018.314.gz\n",
      "|    Output Raw  .../data/outputs_raw/icesat2/msis2/msis2_BWDRAG_fixedscaledCD/\n",
      "|\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "\n",
      "Run #2          Running IIS\n",
      "Run #2          No errors in IIS\n",
      "Run #2 ---------End of IIS\n",
      "\n",
      "Run #2          Running IIE\n",
      "Run #2          Current Time = 10:48:51 GMT-7\n",
      " ------ Current DIR:  /data/SatDragModelValidation/data/tmp/msis2_BWDRAG_fixedscaledCD/icesat2_2018314.01_msis2.CDmeanadj\n",
      "Run #2          No errors in IIE\n",
      "Run #2 ---------End of IIE\n",
      "  - convergence achieved\n",
      "Run #2          Time of IIE:  275.16301441192627 secs ( 4.586050240198771  mins)\n",
      "Run #2          Current Time = 17:53:26\n",
      "Saving fort.103 as drag_file\n",
      "Saving fort.104 as SatGeometry_file\n",
      "Run #2                Finished renaming files\n",
      "Run #2                Finished copying files to outputdir\n",
      "        Deleting tmp/:  /data/SatDragModelValidation/data/tmp/msis2_BWDRAG_fixedscaledCD/icesat2_2018314.01_msis2.CDmeanadj\n",
      "Using the ICESat-2 Class\n",
      "+==================================================\n",
      "|     Running GEODYN with Orbit Cloud Method     \n",
      "|                                                \n",
      "|     MSIS2 Density file already exists. \n",
      "|          - icesat2_2018313.01_msis2.CDmeanadj_msisin           \n",
      "|     Already have OrbitCloud file for this arc: \n",
      "|          -OrbitCloud_icesat2_Step10_2018313.01.csv\n",
      "|          - icesat2_2018313.01_tiegcm_oc.CDmeanadj \n",
      "|     MSIS2 Density file already exists. \n",
      "|          - icesat2_2018314.01_msis2.CDmeanadj_msisin           \n",
      "|     Already have OrbitCloud file for this arc: \n",
      "|          -OrbitCloud_icesat2_Step10_2018314.01.csv\n",
      "|          - icesat2_2018314.01_tiegcm_oc.CDmeanadj \n",
      "|     Running GEODYN with orbit cloud\n",
      "Run #1     Current Time =      10:53:35  GMT-7\n",
      "Run #1\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "| Run #1 Parameters\n",
      "| —————————————————\n",
      "|  Run Specs\n",
      "|  --------- \n",
      "|    Satellite    icesat2\n",
      "|    Run Type     DataReduction_PCE\n",
      "|    CD Type      Fixed_CD\n",
      "|    CD Value     1.372949\n",
      "|    Density      tiegcm_oc\n",
      "|\n",
      "|  Epoch Info \n",
      "|  ---------- \n",
      "|    Arc          2018.313\n",
      "|    Arc length   24.0 hours\n",
      "|    Epoch Start  2018-11-09 00:00:00\n",
      "|    Epoch End    2018-11-10 00:00:00\n",
      "|    Step Size    10.0 seconds\n",
      "|\n",
      "|  Files Info\n",
      "|  ---------- \n",
      "|    Arc Name    icesat2_2018313.01_tiegcm_oc.CDmeanadj\n",
      "|\n",
      "|    IISSET      .../data/inputs/sat_icesat2/setups/iisset.2018.313\n",
      "|    EXAT        .../data/inputs/sat_icesat2/external_attitude/EXAT01.2018.313.gz\n",
      "|    Output Raw  .../data/outputs_raw/icesat2/tiegcm_oc/tiegcm_oc_BWDRAG_fixedscaledCD/\n",
      "|\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "\n",
      "Run #1          Running IIS\n",
      "Run #1          No errors in IIS\n",
      "Run #1 ---------End of IIS\n",
      "\n",
      "Run #1          Running IIE\n",
      "Run #1          Current Time = 10:54:03 GMT-7\n",
      " ------ Current DIR:  /data/SatDragModelValidation/data/tmp/tiegcm_oc_BWDRAG_fixedscaledCD/icesat2_2018313.01_tiegcm_oc.CDmeanadj\n",
      "Run #1          No errors in IIE\n",
      "Run #1 ---------End of IIE\n",
      "  - convergence achieved\n",
      "Run #1          Time of IIE:  1146.9793956279755 secs ( 19.116323260466256  mins)\n",
      "Run #1          Current Time = 18:13:10\n",
      "Saving fort.103 as drag_file\n",
      "Saving fort.104 as SatGeometry_file\n",
      "Run #1                Finished renaming files\n",
      "Run #1                Finished copying files to outputdir\n",
      "        Deleting tmp/:  /data/SatDragModelValidation/data/tmp/tiegcm_oc_BWDRAG_fixedscaledCD/icesat2_2018313.01_tiegcm_oc.CDmeanadj\n",
      "|     Running GEODYN with orbit cloud\n",
      "Run #2     Current Time =      11:13:14  GMT-7\n",
      "Run #2\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "| Run #2 Parameters\n",
      "| —————————————————\n",
      "|  Run Specs\n",
      "|  --------- \n",
      "|    Satellite    icesat2\n",
      "|    Run Type     DataReduction_PCE\n",
      "|    CD Type      Fixed_CD\n",
      "|    CD Value     1.372949\n",
      "|    Density      tiegcm_oc\n",
      "|\n",
      "|  Epoch Info \n",
      "|  ---------- \n",
      "|    Arc          2018.314\n",
      "|    Arc length   24.0 hours\n",
      "|    Epoch Start  2018-11-10 00:00:00\n",
      "|    Epoch End    2018-11-11 00:00:00\n",
      "|    Step Size    10.0 seconds\n",
      "|\n",
      "|  Files Info\n",
      "|  ---------- \n",
      "|    Arc Name    icesat2_2018314.01_tiegcm_oc.CDmeanadj\n",
      "|\n",
      "|    IISSET      .../data/inputs/sat_icesat2/setups/iisset.2018.314\n",
      "|    EXAT        .../data/inputs/sat_icesat2/external_attitude/EXAT01.2018.314.gz\n",
      "|    Output Raw  .../data/outputs_raw/icesat2/tiegcm_oc/tiegcm_oc_BWDRAG_fixedscaledCD/\n",
      "|\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "\n",
      "Run #2          Running IIS\n",
      "Run #2          No errors in IIS\n",
      "Run #2 ---------End of IIS\n",
      "\n",
      "Run #2          Running IIE\n",
      "Run #2          Current Time = 11:13:42 GMT-7\n",
      " ------ Current DIR:  /data/SatDragModelValidation/data/tmp/tiegcm_oc_BWDRAG_fixedscaledCD/icesat2_2018314.01_tiegcm_oc.CDmeanadj\n",
      "Run #2          No errors in IIE\n",
      "Run #2 ---------End of IIE\n",
      "  - convergence achieved\n",
      "Run #2          Time of IIE:  352.7102589607239 secs ( 5.878504316012065  mins)\n",
      "Run #2          Current Time = 18:19:35\n",
      "Saving fort.103 as drag_file\n",
      "Saving fort.104 as SatGeometry_file\n",
      "Run #2                Finished renaming files\n",
      "Run #2                Finished copying files to outputdir\n",
      "        Deleting tmp/:  /data/SatDragModelValidation/data/tmp/tiegcm_oc_BWDRAG_fixedscaledCD/icesat2_2018314.01_tiegcm_oc.CDmeanadj\n",
      "Using the ICESat-2 Class\n",
      "+==================================================\n",
      "|     Running GEODYN with Orbit Cloud Method     \n",
      "|                                                \n",
      "|     MSIS2 Density file already exists. \n",
      "|          - icesat2_2018313.01_msis2.CDmeanadj_msisin           \n",
      "|     Already have OrbitCloud file for this arc: \n",
      "|          -OrbitCloud_icesat2_Step10_2018313.01.csv\n",
      "|          - icesat2_2018313.01_ctipe_oc.CDmeanadj \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|     MSIS2 Density file already exists. \n",
      "|          - icesat2_2018314.01_msis2.CDmeanadj_msisin           \n",
      "|     Already have OrbitCloud file for this arc: \n",
      "|          -OrbitCloud_icesat2_Step10_2018314.01.csv\n",
      "|          - icesat2_2018314.01_ctipe_oc.CDmeanadj \n",
      "|     Running GEODYN with orbit cloud\n",
      "Run #1     Current Time =      11:19:44  GMT-7\n",
      "Run #1\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "| Run #1 Parameters\n",
      "| —————————————————\n",
      "|  Run Specs\n",
      "|  --------- \n",
      "|    Satellite    icesat2\n",
      "|    Run Type     DataReduction_PCE\n",
      "|    CD Type      Fixed_CD\n",
      "|    CD Value     4.368334\n",
      "|    Density      ctipe_oc\n",
      "|\n",
      "|  Epoch Info \n",
      "|  ---------- \n",
      "|    Arc          2018.313\n",
      "|    Arc length   24.0 hours\n",
      "|    Epoch Start  2018-11-09 00:00:00\n",
      "|    Epoch End    2018-11-10 00:00:00\n",
      "|    Step Size    10.0 seconds\n",
      "|\n",
      "|  Files Info\n",
      "|  ---------- \n",
      "|    Arc Name    icesat2_2018313.01_ctipe_oc.CDmeanadj\n",
      "|\n",
      "|    IISSET      .../data/inputs/sat_icesat2/setups/iisset.2018.313\n",
      "|    EXAT        .../data/inputs/sat_icesat2/external_attitude/EXAT01.2018.313.gz\n",
      "|    Output Raw  .../data/outputs_raw/icesat2/ctipe_oc/ctipe_oc_BWDRAG_fixedscaledCD/\n",
      "|\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "\n",
      "Run #1          Running IIS\n",
      "Run #1          No errors in IIS\n",
      "Run #1 ---------End of IIS\n",
      "\n",
      "Run #1          Running IIE\n",
      "Run #1          Current Time = 11:20:13 GMT-7\n",
      " ------ Current DIR:  /data/SatDragModelValidation/data/tmp/ctipe_oc_BWDRAG_fixedscaledCD/icesat2_2018313.01_ctipe_oc.CDmeanadj\n",
      "Run #1          No errors in IIE\n",
      "Run #1 ---------End of IIE\n",
      "  - convergence achieved\n",
      "Run #1          Time of IIE:  975.6863000392914 secs ( 16.26143833398819  mins)\n",
      "Run #1          Current Time = 18:36:29\n",
      "Saving fort.103 as drag_file\n",
      "Saving fort.104 as SatGeometry_file\n",
      "Run #1                Finished renaming files\n",
      "Run #1                Finished copying files to outputdir\n",
      "        Deleting tmp/:  /data/SatDragModelValidation/data/tmp/ctipe_oc_BWDRAG_fixedscaledCD/icesat2_2018313.01_ctipe_oc.CDmeanadj\n",
      "|     Running GEODYN with orbit cloud\n",
      "Run #2     Current Time =      11:36:33  GMT-7\n",
      "Run #2\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "| Run #2 Parameters\n",
      "| —————————————————\n",
      "|  Run Specs\n",
      "|  --------- \n",
      "|    Satellite    icesat2\n",
      "|    Run Type     DataReduction_PCE\n",
      "|    CD Type      Fixed_CD\n",
      "|    CD Value     4.368334\n",
      "|    Density      ctipe_oc\n",
      "|\n",
      "|  Epoch Info \n",
      "|  ---------- \n",
      "|    Arc          2018.314\n",
      "|    Arc length   24.0 hours\n",
      "|    Epoch Start  2018-11-10 00:00:00\n",
      "|    Epoch End    2018-11-11 00:00:00\n",
      "|    Step Size    10.0 seconds\n",
      "|\n",
      "|  Files Info\n",
      "|  ---------- \n",
      "|    Arc Name    icesat2_2018314.01_ctipe_oc.CDmeanadj\n",
      "|\n",
      "|    IISSET      .../data/inputs/sat_icesat2/setups/iisset.2018.314\n",
      "|    EXAT        .../data/inputs/sat_icesat2/external_attitude/EXAT01.2018.314.gz\n",
      "|    Output Raw  .../data/outputs_raw/icesat2/ctipe_oc/ctipe_oc_BWDRAG_fixedscaledCD/\n",
      "|\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "\n",
      "Run #2          Running IIS\n",
      "Run #2          No errors in IIS\n",
      "Run #2 ---------End of IIS\n",
      "\n",
      "Run #2          Running IIE\n",
      "Run #2          Current Time = 11:37:01 GMT-7\n",
      " ------ Current DIR:  /data/SatDragModelValidation/data/tmp/ctipe_oc_BWDRAG_fixedscaledCD/icesat2_2018314.01_ctipe_oc.CDmeanadj\n",
      "Run #2          No errors in IIE\n",
      "Run #2 ---------End of IIE\n",
      "  - convergence achieved\n",
      "Run #2          Time of IIE:  739.086827993393 secs ( 12.318113799889883  mins)\n",
      "Run #2          Current Time = 18:49:20\n",
      "Saving fort.103 as drag_file\n",
      "Saving fort.104 as SatGeometry_file\n",
      "Run #2                Finished renaming files\n",
      "Run #2                Finished copying files to outputdir\n",
      "        Deleting tmp/:  /data/SatDragModelValidation/data/tmp/ctipe_oc_BWDRAG_fixedscaledCD/icesat2_2018314.01_ctipe_oc.CDmeanadj\n",
      "Using the ICESat-2 Class\n",
      "Run #1     Current Time =      11:49:23  GMT-7\n",
      "Run #1\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "| Run #1 Parameters\n",
      "| —————————————————\n",
      "|  Run Specs\n",
      "|  --------- \n",
      "|    Satellite    icesat2\n",
      "|    Run Type     DataReduction_PCE\n",
      "|    CD Type      Fixed_CD\n",
      "|    CD Value     1.908777\n",
      "|    Density      jb2008\n",
      "|\n",
      "|  Epoch Info \n",
      "|  ---------- \n",
      "|    Arc          2018.313\n",
      "|    Arc length   24.0 hours\n",
      "|    Epoch Start  2018-11-09 00:00:00\n",
      "|    Epoch End    2018-11-10 00:00:00\n",
      "|    Step Size    10.0 seconds\n",
      "|\n",
      "|  Files Info\n",
      "|  ---------- \n",
      "|    Arc Name    icesat2_2018313.01_jb2008.CDmeanadj\n",
      "|\n",
      "|    IISSET      .../data/inputs/sat_icesat2/setups/iisset.2018.313\n",
      "|    EXAT        .../data/inputs/sat_icesat2/external_attitude/EXAT01.2018.313.gz\n",
      "|    Output Raw  .../data/outputs_raw/icesat2/jb2008/jb2008_BWDRAG_fixedscaledCD/\n",
      "|\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "\n",
      "Run #1          Running IIS\n",
      "Run #1          No errors in IIS\n",
      "Run #1 ---------End of IIS\n",
      "\n",
      "Run #1          Running IIE\n",
      "Run #1          Current Time = 11:49:51 GMT-7\n",
      " ------ Current DIR:  /data/SatDragModelValidation/data/tmp/jb2008_BWDRAG_fixedscaledCD/icesat2_2018313.01_jb2008.CDmeanadj\n",
      "Run #1          No errors in IIE\n",
      "Run #1 ---------End of IIE\n",
      "  - convergence achieved\n",
      "Run #1          Time of IIE:  742.2683157920837 secs ( 12.37113859653473  mins)\n",
      "Run #1          Current Time = 19:02:13\n",
      "Saving fort.103 as drag_file\n",
      "Saving fort.104 as SatGeometry_file\n",
      "Run #1                Finished renaming files\n",
      "Run #1                Finished copying files to outputdir\n",
      "        Deleting tmp/:  /data/SatDragModelValidation/data/tmp/jb2008_BWDRAG_fixedscaledCD/icesat2_2018313.01_jb2008.CDmeanadj\n",
      "Run #2     Current Time =      12:02:16  GMT-7\n",
      "Run #2\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "| Run #2 Parameters\n",
      "| —————————————————\n",
      "|  Run Specs\n",
      "|  --------- \n",
      "|    Satellite    icesat2\n",
      "|    Run Type     DataReduction_PCE\n",
      "|    CD Type      Fixed_CD\n",
      "|    CD Value     1.908777\n",
      "|    Density      jb2008\n",
      "|\n",
      "|  Epoch Info \n",
      "|  ---------- \n",
      "|    Arc          2018.314\n",
      "|    Arc length   24.0 hours\n",
      "|    Epoch Start  2018-11-10 00:00:00\n",
      "|    Epoch End    2018-11-11 00:00:00\n",
      "|    Step Size    10.0 seconds\n",
      "|\n",
      "|  Files Info\n",
      "|  ---------- \n",
      "|    Arc Name    icesat2_2018314.01_jb2008.CDmeanadj\n",
      "|\n",
      "|    IISSET      .../data/inputs/sat_icesat2/setups/iisset.2018.314\n",
      "|    EXAT        .../data/inputs/sat_icesat2/external_attitude/EXAT01.2018.314.gz\n",
      "|    Output Raw  .../data/outputs_raw/icesat2/jb2008/jb2008_BWDRAG_fixedscaledCD/\n",
      "|\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "\n",
      "Run #2          Running IIS\n",
      "Run #2          No errors in IIS\n",
      "Run #2 ---------End of IIS\n",
      "\n",
      "Run #2          Running IIE\n",
      "Run #2          Current Time = 12:02:44 GMT-7\n",
      " ------ Current DIR:  /data/SatDragModelValidation/data/tmp/jb2008_BWDRAG_fixedscaledCD/icesat2_2018314.01_jb2008.CDmeanadj\n",
      "Run #2          No errors in IIE\n",
      "Run #2 ---------End of IIE\n",
      "  - convergence achieved\n",
      "Run #2          Time of IIE:  270.4373013973236 secs ( 4.50728835662206  mins)\n",
      "Run #2          Current Time = 19:07:15\n",
      "Saving fort.103 as drag_file\n",
      "Saving fort.104 as SatGeometry_file\n",
      "Run #2                Finished renaming files\n",
      "Run #2                Finished copying files to outputdir\n",
      "        Deleting tmp/:  /data/SatDragModelValidation/data/tmp/jb2008_BWDRAG_fixedscaledCD/icesat2_2018314.01_jb2008.CDmeanadj\n",
      "Using the ICESat-2 Class\n",
      "Run #1     Current Time =      12:07:18  GMT-7\n",
      "Run #1\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "| Run #1 Parameters\n",
      "| —————————————————\n",
      "|  Run Specs\n",
      "|  --------- \n",
      "|    Satellite    icesat2\n",
      "|    Run Type     DataReduction_PCE\n",
      "|    CD Type      Fixed_CD\n",
      "|    CD Value     3.351462\n",
      "|    Density      dtm2020_o\n",
      "|\n",
      "|  Epoch Info \n",
      "|  ---------- \n",
      "|    Arc          2018.313\n",
      "|    Arc length   24.0 hours\n",
      "|    Epoch Start  2018-11-09 00:00:00\n",
      "|    Epoch End    2018-11-10 00:00:00\n",
      "|    Step Size    10.0 seconds\n",
      "|\n",
      "|  Files Info\n",
      "|  ---------- \n",
      "|    Arc Name    icesat2_2018313.01_dtm2020_o.CDmeanadj\n",
      "|\n",
      "|    IISSET      .../data/inputs/sat_icesat2/setups/iisset.2018.313\n",
      "|    EXAT        .../data/inputs/sat_icesat2/external_attitude/EXAT01.2018.313.gz\n",
      "|    Output Raw  .../data/outputs_raw/icesat2/dtm2020_o/dtm2020_o_BWDRAG_fixedscaledCD/\n",
      "|\n",
      "|————————————————————————————————————————————————————————————————————————————————\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run #1          Running IIS\n",
      "Run #1          No errors in IIS\n",
      "Run #1 ---------End of IIS\n",
      "\n",
      "Run #1          Running IIE\n",
      "Run #1          Current Time = 12:07:46 GMT-7\n",
      " ------ Current DIR:  /data/SatDragModelValidation/data/tmp/dtm2020_o_BWDRAG_fixedscaledCD/icesat2_2018313.01_dtm2020_o.CDmeanadj\n",
      "Run #1          No errors in IIE\n",
      "Run #1 ---------End of IIE\n",
      "  - convergence achieved\n",
      "Run #1          Time of IIE:  586.7491872310638 secs ( 9.77915312051773  mins)\n",
      "Run #1          Current Time = 19:17:32\n",
      "Saving fort.103 as drag_file\n",
      "Saving fort.104 as SatGeometry_file\n",
      "Run #1                Finished renaming files\n",
      "Run #1                Finished copying files to outputdir\n",
      "        Deleting tmp/:  /data/SatDragModelValidation/data/tmp/dtm2020_o_BWDRAG_fixedscaledCD/icesat2_2018313.01_dtm2020_o.CDmeanadj\n",
      "Run #2     Current Time =      12:17:35  GMT-7\n",
      "Run #2\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "| Run #2 Parameters\n",
      "| —————————————————\n",
      "|  Run Specs\n",
      "|  --------- \n",
      "|    Satellite    icesat2\n",
      "|    Run Type     DataReduction_PCE\n",
      "|    CD Type      Fixed_CD\n",
      "|    CD Value     3.351462\n",
      "|    Density      dtm2020_o\n",
      "|\n",
      "|  Epoch Info \n",
      "|  ---------- \n",
      "|    Arc          2018.314\n",
      "|    Arc length   24.0 hours\n",
      "|    Epoch Start  2018-11-10 00:00:00\n",
      "|    Epoch End    2018-11-11 00:00:00\n",
      "|    Step Size    10.0 seconds\n",
      "|\n",
      "|  Files Info\n",
      "|  ---------- \n",
      "|    Arc Name    icesat2_2018314.01_dtm2020_o.CDmeanadj\n",
      "|\n",
      "|    IISSET      .../data/inputs/sat_icesat2/setups/iisset.2018.314\n",
      "|    EXAT        .../data/inputs/sat_icesat2/external_attitude/EXAT01.2018.314.gz\n",
      "|    Output Raw  .../data/outputs_raw/icesat2/dtm2020_o/dtm2020_o_BWDRAG_fixedscaledCD/\n",
      "|\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "\n",
      "Run #2          Running IIS\n",
      "Run #2          No errors in IIS\n",
      "Run #2 ---------End of IIS\n",
      "\n",
      "Run #2          Running IIE\n",
      "Run #2          Current Time = 12:18:04 GMT-7\n",
      " ------ Current DIR:  /data/SatDragModelValidation/data/tmp/dtm2020_o_BWDRAG_fixedscaledCD/icesat2_2018314.01_dtm2020_o.CDmeanadj\n",
      "Run #2          No errors in IIE\n",
      "Run #2 ---------End of IIE\n",
      "  - convergence achieved\n",
      "Run #2          Time of IIE:  532.5442390441895 secs ( 8.875737317403157  mins)\n",
      "Run #2          Current Time = 19:26:56\n",
      "Saving fort.103 as drag_file\n",
      "Saving fort.104 as SatGeometry_file\n",
      "Run #2                Finished renaming files\n",
      "Run #2                Finished copying files to outputdir\n",
      "        Deleting tmp/:  /data/SatDragModelValidation/data/tmp/dtm2020_o_BWDRAG_fixedscaledCD/icesat2_2018314.01_dtm2020_o.CDmeanadj\n",
      "Using the ICESat-2 Class\n",
      "+==================================================\n",
      "|     Running GEODYN with Orbit Cloud Method     \n",
      "|                                                \n",
      "|     MSIS2 Density file already exists. \n",
      "|          - icesat2_2018313.01_msis2.CDmeanadj_msisin           \n",
      "|     Already have OrbitCloud file for this arc: \n",
      "|          -OrbitCloud_icesat2_Step10_2018313.01.csv\n",
      "|          - icesat2_2018313.01_gitm.CDmeanadj \n",
      "|     MSIS2 Density file already exists. \n",
      "|          - icesat2_2018314.01_msis2.CDmeanadj_msisin           \n",
      "|     Already have OrbitCloud file for this arc: \n",
      "|          -OrbitCloud_icesat2_Step10_2018314.01.csv\n",
      "|          - icesat2_2018314.01_gitm.CDmeanadj \n",
      "|     Running GEODYN with orbit cloud\n",
      "Run #1     Current Time =      12:27:05  GMT-7\n",
      "Run #1\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "| Run #1 Parameters\n",
      "| —————————————————\n",
      "|  Run Specs\n",
      "|  --------- \n",
      "|    Satellite    icesat2\n",
      "|    Run Type     DataReduction_PCE\n",
      "|    CD Type      Fixed_CD\n",
      "|    CD Value     3.063949\n",
      "|    Density      gitm\n",
      "|\n",
      "|  Epoch Info \n",
      "|  ---------- \n",
      "|    Arc          2018.313\n",
      "|    Arc length   24.0 hours\n",
      "|    Epoch Start  2018-11-09 00:00:00\n",
      "|    Epoch End    2018-11-10 00:00:00\n",
      "|    Step Size    10.0 seconds\n",
      "|\n",
      "|  Files Info\n",
      "|  ---------- \n",
      "|    Arc Name    icesat2_2018313.01_gitm.CDmeanadj\n",
      "|\n",
      "|    IISSET      .../data/inputs/sat_icesat2/setups/iisset.2018.313\n",
      "|    EXAT        .../data/inputs/sat_icesat2/external_attitude/EXAT01.2018.313.gz\n",
      "|    Output Raw  .../data/outputs_raw/icesat2/gitm/gitm_BWDRAG_fixedscaledCD/\n",
      "|\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "\n",
      "Run #1          Running IIS\n",
      "Run #1          No errors in IIS\n",
      "Run #1 ---------End of IIS\n",
      "\n",
      "Run #1          Running IIE\n",
      "Run #1          Current Time = 12:27:33 GMT-7\n",
      " ------ Current DIR:  /data/SatDragModelValidation/data/tmp/gitm_BWDRAG_fixedscaledCD/icesat2_2018313.01_gitm.CDmeanadj\n",
      "Run #1          No errors in IIE\n",
      "Run #1 ---------End of IIE\n",
      "  - convergence achieved\n",
      "Run #1          Time of IIE:  401.37111043930054 secs ( 6.689518507321676  mins)\n",
      "Run #1          Current Time = 19:34:15\n",
      "Saving fort.103 as drag_file\n",
      "Saving fort.104 as SatGeometry_file\n",
      "Run #1                Finished renaming files\n",
      "Run #1                Finished copying files to outputdir\n",
      "        Deleting tmp/:  /data/SatDragModelValidation/data/tmp/gitm_BWDRAG_fixedscaledCD/icesat2_2018313.01_gitm.CDmeanadj\n",
      "|     Running GEODYN with orbit cloud\n",
      "Run #2     Current Time =      12:34:19  GMT-7\n",
      "Run #2\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "| Run #2 Parameters\n",
      "| —————————————————\n",
      "|  Run Specs\n",
      "|  --------- \n",
      "|    Satellite    icesat2\n",
      "|    Run Type     DataReduction_PCE\n",
      "|    CD Type      Fixed_CD\n",
      "|    CD Value     3.063949\n",
      "|    Density      gitm\n",
      "|\n",
      "|  Epoch Info \n",
      "|  ---------- \n",
      "|    Arc          2018.314\n",
      "|    Arc length   24.0 hours\n",
      "|    Epoch Start  2018-11-10 00:00:00\n",
      "|    Epoch End    2018-11-11 00:00:00\n",
      "|    Step Size    10.0 seconds\n",
      "|\n",
      "|  Files Info\n",
      "|  ---------- \n",
      "|    Arc Name    icesat2_2018314.01_gitm.CDmeanadj\n",
      "|\n",
      "|    IISSET      .../data/inputs/sat_icesat2/setups/iisset.2018.314\n",
      "|    EXAT        .../data/inputs/sat_icesat2/external_attitude/EXAT01.2018.314.gz\n",
      "|    Output Raw  .../data/outputs_raw/icesat2/gitm/gitm_BWDRAG_fixedscaledCD/\n",
      "|\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "\n",
      "Run #2          Running IIS\n",
      "Run #2          No errors in IIS\n",
      "Run #2 ---------End of IIS\n",
      "\n",
      "Run #2          Running IIE\n",
      "Run #2          Current Time = 12:34:47 GMT-7\n",
      " ------ Current DIR:  /data/SatDragModelValidation/data/tmp/gitm_BWDRAG_fixedscaledCD/icesat2_2018314.01_gitm.CDmeanadj\n",
      "Run #2          No errors in IIE\n",
      "Run #2 ---------End of IIE\n",
      "  - convergence achieved\n",
      "Run #2          Time of IIE:  284.4068660736084 secs ( 4.74011443456014  mins)\n",
      "Run #2          Current Time = 19:39:31\n",
      "Saving fort.103 as drag_file\n",
      "Saving fort.104 as SatGeometry_file\n",
      "Run #2                Finished renaming files\n",
      "Run #2                Finished copying files to outputdir\n",
      "        Deleting tmp/:  /data/SatDragModelValidation/data/tmp/gitm_BWDRAG_fixedscaledCD/icesat2_2018314.01_gitm.CDmeanadj\n",
      "Using the ICESat-2 Class\n",
      "+==================================================\n",
      "|     Running GEODYN with Orbit Cloud Method     \n",
      "|                                                \n",
      "|     MSIS2 Density file already exists. \n",
      "|          - icesat2_2018313.01_msis2.CDmeanadj_msisin           \n",
      "|     Already have OrbitCloud file for this arc: \n",
      "|          -HASDM_OrbitCloud_2018313.01.csv\n",
      "|          - icesat2_2018313.01_hasdm_oc.CDmeanadj \n",
      "|     MSIS2 Density file already exists. \n",
      "|          - icesat2_2018314.01_msis2.CDmeanadj_msisin           \n",
      "|     Already have OrbitCloud file for this arc: \n",
      "|          -HASDM_OrbitCloud_2018314.01.csv\n",
      "|          - icesat2_2018314.01_hasdm_oc.CDmeanadj \n",
      "|     Running GEODYN with orbit cloud\n",
      "Run #1     Current Time =      12:39:40  GMT-7\n",
      "Run #1\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "| Run #1 Parameters\n",
      "| —————————————————\n",
      "|  Run Specs\n",
      "|  --------- \n",
      "|    Satellite    icesat2\n",
      "|    Run Type     DataReduction_PCE\n",
      "|    CD Type      Fixed_CD\n",
      "|    CD Value     2.076144\n",
      "|    Density      hasdm_oc\n",
      "|\n",
      "|  Epoch Info \n",
      "|  ---------- \n",
      "|    Arc          2018.313\n",
      "|    Arc length   24.0 hours\n",
      "|    Epoch Start  2018-11-09 00:00:00\n",
      "|    Epoch End    2018-11-10 00:00:00\n",
      "|    Step Size    10.0 seconds\n",
      "|\n",
      "|  Files Info\n",
      "|  ---------- \n",
      "|    Arc Name    icesat2_2018313.01_hasdm_oc.CDmeanadj\n",
      "|\n",
      "|    IISSET      .../data/inputs/sat_icesat2/setups/iisset.2018.313\n",
      "|    EXAT        .../data/inputs/sat_icesat2/external_attitude/EXAT01.2018.313.gz\n",
      "|    Output Raw  .../data/outputs_raw/icesat2/hasdm_oc/hasdm_oc_BWDRAG_fixedscaledCD/\n",
      "|\n",
      "|————————————————————————————————————————————————————————————————————————————————\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run #1          Running IIS\n",
      "Run #1          No errors in IIS\n",
      "Run #1 ---------End of IIS\n",
      "\n",
      "Run #1          Running IIE\n",
      "Run #1          Current Time = 12:40:08 GMT-7\n",
      " ------ Current DIR:  /data/SatDragModelValidation/data/tmp/hasdm_oc_BWDRAG_fixedscaledCD/icesat2_2018313.01_hasdm_oc.CDmeanadj\n",
      "Run #1          No errors in IIE\n",
      "Run #1 ---------End of IIE\n",
      "  - convergence achieved\n",
      "Run #1          Time of IIE:  401.9785780906677 secs ( 6.699642968177796  mins)\n",
      "Run #1          Current Time = 19:46:50\n",
      "Saving fort.103 as drag_file\n",
      "Saving fort.104 as SatGeometry_file\n",
      "Run #1                Finished renaming files\n",
      "Run #1                Finished copying files to outputdir\n",
      "        Deleting tmp/:  /data/SatDragModelValidation/data/tmp/hasdm_oc_BWDRAG_fixedscaledCD/icesat2_2018313.01_hasdm_oc.CDmeanadj\n",
      "|     Running GEODYN with orbit cloud\n",
      "Run #2     Current Time =      12:46:54  GMT-7\n",
      "Run #2\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "| Run #2 Parameters\n",
      "| —————————————————\n",
      "|  Run Specs\n",
      "|  --------- \n",
      "|    Satellite    icesat2\n",
      "|    Run Type     DataReduction_PCE\n",
      "|    CD Type      Fixed_CD\n",
      "|    CD Value     2.076144\n",
      "|    Density      hasdm_oc\n",
      "|\n",
      "|  Epoch Info \n",
      "|  ---------- \n",
      "|    Arc          2018.314\n",
      "|    Arc length   24.0 hours\n",
      "|    Epoch Start  2018-11-10 00:00:00\n",
      "|    Epoch End    2018-11-11 00:00:00\n",
      "|    Step Size    10.0 seconds\n",
      "|\n",
      "|  Files Info\n",
      "|  ---------- \n",
      "|    Arc Name    icesat2_2018314.01_hasdm_oc.CDmeanadj\n",
      "|\n",
      "|    IISSET      .../data/inputs/sat_icesat2/setups/iisset.2018.314\n",
      "|    EXAT        .../data/inputs/sat_icesat2/external_attitude/EXAT01.2018.314.gz\n",
      "|    Output Raw  .../data/outputs_raw/icesat2/hasdm_oc/hasdm_oc_BWDRAG_fixedscaledCD/\n",
      "|\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "\n",
      "Run #2          Running IIS\n",
      "Run #2          No errors in IIS\n",
      "Run #2 ---------End of IIS\n",
      "\n",
      "Run #2          Running IIE\n",
      "Run #2          Current Time = 12:47:22 GMT-7\n",
      " ------ Current DIR:  /data/SatDragModelValidation/data/tmp/hasdm_oc_BWDRAG_fixedscaledCD/icesat2_2018314.01_hasdm_oc.CDmeanadj\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# from pygeodyn.PYGEODYN import Pygeodyn\n",
    "from gc import collect as gc_collect\n",
    "\n",
    "import pickle \n",
    "import os\n",
    "\n",
    "\n",
    "file_raw_ICs = f\"/data/SatDragModelValidation/data/inputs/sat_icesat2/g2b/\"\\\n",
    "          +\"ICESat2_RawEphem_20181108_20181124.txt\"\n",
    "\n",
    "\n",
    "dir_save    =  '/data/SatDragModelValidation/data/outputs_clean/'\\\n",
    "             + 'icesat2/Paper2023_icesat2_assessment/results_2week_ScalingFactor/'\n",
    "\n",
    "pickleName = '_2weeks_TwoWeekDragScaleFactor.pkl'\n",
    "\n",
    "obj = {}\n",
    "for i,den in enumerate(run_list):\n",
    "    \n",
    "    settings_icesat2= {# Basic input settings\n",
    "                 'satellite'      : {'input': 'icesat2'},\n",
    "                 'den_model'      : {'input': den},\n",
    "                 'run_type'       : {'input': 'DataReduction_PCE'},\n",
    "                 'run_specifier'  : {'input': '_fixedscaledCD'},\n",
    "                 'cd_model'       : {'input': 'BWDRAG'},\n",
    "                 'file_string'    : {'input': 'CDmeanadj'},\n",
    "                 'model_data_path' : {'input': run_dict[den]['model_path']},\n",
    "                 # Force Model settings\n",
    "                  'cd_type'               : {'input':\"Fixed_CD\"},\n",
    "                  'cd_value'              : {'input':run_dict[den]['CD']},\n",
    "                  'scaling_factor'        : {'input':False},\n",
    "#                   'hours_between_cd_adj'  : {'input':24},\n",
    "                  #### Comment for unadjusted run:\n",
    "                  'cd_adjustment_boolean' : {'input':False },\n",
    "                  #### ---------------------------------------\n",
    "                 # Run\n",
    "                  'step'           : {'input': 10.},\n",
    "                  'orbfil_step'    : {'input': 120.},\n",
    "                  'which_ICfile'   : {'input':file_raw_ICs},\n",
    "                   #    # 312-328\n",
    "                  'arc'            : {'input':[\n",
    "                                               '2018.313',\n",
    "                                               '2018.314',\n",
    "#                                                '2018.315',\n",
    "#                                                '2018.316',\n",
    "#                                                '2018.317',\n",
    "#                                                '2018.318',\n",
    "#                                                '2018.319',\n",
    "#                                                '2018.320',\n",
    "#                                                '2018.321',\n",
    "#                                                '2018.322', # failed convergence for MSIS\n",
    "#                                                '2018.323',\n",
    "#                                                '2018.324', # failed convergence for MSIS\n",
    "#                                                '2018.325',\n",
    "#                                                '2018.326',\n",
    "                                              ]},\n",
    "                  'epoch_start'    : {'input': [\n",
    "                                                '2018-11-09 00:00:00',\n",
    "                                                '2018-11-10 00:00:00',\n",
    "#                                                 '2018-11-11 00:00:00',\n",
    "#                                                 '2018-11-12 00:00:00',\n",
    "#                                                 '2018-11-13 00:00:00',\n",
    "#                                                 '2018-11-14 00:00:00',\n",
    "#                                                 '2018-11-15 00:00:00',\n",
    "#                                                 '2018-11-16 00:00:00',\n",
    "#                                                 '2018-11-17 00:00:00',\n",
    "#                                                 '2018-11-18 00:00:00',\n",
    "#                                                 '2018-11-19 00:00:00',\n",
    "#                                                 '2018-11-20 00:00:00',\n",
    "#                                                 '2018-11-21 00:00:00',\n",
    "#                                                 '2018-11-22 00:00:00',\n",
    "                                               ]},\n",
    "                   #\n",
    "                  'epoch_stop'     : {'input':[ \n",
    "                                                '2018-11-10 00:00:00',\n",
    "                                                '2018-11-11 00:00:00',\n",
    "#                                                 '2018-11-12 00:00:00',\n",
    "#                                                 '2018-11-13 00:00:00',\n",
    "#                                                 '2018-11-14 00:00:00',\n",
    "#                                                 '2018-11-15 00:00:00',\n",
    "#                                                 '2018-11-16 00:00:00',\n",
    "#                                                 '2018-11-17 00:00:00',\n",
    "#                                                 '2018-11-18 00:00:00',\n",
    "#                                                 '2018-11-19 00:00:00',\n",
    "#                                                 '2018-11-20 00:00:00',\n",
    "#                                                 '2018-11-21 00:00:00',\n",
    "#                                                 '2018-11-22 00:00:00',\n",
    "#                                                 '2018-11-23 00:00:00',\n",
    "                                                ]},  \n",
    "                   #\n",
    "\n",
    "                                \n",
    "                  'global_options' : {'input':'pso_2018'},\n",
    "                 # Request read on raw outputs\n",
    "                  'request_data'   : {'input': ['Trajectory_orbfil', \n",
    "                                               'Density', \n",
    "                                               'Residuals_summary',\n",
    "                                               'RunSummary',\n",
    "                                               'DragFile',\n",
    "                                               'AdjustedParams'\n",
    "                                               ]},\n",
    "              #end dict\n",
    "              }\n",
    "\n",
    "\n",
    "    \n",
    "    sat = Pygeodyn(settings_icesat2, use_file=False)\n",
    "    sat.run_arcs()\n",
    "#     obj[den] =  sat.getData_BigData_lowmemory()\n",
    "    gc_collect()\n",
    "\n",
    "\n",
    "\n",
    "#     pickle_file = dir_save+den+pickleName\n",
    "#     if not os.path.exists(pickle_file):\n",
    "#         print('Must create pickle file...')\n",
    "#         print('   ',  pickle_file)\n",
    "#         print('   ', 'Reading Geodyn Data')\n",
    "\n",
    "#         ### Load the data into an object\n",
    "#         sat = Pygeodyn(settings_icesat2, use_file=False)\n",
    "#         obj = sat.getData_BigData_lowmemory()\n",
    "#         gc_collect()\n",
    "\n",
    "#         #### Pickle the object to save it\n",
    "#         print('   ', 'Saving pickle')\n",
    "#         filehandler = open(pickle_file, 'wb') \n",
    "#         pickle.dump(vars(obj), filehandler)\n",
    "#         filehandler.close()\n",
    "#         obj = 0\n",
    "#         print('   ', 'Saved pickle')\n",
    "\n",
    "# obj = {}\n",
    "# for i,model in enumerate(run_list):     \n",
    "#     ### Load the data if the pickles exist\n",
    "#     print()\n",
    "#     print()\n",
    "#     gc_collect()\n",
    "\n",
    "#     pickle_file = dir_save+model+pickleName\n",
    "\n",
    "#     filehandler = open(pickle_file, 'rb') \n",
    "#     obj[model] = pickle.load(filehandler)\n",
    "#     filehandler.close()\n",
    "#     print('Loaded data from pickle... ', model)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# #     obj[den] =  sat.get_make_CleanData()\n",
    "    \n",
    "#     ### -----------------------------------------------------\n",
    "# # startdate = \"2018-11-08\"\n",
    "# # enddate   = \"2018-11-24\"  #24\n",
    "# # sat = Pygeodyn(settings_icesat2, use_file=False)\n",
    "# # sat.initialize_timeperiod_stage1(startdate, enddate,\n",
    "# #                                  overwrite_exat=False, \n",
    "# #                                  overwrite_g2b=True)\n",
    "# # import sys\n",
    "# # sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d180a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-06T18:23:40.255496Z",
     "start_time": "2023-03-06T18:23:40.251072Z"
    }
   },
   "source": [
    "1. Check if cleaned data exists  \n",
    "   1. If not, process the `getData_BigData_lowmemory()`\n",
    "   2. Further process the data into textfiles, saving the following.\n",
    "       - One PCE file containing all arcs (XYZ, NTW, 120 sec cadence)\n",
    "       - Seven Orbit Fit files for each density model (XYZ, NTW, 120 sec cadence)\n",
    "       - Density File at proper time cadence (time, lon, lat, alt, to match orbfil data, 120 sec cadence)\n",
    "       - Arc details file\n",
    "           - Drag scaling factor\n",
    "           - any other arc details\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c66fad8",
   "metadata": {},
   "source": [
    "# Run output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fd0360",
   "metadata": {},
   "source": [
    "## plot Drag acceleration scaling factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdf8cdf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:19.963Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_percent_change(a, b):\n",
    "    from numpy import absolute as np_abs\n",
    "        \n",
    "    return(  ( (b-a)/np_abs(a) )*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4860b02c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:19.966Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "\n",
    "# def plot__ScalingFactor(fig, obj_m1, model_dict ):\n",
    "\n",
    "#     cd_apriori  = 2.5\n",
    "\n",
    "#     ####  Get plot Parameters for this model\n",
    "#     model_m1 = obj_m1['global_params']['prms']['den_model']\n",
    "#     col = get_plot_params( model_m1)\n",
    "#     dateplot = []\n",
    "#     rms_totals = []\n",
    "\n",
    "#     fig.add_trace(go.Scattergl(x=model_dict['ScalingFactor_times'],\n",
    "#                            y=model_dict['ScalingFactors'],\n",
    "#                            name= model,\n",
    "#                            mode='markers+lines',\n",
    "#                            opacity=1,\n",
    "#                                marker=dict(color=col, size=6 ),\n",
    "#                            line = dict(shape = 'hvh', color = col, width=2),\n",
    "#                            showlegend=False),\n",
    "#                            secondary_y=False,row=1, col=1)\n",
    "\n",
    "#     fig.add_trace(go.Scattergl(x=model_dict['ScalingFactor_times'],\n",
    "#                            y=model_dict['percent_change'],\n",
    "#                            name= model,\n",
    "#                            mode='markers+lines',\n",
    "#                            opacity=1,\n",
    "#                                marker=dict(color=col, size=6 ),\n",
    "#                            line = dict(shape = 'hvh', color = col, width=2),\n",
    "#                            showlegend=False),\n",
    "#                            secondary_y=False,row=2, col=1)\n",
    "\n",
    "# # full_fig = fig.full_figure_for_development()\n",
    "\n",
    "#     if model_m1 == 'jb2008':\n",
    "\n",
    "#         fig.update_yaxes( title=r\"$\\text{Scaling Factor}$\",\n",
    "#                          range=[0.25,2.05], \n",
    "#                  exponentformat= 'power',row=1, col=1)\n",
    "#         fig.update_yaxes( title=r\"$\\% \\text{ change}$\",\n",
    "#                  exponentformat= 'power',row=2, col=1)\n",
    "#         ###\n",
    "#         ###  DATE on Final x-Axis only\n",
    "#         fig.update_xaxes(title=r\"$\\text{Date}$\", \n",
    "#                          range=[pd.to_datetime( \"181108-160000\", format='%y%m%d-%H%M%S'),\n",
    "#                                 pd.to_datetime( \"181123-120000\", format='%y%m%d-%H%M%S')],\n",
    "#                          row=2, col=1)\n",
    "\n",
    "\n",
    "#     return(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ### -----------------------------------------------------------------------------------------------------\n",
    "# ### -----------------------------------------------------------------------------------------------------\n",
    "# ### -----------------------------------------------------------------------------------------------------\n",
    "# ### -----------------------------------------------------------------------------------------------------\n",
    "# ### -----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# ROWS_NUM = 2\n",
    "# fig = make_subplots(rows=ROWS_NUM, cols=1,\n",
    "#                     #                     \n",
    "#                     shared_xaxes=True)\n",
    "\n",
    "# # obj[den] = vars(obj[den])\n",
    "# # satid = int(obj['jb2008']['global_params']['prms']['sat_ID'])\n",
    "# satid = int(obj[den]['global_params']['prms']['sat_ID'])\n",
    "# for plot_num, model in enumerate(run_list):\n",
    "#     ScalingFactors      = []\n",
    "#     ScalingFactor_times = []\n",
    "#     PercChange          = []\n",
    "#     for iarc,valarc in enumerate(obj[model]['global_params']['arc_input']):\n",
    "#         arc = valarc+'.01'\n",
    "#         iters = int(obj[model]['run_parameters'+arc]['total_iterations'])\n",
    "#         for itime in obj[model]['AdjustedParams'][arc][iters][satid]['0CD'].keys():\n",
    "#             CURRENT_VALUE = obj[model]['AdjustedParams'][arc][iters][satid]['0CD'][itime]['CURRENT_VALUE']\n",
    "#             APRIORI_VALUE = obj[model]['AdjustedParams'][arc][iters][satid]['0CD'][itime]['APRIORI_VALUE']\n",
    "#             ScalingFactors.append(CURRENT_VALUE/APRIORI_VALUE)\n",
    "#             ScalingFactor_times.append(itime - datetime.timedelta(hours=12) )\n",
    "#             PercChange.append(calc_percent_change(APRIORI_VALUE, CURRENT_VALUE))\n",
    "            \n",
    "#     run_dict[model]['ScalingFactor_times'] = ScalingFactor_times\n",
    "#     run_dict[model]['ScalingFactors']      = ScalingFactors\n",
    "\n",
    "#     run_dict[model]['percent_change']      = PercChange\n",
    "\n",
    "# for model in run_dict.keys():\n",
    "#     fig = plot__ScalingFactor(fig, obj[model],  run_dict[model] )\n",
    "\n",
    "\n",
    "# #######################################################\n",
    "# font_dict=dict(family='Arial',size=16,color='black')\n",
    "# #######################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for i in [1,2]:\n",
    "#     fig.update_xaxes(### LINE at axis border\n",
    "#                       showline=True,\n",
    "#                       showticklabels=True,\n",
    "#                       linecolor='black',\n",
    "#                       linewidth=1,\n",
    "#                      ### Major ticks\n",
    "#                       ticks='inside',\n",
    "#                       tickfont=font_dict,\n",
    "#                       mirror=True,\n",
    "#                       tickwidth=2,\n",
    "#                       ticklen=9,\n",
    "#                       tickcolor='grey',\n",
    "#                       tick0=\"2018-11-9\" ,\n",
    "#                       dtick=86400000.0*2,    # milliseconds in a day, every 7 days\n",
    "#                       #### Minor Ticks\n",
    "#                        minor=dict(\n",
    "#                          dtick=86400000.0, # milliseconds in a day\n",
    "#                          tickwidth=1,\n",
    "#                          ticklen=4,\n",
    "#                          tickcolor='grey',\n",
    "#                          ticks='inside'),\n",
    "#                       ### GRID\n",
    "#                        gridcolor='gainsboro',\n",
    "#                        gridwidth=1,\n",
    "#                        layer='above traces',\n",
    "#                        tickangle=0,\n",
    "#                        row=i, col=1)\n",
    "#     fig.update_yaxes(showline=True,      # add line at x=0\n",
    "#                          showticklabels=True,\n",
    "#                          linecolor='black',  # line color\n",
    "#                          linewidth=1,        # line size\n",
    "#                      ticks='inside',     # ticks outside axis\n",
    "#                      tickfont=font_dict, # tick label font\n",
    "#                      mirror='allticks',  # add ticks to top/right axes\n",
    "#                      tickwidth=1,      # tick width\n",
    "#                      tickcolor='black',  # tick color\n",
    "#                      gridcolor='gainsboro',\n",
    "#                      gridwidth=1,\n",
    "#                      layer='above traces',\n",
    "#                      row=i, col=1)\n",
    "\n",
    "\n",
    "# modelnames=[]\n",
    "# modelcolors = []\n",
    "# #### LEGEND ####\n",
    "# for model in run_dict.keys():\n",
    "#     if model == 'msis2':\n",
    "#         modelnames.append(\"MSISe2\")\n",
    "#         modelcolors.append(col_msis2)\n",
    "\n",
    "#     elif model == 'dtm2020_o':\n",
    "#         modelnames.append(\"DTM2020\")\n",
    "#         modelcolors.append(col_dtm2020)\n",
    "\n",
    "#     elif model == 'jb2008':\n",
    "#         modelnames.append(\"JB2008\")\n",
    "#         modelcolors.append(col_jb2008)\n",
    "\n",
    "#     elif model == 'tiegcm_oc':\n",
    "#         modelnames.append(\"TIEGCM\")\n",
    "#         modelcolors.append(col_tiegcm_oc)\n",
    "\n",
    "#     elif model == 'hasdm_oc':\n",
    "#         modelnames.append(\"HASDM\")\n",
    "#         modelcolors.append(col_hasdm_oc)\n",
    "\n",
    "#     elif model == 'ctipe_oc':\n",
    "#         modelnames.append(\"CTIPe\")\n",
    "#         modelcolors.append(col_ctipe_oc)\n",
    "\n",
    "#     elif model == 'gitm':\n",
    "#         modelnames.append(\"GITM\")\n",
    "#         modelcolors.append(col_gitm)\n",
    "\n",
    "\n",
    "\n",
    "# df = pd.DataFrame({\"starts_colors\": modelcolors\n",
    "#                                     })\n",
    "\n",
    "# fig.update_traces(showlegend=False).add_traces(\n",
    "#     [   go.Scattergl(name=modelnames[i], \n",
    "#                x=[pd.to_datetime( \"181107-000000\", format='%y%m%d-%H%M%S')],\n",
    "#                mode='lines',\n",
    "#                line = dict(shape = 'hv',  width=10),\n",
    "#                marker_color=c, \n",
    "#                showlegend=True)\n",
    "#         for i,c in enumerate((df.loc[:,[\"starts_colors\"]].values.ravel()))])\n",
    "\n",
    "# fig.update_layout(legend=dict(\n",
    "#     yanchor=\"middle\",\n",
    "#     y=0.5,\n",
    "#     xanchor=\"center\",\n",
    "#     x=1.1,\n",
    "# #     x=1.015,\n",
    "#         font=font_dict      ,\n",
    "#         bgcolor=\"white\",\n",
    "#         bordercolor=\"darkgrey\",\n",
    "#         borderwidth=0.8,\n",
    "#     )  )\n",
    "\n",
    "# fig.update_layout(\n",
    "# #                   title = '',\n",
    "#                   autosize=False,    width=1000,    height=600,\n",
    "#                   legend= {'itemsizing': 'trace'},\n",
    "#                   font=font_dict,\n",
    "#                   plot_bgcolor='white', \n",
    "#                  )\n",
    "# fig.update_annotations(font_size=14)  # Increase size of subplot title\n",
    "\n",
    "# fig.show(#renderer=\"jpg\",\n",
    "#          config=dict({\n",
    "#             'displayModeBar': False,\n",
    "#             'responsive': False,\n",
    "#             'staticPlot': True,\n",
    "#             'displaylogo': False,\n",
    "#             'showTips': False,\n",
    "#             }))\n",
    "\n",
    "# #     if save_plot_flag:\n",
    "# #         pio.write_image(fig, plot_dir+'Assessment_CDAvgAdj.jpg', scale=3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f065034",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:19.968Z"
    }
   },
   "outputs": [],
   "source": [
    "# obj[model]['AdjustedParams']['2018.313.01'][7][satid]['0CD'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3077bde4",
   "metadata": {},
   "source": [
    "### Scaling factor w Kp Cross correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba606ce",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:19.971Z"
    }
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "def read_nc_file( filename, variables):\n",
    "    ''' This function reads the TIEGCM .nc files and saves the given input variables to a dictionary.\n",
    "        The breakloop feature is here so that if the file doesn't exist the code can still continue.  '''\n",
    "    status = os.path.exists(filename)\n",
    "    \n",
    "    if status == True:\n",
    "        data = {}\n",
    "        for i, var_names in enumerate(variables):\n",
    "            ncid =  Dataset(filename,\"r+\", format=\"NETCDF4\")# filename must be a string\n",
    "            varData = ncid.variables\n",
    "            data[var_names] = np.array(varData[var_names])  \n",
    "    elif status == False:\n",
    "        print('No File Found', filename )\n",
    "        breakloop = True\n",
    "        data = 0\n",
    "        return( data , breakloop)\n",
    "    breakloop = False\n",
    "    return(data,breakloop )\n",
    "\n",
    "\n",
    "arc_list = []\n",
    "\n",
    "arc_list_18 = np.arange(292,366)\n",
    "for i in arc_list_18:\n",
    "    val = '2018'+str(i)\n",
    "    arc_list.append(int(val))\n",
    "    \n",
    "    #     print(val)\n",
    "    \n",
    "arc_list_19 = np.arange(1,10)\n",
    "for i in arc_list_19:\n",
    "    val = '201900'+str(i)\n",
    "    arc_list.append(int(val))\n",
    "\n",
    "path =  \"/data/SatDragModelValidation/data/inputs/atmos_models/geo_phys_indicies/\"\n",
    "path_to_f107 = path+ 'gpi_1960001-2021243_f107aDaily.nc'\n",
    "variables = ['year_day', 'f107d', 'f107a', 'kp']\n",
    "f107_data = read_nc_file(path_to_f107, variables)\n",
    "\n",
    "date = []\n",
    "kp_list = []\n",
    "f107d_list = []\n",
    "f107a_list  = []\n",
    "date_3hr = []\n",
    "doy_list    = []\n",
    "\n",
    "\n",
    "\n",
    "for i,val in enumerate(arc_list):\n",
    "    \n",
    "    index = f107_data[0]['year_day']==val\n",
    "    kp_list.append(f107_data[0]['kp'][index][0])\n",
    "    f107d_list.append(f107_data[0]['f107d'][index][0])\n",
    "    f107a_list.append(f107_data[0]['f107a'][index][0])\n",
    "    doy_list.append(str(f107_data[0]['year_day'][index][0])[-3:])\n",
    "\n",
    "    date.append(pd.to_datetime( str(val), format='%Y%j'))\n",
    "\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=0))\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=3))\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=6))\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=9))\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=12))\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=15))\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=18))\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=21))\n",
    "#     date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=24))\n",
    "    \n",
    "kp_expand = []\n",
    "for i in kp_list:\n",
    "    for ii in i:\n",
    "        kp_expand.append(ii)\n",
    "        \n",
    "        \n",
    "        \n",
    "solar_fluxes = {}\n",
    "solar_fluxes['f107d_list'] = f107d_list\n",
    "solar_fluxes['f107a_list'] = f107a_list\n",
    "solar_fluxes['date']       = date\n",
    "solar_fluxes['date_3hr']   = date_3hr\n",
    "solar_fluxes['kp_expand']  = kp_expand\n",
    "\n",
    "f107d_earth = []\n",
    "f107a_earth = []\n",
    "######################################################################### \n",
    "##### Account for the F10.7 at earth (instead of referenced at 1AU) #####\n",
    "######################################################################### \n",
    "\n",
    "for i_doy,val_doy in enumerate(doy_list):\n",
    "    iday = int(val_doy)\n",
    "    theta0 = 2 * np.pi * (iday)/365.\n",
    "    sfeps = 1.000110 + 0.034221*np.cos(theta0)+0.001280* np.sin(theta0) +0.000719*np.cos(2.*theta0)+0.000077*np.sin(2.*theta0)\n",
    "\n",
    "    f107d_earth.append(sfeps * solar_fluxes['f107d_list'][i_doy])\n",
    "    f107a_earth.append(sfeps * solar_fluxes['f107a_list'][i_doy])\n",
    "\n",
    "solar_fluxes['f107d_earth'] = f107d_earth\n",
    "solar_fluxes['f107a_earth'] = f107a_earth\n",
    "\n",
    "\n",
    "\n",
    "### Prepare RMS total Plot arrays\n",
    "\n",
    "arc_listlist=[  ['2018.292', '2018.293', '2018.294', '2018.295', '2018.296', \n",
    "                 '2018.297', '2018.298', '2018.299' ],                  \n",
    "                #\n",
    "                ['2018.304', '2018.305', '2018.306', '2018.307', '2018.308' ],  \n",
    "                #\n",
    "                ['2018.313', '2018.314', '2018.315', '2018.316', '2018.317',\n",
    "                 '2018.318', '2018.319', '2018.320', '2018.321', '2018.322',\n",
    "                 '2018.323', '2018.324', '2018.325', '2018.326', '2018.327' ],  \n",
    "                #\n",
    "                ['2018.335', '2018.336', '2018.337' ],  \n",
    "                #\n",
    "                ['2018.349', '2018.350', '2018.351', '2018.352' ],  \n",
    "                #\n",
    "                ['2018.356', '2018.357', '2018.358' ],  \n",
    "                #\n",
    "                ['2018.365', '2019.001', '2019.002', '2019.003', '2019.004', \n",
    "                 '2019.005', '2019.006', '2019.007', '2019.008',\n",
    "                '2019.009'],  \n",
    "                ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07eefd7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:19.974Z"
    }
   },
   "outputs": [],
   "source": [
    "len(f107_data[0]['kp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e92da1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:19.977Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(kp_list)\n",
    "\n",
    "\n",
    "date[21:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076029e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:18:39.514850Z",
     "start_time": "2023-05-10T17:18:39.499628Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0ee627",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:18:39.868983Z",
     "start_time": "2023-05-10T17:18:39.516789Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4419667c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:19.983Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=1,\n",
    "                    vertical_spacing = 0.03,\n",
    "                    shared_xaxes=True)\n",
    "\n",
    "\n",
    "index1 = 21\n",
    "index2 = 37\n",
    "index3h_1 = 168\n",
    "index3h_2 = 289\n",
    "\n",
    "fig.add_trace(go.Scatter(x=solar_fluxes['date'][index1:index2],\n",
    "                           y=solar_fluxes['f107d_earth'][index1:index2],\n",
    "                           name= 'F107d_1AU',\n",
    "                           mode='lines',\n",
    "                           opacity=1,\n",
    "#                                marker=dict(color='cornflowerblue', size=2 ),\n",
    "                           line = dict(shape = 'hvh',dash='dash', color = 'black', width=2),\n",
    "                           showlegend=False),\n",
    "                           secondary_y=False,row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=solar_fluxes['date'][index1:index2],\n",
    "                           y=solar_fluxes['f107a_earth'][index1:index2],\n",
    "                           name= 'F107a_1AU',\n",
    "                           mode='lines',\n",
    "                           opacity=1,\n",
    "#                                marker=dict(color='cornflowerblue', size=2 ),\n",
    "                           line = dict(shape = 'hvh', color = 'black', width=2),\n",
    "                           showlegend=False),\n",
    "                           secondary_y=False,row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=solar_fluxes['date_3hr'][index3h_1:index3h_2],\n",
    "                           y=solar_fluxes['kp_expand'][index3h_1:index3h_2],\n",
    "                           name= 'Kp',\n",
    "                           mode='lines',\n",
    "                           opacity=1,\n",
    "#                                marker=dict(color='black',size=2),\n",
    "                           line = dict(shape = 'hvh', color = 'black', width=2),\n",
    "                           showlegend=False),\n",
    "                           secondary_y=False,row=2, col=1) \n",
    "\n",
    "\n",
    "index_1shaded=16\n",
    "index3h_1shaded = 128\n",
    "index3h_1shaded = 128\n",
    "\n",
    "fig.add_trace(go.Scatter(x=solar_fluxes['date'][index_1shaded:index1+1],\n",
    "                           y=solar_fluxes['f107d_earth'][index_1shaded:index1+1],\n",
    "                           name= 'F107d',\n",
    "                           mode='lines',\n",
    "                           opacity=0.65,\n",
    "                           line = dict(shape = 'hvh',dash='dash', color = 'black', width=1.5),\n",
    "                           showlegend=False),\n",
    "                           secondary_y=False,row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=solar_fluxes['date'][index_1shaded:index1+1],\n",
    "                           y=solar_fluxes['f107a_earth'][index_1shaded:index1+1],\n",
    "                           name= 'F107a',\n",
    "                           mode='lines',\n",
    "                           opacity=0.65,\n",
    "                           line = dict(shape = 'hvh', color = 'black', width=1.5),\n",
    "                           showlegend=False),\n",
    "                           secondary_y=False,row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=solar_fluxes['date_3hr'][index3h_1shaded:index3h_1+1],\n",
    "                           y=solar_fluxes['kp_expand'][index3h_1shaded:index3h_1+1],\n",
    "                           name= 'Kp',\n",
    "                           mode='lines',\n",
    "                           opacity=0.55,\n",
    "                           line = dict(shape = 'hvh', color = 'black', width=1.5),\n",
    "                           showlegend=False),\n",
    "                           secondary_y=False,row=2, col=1) \n",
    "### --------------------------------------------------------------------------------------------\n",
    "fig.add_trace(go.Scatter(x=solar_fluxes['date'][index2-1:index2+5],\n",
    "                           y=solar_fluxes['f107d_earth'][index2-1:index2+5],\n",
    "                           name= 'F107d',\n",
    "                           mode='lines',\n",
    "                           opacity=0.65,\n",
    "                           line = dict(shape = 'hvh',dash='dash', color = 'black', width=1.5),\n",
    "                           showlegend=False),\n",
    "                           secondary_y=False,row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=solar_fluxes['date'][index2-1:index2+5],\n",
    "                           y=solar_fluxes['f107a_earth'][index2-1:index2+5],\n",
    "                           name= 'F107a',\n",
    "                           mode='lines',\n",
    "                           opacity=0.65,\n",
    "                           line = dict(shape = 'hvh', color = 'black', width=1.5),\n",
    "                           showlegend=False),\n",
    "                           secondary_y=False,row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=solar_fluxes['date_3hr'][index3h_2-1:index3h_2+40],\n",
    "                           y=solar_fluxes['kp_expand'][index3h_2-1:index3h_2+40],\n",
    "                           name= 'Kp',\n",
    "                           mode='lines',\n",
    "                           opacity=0.55,\n",
    "                           line = dict(shape = 'hvh', color = 'black', width=1.5),\n",
    "                           showlegend=False),\n",
    "                           secondary_y=False,row=2, col=1) \n",
    "\n",
    "\n",
    "\n",
    "fig.add_vrect(x0=pd.to_datetime( str(2018308), format='%Y%j'),\n",
    "              x1=pd.to_datetime( str(2018313), format='%Y%j'),\n",
    "              fillcolor='gainsboro',\n",
    "              opacity=.6,\n",
    "              layer=\"below\",\n",
    "              line_width=0,\n",
    "#               row=1,col=1,\n",
    "             )\n",
    "fig.add_vrect(x0=pd.to_datetime( str(2018328), format='%Y%j'),\n",
    "              x1=pd.to_datetime( str(2018333), format='%Y%j'),\n",
    "              fillcolor='gainsboro',\n",
    "              opacity=.6,\n",
    "              layer=\"below\",\n",
    "              line_width=0,\n",
    "#               row=1,col=1,\n",
    "             )\n",
    "\n",
    "\n",
    "  \n",
    "    \n",
    "#######################################################\n",
    "font_dict=dict(family='Arial',size=16,color='black')\n",
    "#######################################################\n",
    "\n",
    "fig.update_yaxes(title_text=r\"$\\text{F}_{\\text{10.7}}\\text{ Solar Flux (sfu)}$\", \n",
    "#                  color='black',\n",
    "                 range=[64.5, 86],\n",
    "                  row=1, col=1,)\n",
    "\n",
    "fig.update_yaxes(title_text=r\"$\\text{K}_\\text{p}\\text{ Index}$\",\n",
    "                  range=[-0.3, 8],\n",
    "                 row=2, col=1,)\n",
    "\n",
    "   \n",
    "\n",
    "for i in [1,2]:\n",
    "    if i ==1:\n",
    "        xlabel=False\n",
    "    else:\n",
    "        xlabel=True\n",
    "    \n",
    "    fig.update_xaxes(### LINE at axis border\n",
    "                      showline=True,showticklabels=xlabel,\n",
    "                      linecolor='black',linewidth=1,\n",
    "                     ### Major ticks\n",
    "                      ticks='inside',tickfont=font_dict,mirror=True,\n",
    "                      tickwidth=2,ticklen=9,\n",
    "                      tickcolor='grey',tick0=\"2018-11-9\" ,\n",
    "                      dtick=86400000.0*2,    # milliseconds in a day, every 7 days\n",
    "                      #### Minor Ticks\n",
    "                       minor=dict(dtick=86400000.0, # milliseconds in a day\n",
    "                         tickwidth=1,ticklen=4,\n",
    "                         tickcolor='grey',ticks='inside'),\n",
    "                      ### GRID\n",
    "                       gridcolor='gainsboro',gridwidth=1,\n",
    "                       layer='above traces',tickangle=-45,\n",
    "                       row=i, col=1)\n",
    "    fig.update_yaxes(showline=True,      # add line at x=0\n",
    "                     showticklabels=True,linecolor='black',  \n",
    "                     linewidth=1,ticks='inside',tickfont=font_dict, \n",
    "                     mirror='allticks',tickwidth=1,tickcolor='black',\n",
    "                     gridcolor='gainsboro',gridwidth=1,layer='above traces',\n",
    "                     row=i, col=1)\n",
    "\n",
    "fig.update_layout(autosize=False,    width=800,    height=600,\n",
    "                  legend= {'itemsizing': 'trace'},\n",
    "                  font=font_dict, plot_bgcolor='white', \n",
    "                 )\n",
    "fig.update_annotations(font_size=14)  # Increase size of subplot title\n",
    "fig.show(config=config)\n",
    "\n",
    "### pio.write_image(fig, plots_dir+'twoweek_fullresult.pdf')\n",
    "# pio.write_image(fig, plots_dir+'f107_kp_twoweek.jpg', scale=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43bafc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843925ef",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:19.987Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "def plot__ScalingFactor(fig, obj_m1, model_dict ):\n",
    "\n",
    "    cd_apriori  = 2.5\n",
    "\n",
    "    ####  Get plot Parameters for this model\n",
    "    model_m1 = obj_m1['global_params']['prms']['den_model']\n",
    "    col = get_plot_params( model_m1)\n",
    "    dateplot = []\n",
    "    rms_totals = []\n",
    "\n",
    "\n",
    "    fig.add_trace(go.Scattergl(x=model_dict['ScalingFactor_times'],\n",
    "                           y=model_dict['percent_change'],\n",
    "                           name= model,\n",
    "                           mode='markers+lines',\n",
    "                           opacity=1,\n",
    "                               marker=dict(color=col, size=6 ),\n",
    "                           line = dict(shape = 'hvh', color = col, width=2),\n",
    "                           showlegend=False),\n",
    "                           secondary_y=False,row=1, col=1)\n",
    "\n",
    "# full_fig = fig.full_figure_for_development()\n",
    "\n",
    "    if model_m1 == 'jb2008':\n",
    "\n",
    "        fig.update_yaxes( title=r\"$\\text{Scaling Factor as } \\% \\text{ change}$\",\n",
    "                 exponentformat= 'power',row=1, col=1)\n",
    "        ###\n",
    "        ###  DATE on Final x-Axis only\n",
    "#         fig.update_xaxes(title=r\"$\\text{Date}$\", \n",
    "#                          range=[pd.to_datetime( \"181108-160000\", format='%y%m%d-%H%M%S'),\n",
    "#                                 pd.to_datetime( \"181123-120000\", format='%y%m%d-%H%M%S')],\n",
    "#                          row=1, col=1)\n",
    "\n",
    "\n",
    "    return(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### -----------------------------------------------------------------------------------------------------\n",
    "### -----------------------------------------------------------------------------------------------------\n",
    "### -----------------------------------------------------------------------------------------------------\n",
    "### -----------------------------------------------------------------------------------------------------\n",
    "### -----------------------------------------------------------------------------------------------------\n",
    "\n",
    "ROWS_NUM = 1\n",
    "fig = make_subplots(rows=ROWS_NUM, cols=1,\n",
    "                    #                     \n",
    "                    shared_xaxes=True)\n",
    "\n",
    "# obj[den] = vars(obj[den])\n",
    "# satid = int(obj['jb2008']['global_params']['prms']['sat_ID'])\n",
    "satid = int(obj[den]['global_params']['prms']['sat_ID'])\n",
    "for plot_num, model in enumerate(run_list):\n",
    "    ScalingFactors      = []\n",
    "    ScalingFactor_times = []\n",
    "    PercChange          = []\n",
    "    for iarc,valarc in enumerate(obj[model]['global_params']['arc_input']):\n",
    "        arc = valarc+'.01'\n",
    "        iters = int(obj[model]['run_parameters'+arc]['total_iterations'])\n",
    "        for itime in obj[model]['AdjustedParams'][arc][iters][satid]['0CD'].keys():\n",
    "            CURRENT_VALUE = obj[model]['AdjustedParams'][arc][iters][satid]['0CD'][itime]['CURRENT_VALUE']\n",
    "            APRIORI_VALUE = obj[model]['AdjustedParams'][arc][iters][satid]['0CD'][itime]['APRIORI_VALUE']\n",
    "            ScalingFactors.append(CURRENT_VALUE/APRIORI_VALUE)\n",
    "            ScalingFactor_times.append(itime - datetime.timedelta(hours=12) )\n",
    "            PercChange.append(calc_percent_change(APRIORI_VALUE, CURRENT_VALUE))\n",
    "            \n",
    "    run_dict[model]['ScalingFactor_times'] = ScalingFactor_times\n",
    "    run_dict[model]['ScalingFactors']      = ScalingFactors\n",
    "\n",
    "    run_dict[model]['percent_change']      = PercChange\n",
    "\n",
    "for model in run_dict.keys():\n",
    "    fig = plot__ScalingFactor(fig, obj[model],  run_dict[model] )\n",
    "\n",
    "\n",
    "#######################################################\n",
    "font_dict=dict(family='Arial',size=16,color='black')\n",
    "#######################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in [1]:\n",
    "    fig.update_xaxes(### LINE at axis border\n",
    "                      showline=True,\n",
    "                      showticklabels=True,\n",
    "                      linecolor='black',\n",
    "                      linewidth=1,\n",
    "                     ### Major ticks\n",
    "                      ticks='inside',\n",
    "                      tickfont=font_dict,\n",
    "                      mirror=True,\n",
    "                      tickwidth=2,\n",
    "                      ticklen=9,\n",
    "                      tickcolor='grey',\n",
    "                      tick0=\"2018-11-9\" ,\n",
    "                      dtick=86400000.0*1,    # milliseconds in a day, every 7 days\n",
    "#                       tickformat='%m/%d',\n",
    "                    ticklabelstep=2,\n",
    "                      #### Minor Ticks\n",
    "                       minor=dict(\n",
    "                         dtick=86400000.0, # milliseconds in a day\n",
    "                         tickwidth=1,\n",
    "                         ticklen=4,\n",
    "                         tickcolor='grey',\n",
    "                         ticks='inside'),\n",
    "                      ### GRID\n",
    "                       gridcolor='gainsboro',\n",
    "                       gridwidth=1,\n",
    "                       layer='above traces',\n",
    "                       tickangle=0,\n",
    "                       row=i, col=1)\n",
    "    fig.update_yaxes(showline=True,      # add line at x=0\n",
    "                         showticklabels=True,\n",
    "                         linecolor='black',  # line color\n",
    "                         linewidth=1,        # line size\n",
    "                     ticks='inside',     # ticks outside axis\n",
    "                     tickfont=font_dict, # tick label font\n",
    "                     mirror='allticks',  # add ticks to top/right axes\n",
    "                     tickwidth=1,      # tick width\n",
    "                     tickcolor='black',  # tick color\n",
    "                     gridcolor='gainsboro',\n",
    "                     gridwidth=1,\n",
    "                     layer='above traces',\n",
    "                     row=i, col=1)\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "#                   title = '',\n",
    "                  autosize=False,    width=1000,    height=450,\n",
    "                  legend= {'itemsizing': 'trace'},\n",
    "                  font=font_dict,\n",
    "                  plot_bgcolor='white', \n",
    "                 )\n",
    "fig.update_annotations(font_size=14)  # Increase size of subplot title\n",
    "\n",
    "fig.show(#renderer=\"jpg\",\n",
    "         config=dict({\n",
    "            'displayModeBar': False,\n",
    "            'responsive': False,\n",
    "            'staticPlot': True,\n",
    "            'displaylogo': False,\n",
    "            'showTips': False,\n",
    "            }))\n",
    "\n",
    "pio.write_image(fig, plot_dir+'24hourScalingFactors.jpg', scale=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8560af58",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:19.991Z"
    }
   },
   "outputs": [],
   "source": [
    "for model in run_dict.keys():\n",
    "    print(f\"{model}   {np.mean(run_dict[model]['percent_change'])}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebff3d62",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:19.994Z"
    }
   },
   "outputs": [],
   "source": [
    "# run_dict['ctipe_oc']['percent_change']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45bce30",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:19.998Z"
    }
   },
   "outputs": [],
   "source": [
    "# solar_fluxes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ffb59f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:20.000Z"
    }
   },
   "outputs": [],
   "source": [
    "# solar_fluxes['date_3hr'][index3h_1:index3h_2-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae7922d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:20.003Z"
    }
   },
   "outputs": [],
   "source": [
    "# solar_fluxes['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5b7281",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:20.006Z"
    }
   },
   "outputs": [],
   "source": [
    "run_dict[model]['CorrCoeff']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ff6c90",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:20.009Z"
    }
   },
   "outputs": [],
   "source": [
    "# index3h_1 = 168+4\n",
    "# index3h_2 = 289-4\n",
    "\n",
    "# solar_fluxes['kp_expand'][index3h_1:index3h_2]\n",
    "\n",
    "\n",
    "# date[21:35]\n",
    "# dailyKp\n",
    "\n",
    "corrcoeffs = {}\n",
    "\n",
    "for model in run_dict.keys():\n",
    "    sf_kplen = []\n",
    "    for sf in run_dict[model]['ScalingFactors']:\n",
    "        sf_kplen.append( sf )\n",
    "\n",
    "    print(model,'----------------')\n",
    "    corr = np.corrcoef(sf_kplen, dailyKp ) \n",
    "    print(f\"   R={corr[0,1]}\")\n",
    "    run_dict[model]['CorrCoeff'] = corr[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a8f52",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:20.012Z"
    }
   },
   "outputs": [],
   "source": [
    "# run_dict[model]['CorrCoeff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2923b4d9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:20.015Z"
    }
   },
   "outputs": [],
   "source": [
    "# date[21:35]\n",
    "# dailyKp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b202c2d9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:20.019Z"
    }
   },
   "outputs": [],
   "source": [
    "# path =  \"/data/SatDragModelValidation/data/inputs/atmos_models/geo_phys_indicies/\"\n",
    "# # path_to_f107 = path+ 'gpi_1960001-2021243_f107aDaily.nc'\n",
    "# # variables = ['year_day', 'f107d', 'f107a', 'kp']\n",
    "# # f107_data = read_nc_file(path_to_f107, variables)\n",
    "\n",
    "\n",
    "# '''\n",
    "# Columns 1 to 4 \n",
    "# Year of date of the UT day, for which data is given in this line\n",
    "\n",
    "# MM \n",
    "# ii \n",
    "# Columns 6 to 7 \n",
    "# Month of date of UT day\n",
    "\n",
    "# DD\n",
    "# ii\n",
    "# Columns 9 to 10 \n",
    "# Day of date of UT day\n",
    "\n",
    "# days\n",
    "# iiiii\n",
    "# Columns 12 to 16\n",
    "# Days since 1932-01-01 00:00 UT to start of UT day\n",
    "\n",
    "# days_m\n",
    "# fffff.f\n",
    "# Columns 18 to 24\n",
    "# Days since 1932-01-01 00:00 UT to midday of UT day\n",
    "\n",
    "# BSR\n",
    "# iiii\n",
    "# Columns 26 to 29\n",
    "# Bartels solar rotation number is a sequence of periods of exactly 27.0 UT days counted continuously from February 8, 1832\n",
    "\n",
    "# dB\n",
    "# ii\n",
    "# Columns 31 to 32\n",
    "# Day number within the Bartels solar rotation\n",
    "\n",
    "# Kp (8 times)\n",
    "# ii.iii (8 times)\n",
    "# Columns 34 to 39, etc.\n",
    "# Planetary three-hour index Kp for each of the intervals 00:00 to 03:00, 03:00 to 06:00, 06:00 to 09:00, 09:00 to 12:00, 12:00 to 15:00, 15:00 to 18:00, 18:00 to 21:00, 21:00 to 24:00 of the UT day, index values are rounded to three digits after the decimal point (one thousandth) and two digits are reserved for the index value before the decimal point to make the format consistent with that of the Hpo indices \n",
    "\n",
    "# ap (8 times)\n",
    "# iiii (8 times)\n",
    "# Columns 90 to 93, etc.\n",
    "# Three-hourly equivalent planetary amplitude ap for each of the intervals 00:00 to 03:00, 03:00 to 06:00, 06:00 to 09:00, 09:00 to 12:00, 12:00 to 15:00, 15:00 to 18:00, 18:00 to 21:00, 21:00 to 24:00 of the UT day, four digits are reserved for ap to make the format consistent with that of the apo indices \n",
    "\n",
    "# Ap\n",
    "# iiii\n",
    "# Columns 132 to 134\n",
    "# Daily equivalent planetary amplitude Ap, the arithmetic mean of the UT day's 8 ap values rounded to integer\n",
    "\n",
    "# SN\n",
    "# iii\n",
    "# Columns 136 to 138\n",
    "# International sunspot number SN\n",
    "\n",
    "# F10.7obs\n",
    "# ffffff.f\n",
    "# Columns 140 to 147\n",
    "# Noon-time observed solar radio flux F10.7 in s.f.u. (10^-22 W m^-2 Hz^-1)\n",
    "\n",
    "# F10.7adj\n",
    "# ffffff.f\n",
    "# Columns 149 to 156\n",
    "# Noon-time adjusted solar radio flux F10.7 in s.f.u. (10^-22 W m^-2 Hz^-1)\n",
    "\n",
    "# D\n",
    "# i\n",
    "# Column 158\n",
    "# D indicates if the Kp and SN values are definitive or preliminary. \n",
    "# D=0: Kp and SN preliminary\n",
    "# D=1: Kp definitive, SN preliminary\n",
    "# D=2 Kp and SN definitive\n",
    "\n",
    "\n",
    "# '''\n",
    "\n",
    "\n",
    "\n",
    "# pd.read_csv(path+'kp_2018.dat',\n",
    "#             sep = '\\s+',\n",
    "#         names = ['YYYY',\n",
    "#                 'MM',\n",
    "#                 'DD',\n",
    "#                 'days',\n",
    "#                 'days_m',\n",
    "#                 'BSR',\n",
    "#                 'dB',\n",
    "#                 'Kp',\n",
    "#                 'Ap',\n",
    "#                 'SN',\n",
    "#                 'F10.7obs',\n",
    "#                  'F10.7adj',\n",
    "#                  'D',\n",
    "#                                   ],\n",
    "\n",
    "#            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc7e34",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:20.025Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dailyKp = []\n",
    "\n",
    "for i in kp_list[21:37]:\n",
    "    dailyKp.append(np.mean(i))\n",
    "\n",
    "fig = make_subplots(rows=2, cols=2,\n",
    "                    subplot_titles=([None, \"Correlation with Kp\",\n",
    "                                     None,  None ]),\n",
    "                    vertical_spacing = 0.03,\n",
    "                    horizontal_spacing = 0.02,\n",
    "                        specs=[[{}, {}],\n",
    "                               [{},  {}         ]],\n",
    "                    column_widths=[0.8, 0.2],\n",
    "                    shared_xaxes=True)\n",
    "\n",
    "for model in run_dict.keys():\n",
    "    fig = plot__ScalingFactor(fig, obj[model],  run_dict[model] )\n",
    "\n",
    "    \n",
    "    \n",
    "fig.add_trace(go.Scatter(x=date[21:37],\n",
    "                           y=dailyKp,\n",
    "#                            name= 'F107d_1AU',\n",
    "                           mode='lines',\n",
    "                           opacity=1,\n",
    "#                                marker=dict(color='cornflowerblue', size=2 ),\n",
    "                           line = dict(shape = 'hv',dash='solid', color = 'black', width=3),\n",
    "                           showlegend=False),\n",
    "                           secondary_y=False,row=2, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=solar_fluxes['date_3hr'][index3h_1-5:index3h_2-5],\n",
    "                           y=solar_fluxes['kp_expand'][index3h_1-5:index3h_2-5],\n",
    "                           name= 'Kp',\n",
    "                           mode='lines',\n",
    "                           opacity=1,\n",
    "#                                marker=dict(color='black',size=2),\n",
    "                           line = dict(shape = 'hv',dash='dot', color = 'black', width=1.5),\n",
    "                           showlegend=False),\n",
    "                           secondary_y=False,row=2, col=1) \n",
    "\n",
    "fig.add_hline(y=0, line_width=1, line_dash=\"dash\", line_color=\"black\", row=1, col=1)\n",
    "\n",
    "#######################################################\n",
    "font_dict=dict(family='Arial',size=16,color='black')\n",
    "#######################################################\n",
    "\n",
    "# fig.update_yaxes(title_text=r\"$\\text{F}_{\\text{10.7}}\\text{ Solar Flux (sfu)}$\", \n",
    "# #                  color='black',\n",
    "#                  range=[64.5, 86],\n",
    "#                   row=1, col=1,)\n",
    "\n",
    "# fig.update_yaxes(title_text=r\"$\\text{K}_\\text{p}\\text{ Index}$\",\n",
    "#                   range=[-0.3, 8],\n",
    "#                  row=2, col=1,)\n",
    "\n",
    "   \n",
    "\n",
    "for i in [1,2]:\n",
    "    if i ==1:\n",
    "        xlabel=False\n",
    "    else:\n",
    "        xlabel=True\n",
    "    \n",
    "    fig.update_xaxes(### LINE at axis border\n",
    "                      showline=True,showticklabels=xlabel,\n",
    "                      linecolor='black',linewidth=1,\n",
    "                     ### Major ticks\n",
    "                      ticks='inside',tickfont=font_dict,mirror=True,\n",
    "                      tickwidth=2,ticklen=9,\n",
    "                      tickcolor='grey',tick0=\"2018-11-9\" ,\n",
    "                      dtick=86400000.0*1,    # milliseconds in a day, every 7 days\n",
    "#                       tickformat='%m/%d',\n",
    "                    ticklabelstep=2,\n",
    "                      #### Minor Ticks\n",
    "                       minor=dict(dtick=86400000.0, # milliseconds in a day\n",
    "                         tickwidth=1,ticklen=4,\n",
    "                         tickcolor='grey',ticks='inside'),\n",
    "                      ### GRID\n",
    "                       gridcolor='gainsboro',gridwidth=1,\n",
    "                       layer='above traces',tickangle=0,\n",
    "                       row=i, col=1)\n",
    "    fig.update_yaxes(showline=True,      # add line at x=0\n",
    "                     showticklabels=True,linecolor='black',  \n",
    "                     linewidth=1,ticks='inside',tickfont=font_dict, \n",
    "                     mirror='allticks',tickwidth=1,tickcolor='black',\n",
    "                     gridcolor='gainsboro',gridwidth=1,layer='above traces',\n",
    "                     row=i, col=1)\n",
    "\n",
    "fig.update_yaxes( title=\"Kp, daily average\",\n",
    "                 range=[-0.5,5],\n",
    "                 exponentformat= 'power',row=2, col=1)\n",
    "\n",
    "\n",
    "\n",
    "fig.add_trace(go.Bar(y=[\"JB2008\",\n",
    "                        \"DTM2020\",\n",
    "                        \"CTIPe\",\n",
    "                        \"TIEGCM\",\n",
    "                        \"MSIS2\",\n",
    "                        \"GITM\",\n",
    "                        ],    \n",
    "                     x=[run_dict[\"jb2008\"]['CorrCoeff'],\n",
    "                        run_dict[\"dtm2020_o\"]['CorrCoeff'],\n",
    "                        run_dict[\"ctipe_oc\"]['CorrCoeff'],\n",
    "                        run_dict[\"tiegcm_oc\"]['CorrCoeff'],\n",
    "                        run_dict[\"msis2\"]['CorrCoeff'],\n",
    "                        run_dict[\"gitm\"]['CorrCoeff'],\n",
    "                       ] ,\n",
    "                     text=[np.round(run_dict[\"jb2008\"]['CorrCoeff'],2)     ,\n",
    "                           np.round(run_dict[\"dtm2020_o\"]['CorrCoeff'],2)  ,\n",
    "                           np.round(run_dict[\"ctipe_oc\"]['CorrCoeff'],2)   ,\n",
    "                           np.round(run_dict[\"tiegcm_oc\"]['CorrCoeff'],2)  ,\n",
    "                           np.round(run_dict[\"msis2\"]['CorrCoeff'],2)      ,\n",
    "                           np.round(run_dict[\"gitm\"]['CorrCoeff'],2)       ,\n",
    "                       ] ,\n",
    "                    textposition='outside',\n",
    "                     textfont=dict(family='Arial',size=13,color='black'),\n",
    "                marker_color=all_cols,\n",
    "                showlegend=False),row=1, col=2)\n",
    "fig.update_traces(orientation=\"h\", selector=dict(type='bar'))\n",
    "\n",
    "fig.add_annotation(x=-0.5,y='GITM',\n",
    "        xref=\"x\",yref=\"y\",\n",
    "        showarrow=False,\n",
    "        text='GITM',\n",
    "        font=dict(size=20,color=\"black\"),\n",
    "        align=\"right\",\n",
    "        row=1, col=2,\n",
    "        )\n",
    "fig.add_annotation(x=-0.5,y='MSIS2',\n",
    "        xref=\"x\",yref=\"y\",\n",
    "        showarrow=False,\n",
    "        text='MSIS2',\n",
    "        font=dict(size=20,color=\"black\"),\n",
    "        align=\"right\",\n",
    "        row=1, col=2,\n",
    "        )\n",
    "fig.add_annotation(x=-0.5,y='TIEGCM',\n",
    "        xref=\"x\",yref=\"y\",\n",
    "        showarrow=False,\n",
    "        text='TIEGCM',\n",
    "        font=dict(size=20,color=\"black\"),\n",
    "        align=\"right\",\n",
    "        row=1, col=2,\n",
    "        )\n",
    "fig.add_annotation(x=-0.5,y='CTIPe',\n",
    "        xref=\"x\",yref=\"y\",\n",
    "        showarrow=False,\n",
    "        text='CTIPe',\n",
    "        font=dict(size=20,color=\"black\"),\n",
    "        align=\"right\",\n",
    "        row=1, col=2,\n",
    "        )\n",
    "fig.add_annotation(x=0.5,y='DTM2020',\n",
    "        xref=\"x\",yref=\"y\",\n",
    "        showarrow=False,\n",
    "        text='DTM2020',\n",
    "        font=dict(size=20,color=\"black\"),\n",
    "        align=\"left\",\n",
    "        row=1, col=2,\n",
    "        )\n",
    "fig.add_annotation(x=0.5,y='JB2008',\n",
    "        xref=\"x\",yref=\"y\",\n",
    "        showarrow=False,\n",
    "        text='JB2008',\n",
    "        font=dict(size=20,color=\"black\"),\n",
    "        align=\"left\",\n",
    "        row=1, col=2,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.update_xaxes(### LINE at axis border\n",
    "                  showline=True,showticklabels=True,\n",
    "                  linecolor='gainsboro',linewidth=1,\n",
    "                 ### Major ticks\n",
    "                  ticks='inside',tickfont=dict(family='Arial',size=14,color='black'),mirror=True,\n",
    "                  tickwidth=2,ticklen=9,\n",
    "                  tickcolor='white',\n",
    "                  ### GRID\n",
    "                   gridcolor='white',gridwidth=1,\n",
    "                   layer='above traces',\n",
    "                    row=1, col=2)\n",
    "fig.update_yaxes(showline=True,      # add line at x=0\n",
    "                 showticklabels=False,linecolor='gainsboro',  \n",
    "                 linewidth=1,ticks='inside',tickfont=dict(family='Arial',size=14,color='black'), \n",
    "                 mirror='allticks',tickwidth=1,tickcolor='gainsboro',\n",
    "                 gridcolor='gainsboro',gridwidth=1,layer='above traces',\n",
    "                                    row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title=\"R, Pearson Corr. Coeff.\",\n",
    "                 range=[-1,1.05],\n",
    "                 titlefont=dict(family='Arial',size=14,color='black'),\n",
    "                 row=1, col=2)\n",
    "\n",
    "fig.update_layout(autosize=False,    width=1000,    height=600,\n",
    "                  legend= {'itemsizing': 'trace'},\n",
    "                  font=font_dict, plot_bgcolor='white', \n",
    "                 )\n",
    "annot = fig['layout']['annotations'][0]\n",
    "annot['yanchor']='bottom'\n",
    "annot['y']=1.015\n",
    "annot['yref']='paper'\n",
    "\n",
    "fig.update_xaxes(range=[pd.to_datetime( \"181109-000000\", format='%y%m%d-%H%M%S'),\n",
    "                        pd.to_datetime( \"181123-000000\", format='%y%m%d-%H%M%S')],\n",
    "                 row=1, col=1)\n",
    "\n",
    "\n",
    "fig.update_annotations(font_size=18)  # Increase size of subplot title\n",
    "fig.show(config=config)\n",
    "\n",
    "### pio.write_image(fig, plots_dir+'twoweek_fullresult.pdf')\n",
    "# pio.write_image(fig, plots_dir+'f107_kp_twoweek.jpg', scale=3)\n",
    "\n",
    "pio.write_image(fig, plot_dir+'24hourScalingFactors_w_R.jpg', scale=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a321e345",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T19:27:51.837103Z",
     "start_time": "2023-05-10T19:27:51.779658Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bdb8b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:42:34.278377Z",
     "start_time": "2023-05-10T17:42:34.222679Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2442d584",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:20.031Z"
    }
   },
   "outputs": [],
   "source": [
    "# Simplify Plotting Schemes:\n",
    "col_msis2     =  \"#2ca02c\"  # 'tab:green'\n",
    "col_jb2008    =  \"#ff7f0e\"  # 'tab:orange'\n",
    "col_dtm2020   =  \"#d62728\"  # 'tab:red'\n",
    "col_tiegcm_oc =  \"#17becf\"  # 'tab:cyan'\n",
    "col_hasdm_oc  =  \"#1f77b4\"  # 'tab:blue'\n",
    "col_ctipe_oc  =  \"#9467bd\"  # 'tab:purple'\n",
    "col_gitm      =  '#e377c2'  # 'tab:pink'\n",
    "\n",
    "all_cols = [col_jb2008,\n",
    "            col_dtm2020,\n",
    "            col_ctipe_oc,\n",
    "            col_tiegcm_oc,\n",
    "            col_msis2,\n",
    "            col_gitm,\n",
    "           ]\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "# for model in run_dict.keys():\n",
    "\n",
    "fig.add_trace(go.Bar(y=[\"JB2008\",\n",
    "                        \"DTM2020\",\n",
    "                        \"CTIPe\",\n",
    "                        \"TIEGCM\",\n",
    "                        \"MSIS2\",\n",
    "                        \"GITM\",\n",
    "                        ],    \n",
    "                     x=[run_dict[\"jb2008\"]['CorrCoeff'],\n",
    "                        run_dict[\"dtm2020_o\"]['CorrCoeff'],\n",
    "                        run_dict[\"ctipe_oc\"]['CorrCoeff'],\n",
    "                        run_dict[\"tiegcm_oc\"]['CorrCoeff'],\n",
    "                        run_dict[\"msis2\"]['CorrCoeff'],\n",
    "                        run_dict[\"gitm\"]['CorrCoeff'],\n",
    "                       ] ,\n",
    "                     text=[np.round(run_dict[\"jb2008\"]['CorrCoeff'],2)     ,\n",
    "                           np.round(run_dict[\"dtm2020_o\"]['CorrCoeff'],2)  ,\n",
    "                           np.round(run_dict[\"ctipe_oc\"]['CorrCoeff'],2)   ,\n",
    "                           np.round(run_dict[\"tiegcm_oc\"]['CorrCoeff'],2)  ,\n",
    "                           np.round(run_dict[\"msis2\"]['CorrCoeff'],2)      ,\n",
    "                           np.round(run_dict[\"gitm\"]['CorrCoeff'],2)       ,\n",
    "                       ] ,\n",
    "            textposition='outside',\n",
    "                marker_color=all_cols,\n",
    "                ))\n",
    "fig.update_traces(orientation=\"h\", selector=dict(type='bar'))\n",
    "\n",
    "fig.update_xaxes(### LINE at axis border\n",
    "                  showline=True,showticklabels=True,\n",
    "                  linecolor='black',linewidth=1,\n",
    "                 ### Major ticks\n",
    "                  ticks='inside',tickfont=font_dict,mirror=True,\n",
    "                  tickwidth=2,ticklen=9,\n",
    "                  tickcolor='grey',\n",
    "                  ### GRID\n",
    "                   gridcolor='gainsboro',gridwidth=1,\n",
    "                   layer='above traces')\n",
    "fig.update_yaxes(showline=True,      # add line at x=0\n",
    "                 showticklabels=True,linecolor='black',  \n",
    "                 linewidth=1,ticks='inside',tickfont=font_dict, \n",
    "                 mirror='allticks',tickwidth=1,tickcolor='black',\n",
    "                 gridcolor='gainsboro',gridwidth=1,layer='above traces',)\n",
    "\n",
    "fig.update_layout(autosize=True,   \n",
    "                  legend= {'itemsizing': 'trace'},\n",
    "                  font=font_dict, plot_bgcolor='white', \n",
    "                 )\n",
    "\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c84b995",
   "metadata": {},
   "source": [
    "## scaling and Kp correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054418b5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:20.033Z"
    }
   },
   "outputs": [],
   "source": [
    "index3h_1 = 168+4\n",
    "index3h_2 = 289-4\n",
    "\n",
    "# solar_fluxes['kp_expand'][index3h_1:index3h_2]\n",
    "\n",
    "print('Length of Kp list:', len(solar_fluxes['date_3hr'][index3h_1:index3h_2-1]))\n",
    "\n",
    "solar_fluxes['date_3hr'][index3h_1:index3h_2-1]\n",
    "\n",
    "\n",
    "for model in run_dict.keys():\n",
    "    sf_kplen = []\n",
    "    for sf in run_dict[model]['ScalingFactors']:\n",
    "        sf_kplen.extend( np.squeeze(np.ones(8)*sf  ))\n",
    "\n",
    "    print(model,'----------------')\n",
    "    corr = np.corrcoef(sf_kplen, solar_fluxes['kp_expand'][index3h_1:index3h_2-1] ) \n",
    "    print(f\"   R={corr[0,1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a1c023",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:20.036Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b085a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:20.039Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy import signal\n",
    "# import matplotlib.pyplot as plt\n",
    "# # rng = np.random.default_rng()\n",
    "\n",
    "\n",
    "\n",
    "# sig1 = sf_kplen            #np.repeat([0., 1., 1., 0., 1., 0., 0., 1.], 128)\n",
    "# sig2 = solar_fluxes['kp_expand'][index3h_1:index3h_2-1] \n",
    "# # sig_noise = sig + rng.standard_normal(len(sig))\n",
    "# corr = signal.correlate(sig1, sig2, mode='same') \n",
    "\n",
    "\n",
    "# fig, (ax_orig, ax_noise, ax_corr) = plt.subplots(3, 1, sharex=True)\n",
    "# ax_orig.plot(sig1)\n",
    "# ax_orig.set_title('Scaling Factors for '+model)\n",
    "# ax_noise.plot(sig2)\n",
    "# ax_noise.set_title('Kp Signal')\n",
    "# ax_corr.plot(corr)\n",
    "# ax_corr.set_title('Cross-correlation')\n",
    "# # ax_orig.margins(0, 0.1)\n",
    "# fig.tight_layout()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa1c4ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T23:15:02.671672Z",
     "start_time": "2023-03-22T23:13:54.194233Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fb4eab",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:20.043Z"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt # matplot lib is the premiere plotting lib for Python: https://matplotlib.org/\n",
    "# import numpy as np # numpy is the premiere signal handling library for Python: http://www.numpy.org/\n",
    "# import scipy as sp # for signal processing\n",
    "# from scipy import signal\n",
    "# from scipy.spatial import distance\n",
    "# # import IPython.display as ipd\n",
    "# # import librosa\n",
    "# # import random\n",
    "# # import math\n",
    "# # import makelab\n",
    "# # # from makelab import audio\n",
    "# # from makelab import signal\n",
    "\n",
    "# def pad_zeros_right(s, padding_length):\n",
    "#     # https://numpy.org/doc/1.18/reference/generated/numpy.pad.html\n",
    "#     return np.pad(s, (0, padding_length), mode = 'constant', constant_values=0)\n",
    "\n",
    "# def pad_mean_right(s, padding_length):\n",
    "#     # https://numpy.org/doc/1.18/reference/generated/numpy.pad.html\n",
    "#     return np.pad(s, (0, padding_length), mode = 'mean')\n",
    "\n",
    "# # def compare_and_plot_signals(a, b, distance_function = distance.euclidean, alignment_function = None):\n",
    "# def plot_signals_with_alignment(a, b, pad_function = None):\n",
    "#     if(len(a) != len(b) and pad_function is None):\n",
    "#         raise Exception(f\"Signal 'a' and 'b' must be the same size; len(a)={len(a)} and len(b)={len(b)} or pad_function must not be None\")\n",
    "#     elif(len(a) != len(b) and pad_function is not None):\n",
    "#         if(len(a) < len(b)):\n",
    "#             a = pad_function(a, len(b) - len(a))\n",
    "#         else:\n",
    "#             b = pad_function(b, len(a) - len(b))\n",
    "    \n",
    "#     correlate_result = np.correlate(a, b, 'full')\n",
    "#     shift_positions = np.arange(-len(a) + 1, len(b))\n",
    "    \n",
    "#     print(\"len(a)\", len(a), \"len(b)\", len(b), \"len(correlate_result)\", len(correlate_result))\n",
    "\n",
    "#     fig, axes = plt.subplots(5, 1, figsize=(10, 18))\n",
    "    \n",
    "#     axes[0].plot(a, alpha=0.7, label=\"a\", marker=\"o\")\n",
    "#     axes[0].plot(b, alpha=0.7, label=\"b\", marker=\"D\")\n",
    "#     axes[0].legend()\n",
    "#     axes[0].set_title(\"Raw Signals 'a' and 'b'\")\n",
    "    \n",
    "#     if len(shift_positions) < 20:\n",
    "#         # useful for debugging and showing correlation results\n",
    "#         print(shift_positions)\n",
    "#         print(correlate_result)\n",
    "\n",
    "#     best_correlation_index = np.argmax(correlate_result)\n",
    "#     shift_amount_debug = shift_positions[best_correlation_index]\n",
    "#     shift_amount = (-len(a) + 1) + best_correlation_index\n",
    "#     print(\"best_correlation_index\", best_correlation_index, \"shift_amount_debug\", shift_amount_debug, \"shift_amount\", shift_amount)\n",
    "    \n",
    "#     axes[1].stem(shift_positions, correlate_result, use_line_collection=True, label=\"Cross-correlation of a and b\")\n",
    "#     axes[1].set_title(f\"Cross-Correlation Result | Best Match Index: {best_correlation_index} Signal 'b' Shift Amount: {shift_amount}\")\n",
    "#     axes[1].set_ylabel(\"Cross Correlation\")\n",
    "#     axes[1].set_xlabel(\"'b' Signal Shift Amount\")\n",
    "    \n",
    "# #     best_match_ymin = 0\n",
    "# #     best_match_ymin_normalized = makelab.signal.map(best_match_ymin, axes[1].get_ylim()[0], axes[1].get_ylim()[1], 0, 1)\n",
    "# #     best_match_ymax = correlate_result[best_correlation_index]\n",
    "# #     best_match_ymax_normalized = makelab.signal.map(best_match_ymax, axes[1].get_ylim()[0], axes[1].get_ylim()[1], 0, 1)\n",
    "# #     axes[1].axvline(shift_positions[best_correlation_index], ymin=best_match_ymin_normalized, ymax=best_match_ymax_normalized, \n",
    "# #                     linewidth=2, color='orange', alpha=0.8, linestyle='-.', \n",
    "# #                     label=f\"Best match ({shift_amount}, {best_match_ymax:.2f})\")\n",
    "# #     axes[1].legend()\n",
    "    \n",
    "# #     b_shifted_mean_fill = makelab.signal.shift_array(b, shift_amount, np.mean(b))\n",
    "# #     axes[2].plot(a, alpha=0.7, label=\"a\", marker=\"o\")\n",
    "# #     axes[2].plot(b_shifted_mean_fill, alpha=0.7, label=\"b_shifted_mean_fill\", marker=\"D\")\n",
    "# #     axes[2].legend()\n",
    "# #     axes[2].set_title(\"Signals 'a' and 'b_shifted_mean_fill'\")\n",
    "    \n",
    "# #     b_shifted_zero_fill = makelab.signal.shift_array(b, shift_amount, 0)\n",
    "# #     axes[3].plot(a, alpha=0.7, label=\"a\", marker=\"o\")\n",
    "# #     axes[3].plot(b_shifted_zero_fill, alpha=0.7, label=\"b_shifted_zero_fill\", marker=\"D\")\n",
    "# #     axes[3].legend()\n",
    "# #     axes[3].set_title(\"Signals 'a' and 'b_shifted_zero_fill'\")\n",
    "    \n",
    "#     b_shifted_roll = np.roll(b, shift_amount)\n",
    "#     axes[4].plot(a, alpha=0.7, label=\"a\", marker=\"o\")\n",
    "#     axes[4].plot(b_shifted_roll, alpha=0.7, label=\"b_shifted_roll\", marker=\"D\")\n",
    "#     axes[4].legend()\n",
    "#     axes[4].set_title(\"Signals 'a' and 'b_shifted_roll'\")\n",
    "    \n",
    "#     fig.tight_layout()\n",
    "    \n",
    "# def compare_and_plot_signals_with_alignment(a, b, bshift_method = 'mean_fill', pad_function = None):\n",
    "#     '''Aligns signals using cross correlation and then plots\n",
    "    \n",
    "#        bshift_method can be: 'mean_fill', 'zero_fill', 'roll', or 'all'. Defaults to 'mean_fill'\n",
    "#     '''\n",
    "    \n",
    "#     if(len(a) != len(b) and pad_function is None):\n",
    "#         raise Exception(f\"Signal 'a' and 'b' must be the same size; len(a)={len(a)} and len(b)={len(b)} or pad_function must not be None\")\n",
    "#     elif(len(a) != len(b) and pad_function is not None):\n",
    "#         if(len(a) < len(b)):\n",
    "#             a = pad_function(a, len(b) - len(a))\n",
    "#         else:\n",
    "#             b = pad_function(b, len(a) - len(b))\n",
    "    \n",
    "#     correlate_result = np.correlate(a, b, 'full')\n",
    "#     shift_positions = np.arange(-len(a) + 1, len(b))\n",
    "#     print(\"len(a)\", len(a), \"len(b)\", len(b), \"len(correlate_result)\", len(correlate_result))\n",
    "    \n",
    "#     euclid_distance_a_to_b = distance.euclidean(a, b)\n",
    "    \n",
    "#     num_charts = 3\n",
    "#     chart_height = 3.6\n",
    "#     if bshift_method is 'all':\n",
    "#         num_charts = 5\n",
    "    \n",
    "#     fig, axes = plt.subplots(num_charts, 1, figsize=(10, num_charts * chart_height))\n",
    "    \n",
    "#     # Turn on markers only if < 50 points\n",
    "#     a_marker = None\n",
    "#     b_marker = None\n",
    "#     if len(a) < 50:\n",
    "#         a_marker = \"o\"\n",
    "#         b_marker = \"D\"\n",
    "        \n",
    "#     axes[0].plot(a, alpha=0.7, label=\"a\", marker=a_marker)\n",
    "#     axes[0].plot(b, alpha=0.7, label=\"b\", marker=b_marker)\n",
    "#     axes[0].legend()\n",
    "#     axes[0].set_title(f\"Raw Signals | Euclidean Distance From 'a' to 'b' = {euclid_distance_a_to_b:.2f}\")\n",
    "    \n",
    "#     if len(shift_positions) < 20:\n",
    "#         # useful for debugging and showing correlation results\n",
    "#         print(shift_positions)\n",
    "#         print(correlate_result)\n",
    "    \n",
    "#     best_correlation_index = np.argmax(correlate_result)\n",
    "#     shift_amount_debug = shift_positions[best_correlation_index]\n",
    "#     shift_amount = (-len(a) + 1) + best_correlation_index\n",
    "#     print(\"best_correlation_index\", best_correlation_index, \"shift_amount_debug\", shift_amount_debug, \"shift_amount\", shift_amount)\n",
    "    \n",
    "#     #axes[1].plot(shift_positions, correlate_result)\n",
    "#     axes[1].stem(shift_positions, correlate_result, use_line_collection=True, label=\"Cross-correlation of a and b\")\n",
    "#     axes[1].set_title(f\"Cross-correlation result | Best match index: {best_correlation_index}; Signal 'b' shift amount: {shift_amount}\")\n",
    "#     axes[1].set_ylabel(\"Cross Correlation\")\n",
    "#     axes[1].set_xlabel(\"'b' Signal Shift Amount\")\n",
    "    \n",
    "#     best_match_ymin = 0\n",
    "# #     best_match_ymin_normalized = makelab.signal.map(best_match_ymin, axes[1].get_ylim()[0], axes[1].get_ylim()[1], 0, 1)\n",
    "# #     best_match_ymax = correlate_result[best_correlation_index]\n",
    "# #     best_match_ymax_normalized = makelab.signal.map(best_match_ymax, axes[1].get_ylim()[0], axes[1].get_ylim()[1], 0, 1)\n",
    "# #     axes[1].axvline(shift_positions[best_correlation_index], ymin=best_match_ymin_normalized, ymax=best_match_ymax_normalized, \n",
    "# #                     linewidth=2, color='orange', alpha=0.8, linestyle='-.', \n",
    "# #                     label=f\"Best match ({shift_amount}, {best_match_ymax:.2f})\")\n",
    "# #     axes[1].legend()\n",
    "    \n",
    "# #     if bshift_method is 'mean_fill' or bshift_method is 'all':\n",
    "# #         b_shifted_mean_fill = makelab.signal.shift_array(b, shift_amount, np.mean(b))\n",
    "# #         euclid_distance_a_to_b_shifted_mean_fill = distance.euclidean(a, b_shifted_mean_fill)\n",
    "# #         axes[2].plot(a, alpha=0.7, label=\"a\", marker=a_marker)\n",
    "# #         axes[2].plot(b_shifted_mean_fill, alpha=0.7, label=\"b_shifted_mean_fill\", marker=b_marker)\n",
    "# #         axes[2].legend()\n",
    "# #         axes[2].set_title(f\"Euclidean distance From 'a' to 'b_shifted_mean_fill' = {euclid_distance_a_to_b_shifted_mean_fill:.2f}\")\n",
    "    \n",
    "# #     ax_idx = 0\n",
    "# #     if bshift_method is 'zero_fill' or bshift_method is 'all':\n",
    "# #         if bshift_method is 'zero_fill':\n",
    "# #             ax_idx = 2\n",
    "# #         else:\n",
    "# #             ax_idx = 3\n",
    "    \n",
    "# #         b_shifted_zero_fill = makelab.signal.shift_array(b, shift_amount, 0)\n",
    "# #         euclid_distance_a_to_b_shifted_zero_fill = distance.euclidean(a, b_shifted_zero_fill)\n",
    "# #         axes[ax_idx].plot(a, alpha=0.7, label=\"a\", marker=a_marker)\n",
    "# #         axes[ax_idx].plot(b_shifted_zero_fill, alpha=0.7, label=\"b_shifted_zero_fill\", marker=b_marker)\n",
    "# #         axes[ax_idx].legend()\n",
    "# #         axes[ax_idx].set_title(f\"Euclidean distance From 'a' to 'b_shifted_zero_fill' = {euclid_distance_a_to_b_shifted_zero_fill:.2f}\")\n",
    "    \n",
    "    \n",
    "#     if bshift_method is 'roll' or bshift_method is 'all':\n",
    "#         if bshift_method is 'roll':\n",
    "#             ax_idx = 2\n",
    "#         else:\n",
    "#             ax_idx = 4\n",
    "#         b_shifted_roll = np.roll(b, shift_amount)\n",
    "#         euclid_distance_a_to_b_shifted_roll = distance.euclidean(a, b_shifted_roll)\n",
    "#         axes[ax_idx].plot(a, alpha=0.7, label=\"a\", marker=a_marker)\n",
    "#         axes[ax_idx].plot(b_shifted_roll, alpha=0.7, label=\"b_shifted_roll\", marker=b_marker)\n",
    "#         axes[ax_idx].legend()\n",
    "#         axes[ax_idx].set_title(f\"Euclidean distance From 'a' to 'b_shifted_roll' = {euclid_distance_a_to_b_shifted_roll:.2f}\")\n",
    "    \n",
    "#     fig.tight_layout()\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "# compare_and_plot_signals_with_alignment(sig1, sig2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc425c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T18:30:52.194818Z",
     "start_time": "2023-03-23T18:30:51.341794Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2989a5d",
   "metadata": {},
   "source": [
    "## plot scaled results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a8f515",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-07T17:41:20.047Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "def plot_all_nokp(fig, obj_m1, model_dict ):\n",
    "\n",
    "    cd_apriori  = 2.5\n",
    "\n",
    "    ####  Get plot Parameters for this model\n",
    "    model_m1 = obj_m1['global_params']['prms']['den_model']\n",
    "    col = get_plot_params( model_m1)\n",
    "    dateplot = []\n",
    "    rms_totals = []\n",
    "\n",
    "    \n",
    "    for ii,arc in enumerate(obj_m1['global_params']['arc_input']):\n",
    "        arc =arc+'.01'\n",
    "        dateplot.append(pd.to_datetime(datetime.datetime(int(arc.split('.')[0]), 1, 1) \\\n",
    "                                     + datetime.timedelta(int(arc.split('.')[1]))      \\\n",
    "                                     - datetime.timedelta(hours=12) ))\n",
    "        rms_totals.append(obj_m1['Statistics'][arc]['T_RMS'].values[0])\n",
    "\n",
    "        ### -----------------------------------------------------------------------------------------------------\n",
    "        ###     DENSITY\n",
    "        ###\n",
    "        time_avg,d_avg, d_avg_rolling = orb_avg(obj_m1['Density'], arc)\n",
    "\n",
    "#         print('scaling factor',model_dict['ScalingFactors'][ii])\n",
    "        \n",
    "\n",
    "        \n",
    "        ### -----------------------------------------------------------------------------------------------------\n",
    "        ###     Orbit Averaged Density\n",
    "#         fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                    y=d_avg*(model_dict['ScalingFactors'][ii]),\n",
    "#                                    ### name= model_m1,\n",
    "#                                    mode='markers+lines',\n",
    "#                                    opacity=1,\n",
    "#                                        marker=dict(color=col,size=2),\n",
    "#                                    ###     line = dict( color = col, width=2),\n",
    "# #                                                    line = dict(shape='hvh', dash ='solid', color = col, width=2),\n",
    "#                                        line = dict(dash ='solid', color = col, width=2),\n",
    "#                                    showlegend=False), row=1, col=1)\n",
    "#         fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                y=d_avg,\n",
    "#                                ### name= model_m1,\n",
    "#                                mode='markers+lines',\n",
    "#                                opacity=1,\n",
    "#                                    marker=dict(color=col,size=2),\n",
    "# #                                                line = dict( color = col, width=2),\n",
    "# #                                    line = dict(shape='hvh', dash ='dot', color = col, width=2),\n",
    "#                                showlegend=False), row=1, col=1)            \n",
    "\n",
    "\n",
    "        ### -----------------------------------------------------------------------------------------------------\n",
    "        ###     In Track Residuals\n",
    "        data_resids = obj_m1['OrbitResids'][arc]['resids']\n",
    "        fig.add_trace(go.Scattergl(x=data_resids['Date'][::50],\n",
    "                                   y=data_resids['T'][::50],\n",
    "                                   ###   name= model_m1,\n",
    "                                     mode='markers+lines',\n",
    "                                     opacity=1,\n",
    "                                         marker=dict(color=col,size=2),\n",
    "                                         line = dict( color = col, width=2),\n",
    "                                     showlegend=False),\n",
    "                                     secondary_y=False, row=1, col=1)\n",
    "        ### -----------------------------------------------------------------------------------------------------\n",
    "        ###     TOTAL RMS\n",
    "#             print(rms_totals)\n",
    "        if ii == 14:\n",
    "#                     print(model_m1, \"mean rms_totals:         \",np.round(np.mean(rms_totals),3) )\n",
    "#                     print('       density scaling factor: ', np.round((cd_adjusted/cd_apriori),3))\n",
    "            print(model_m1 )\n",
    "            print(\"   mean rms_totals:       \",np.round(np.mean(rms_totals),3) )\n",
    "            print('   density scaling factor:', np.round((cd_adjusted/cd_apriori),3))\n",
    "        fig.add_trace(go.Scattergl(x=dateplot,\n",
    "                                   y=rms_totals,\n",
    "                                       ###e= 'NTW '+model_m1,\n",
    "                                   mode='markers+lines',\n",
    "                                         opacity=1,\n",
    "                                         marker=dict(color=col,size=6),\n",
    "                                         line = dict(shape='hvh', dash ='solid', color = col, width=2),\n",
    "                                   showlegend=False),row=2, col=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# full_fig = fig.full_figure_for_development()\n",
    "\n",
    "    if model_m1 == 'jb2008':\n",
    "        ###\n",
    "#         ### DENSITY AXIS\n",
    "#         fig.update_yaxes(title_text=r\"$\\text{Orbit Avg. Density } (\\frac{kg}{m^3})$\", \n",
    "#                          type=\"log\", \n",
    "# #                          range=yaxis2_range, \n",
    "#                          exponentformat= 'power',row=1, col=1)\n",
    "        ###\n",
    "        ### InTrack Residual Axis\n",
    "        fig.update_yaxes( title=r\"$\\text{In-Track Residuals (m)}$\",\n",
    "#                          range=yaxis3_range, \n",
    "                         exponentformat= 'power',row=1, col=1)\n",
    "        ###\n",
    "        ### RMS AXIS\n",
    "        fig.update_yaxes( title=r\"$\\text{In-Track RMSe (m)}$\" ,type=\"linear\" , exponentformat= 'power',\n",
    "#                           range=yaxis4_range, \n",
    "                         row=2, col=1)\n",
    "        ###\n",
    "        ###  DATE on Final x-Axis only\n",
    "        fig.update_xaxes(range=[pd.to_datetime( \"181108-160000\", format='%y%m%d-%H%M%S'),\n",
    "                                pd.to_datetime( \"181123-120000\", format='%y%m%d-%H%M%S')],\n",
    "                         row=2, col=1)\n",
    "\n",
    "\n",
    "    return(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### -----------------------------------------------------------------------------------------------------\n",
    "### -----------------------------------------------------------------------------------------------------\n",
    "### -----------------------------------------------------------------------------------------------------\n",
    "### -----------------------------------------------------------------------------------------------------\n",
    "### -----------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1,\n",
    "                    #                     \n",
    "                    vertical_spacing = 0.03,\n",
    "                    shared_xaxes=True)\n",
    "\n",
    "\n",
    "satid = int(obj[den]['global_params']['prms']['sat_ID'])\n",
    "for plot_num, model in enumerate(run_list):\n",
    "    ScalingFactors  = []\n",
    "    ScalingFactor_times = []\n",
    "    for iarc,valarc in enumerate(obj[model]['global_params']['arc_input']):\n",
    "        arc = valarc+'.01'\n",
    "        iters = int(obj[model]['run_parameters'+arc]['total_iterations'])\n",
    "        for itime in obj[model]['AdjustedParams'][arc][iters][satid]['0CD'].keys():\n",
    "            CURRENT_VALUE = obj[model]['AdjustedParams'][arc][iters][satid]['0CD'][itime]['CURRENT_VALUE']\n",
    "            APRIORI_VALUE = obj[model]['AdjustedParams'][arc][iters][satid]['0CD'][itime]['APRIORI_VALUE']\n",
    "            ScalingFactors.append(CURRENT_VALUE/APRIORI_VALUE)\n",
    "            ScalingFactor_times.append(itime)\n",
    "    run_dict[model]['ScalingFactor_times'] = ScalingFactor_times\n",
    "    run_dict[model]['ScalingFactors']      = ScalingFactors\n",
    "\n",
    "\n",
    "for model in run_dict.keys():\n",
    "    fig = plot_all_nokp(fig, obj[model],  run_dict[model] )\n",
    "\n",
    "\n",
    "#######################################################\n",
    "font_dict=dict(family='Arial',size=16,color='black')\n",
    "#######################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in [1,2]:\n",
    "    if i==1:\n",
    "        label_bool=False\n",
    "    else:\n",
    "        label_bool=True\n",
    "\n",
    "    fig.update_xaxes(### LINE at axis border\n",
    "                      showline=True,\n",
    "                      showticklabels=label_bool,\n",
    "                      linecolor='black',\n",
    "                      linewidth=1,\n",
    "                     ### Major ticks\n",
    "                      ticks='inside',\n",
    "                      tickfont=font_dict,\n",
    "                      mirror=True,\n",
    "                      tickwidth=2,\n",
    "                      ticklen=9,\n",
    "                      tickcolor='grey',\n",
    "                      tick0=\"2018-11-9\" ,\n",
    "                      dtick=86400000.0*1,    # milliseconds in a day, every 7 days\n",
    "#                       tickformat='%m/%d',\n",
    "                    ticklabelstep=2,\n",
    "                      #### Minor Ticks\n",
    "                       minor=dict(\n",
    "                         dtick=86400000.0, # milliseconds in a day\n",
    "                         tickwidth=1,\n",
    "                         ticklen=4,\n",
    "                         tickcolor='grey',\n",
    "                         ticks='inside'),\n",
    "                      ### GRID\n",
    "                       gridcolor='gainsboro',\n",
    "                       gridwidth=1,\n",
    "                       layer='above traces',\n",
    "                       tickangle=0,\n",
    "                       row=i, col=1)\n",
    "    fig.update_yaxes(showline=True,      # add line at x=0\n",
    "                         showticklabels=True,\n",
    "                         linecolor='black',  # line color\n",
    "                         linewidth=1,        # line size\n",
    "                     ticks='inside',     # ticks outside axis\n",
    "                     tickfont=font_dict, # tick label font\n",
    "                     mirror='allticks',  # add ticks to top/right axes\n",
    "                     tickwidth=1,      # tick width\n",
    "                     tickcolor='black',  # tick color\n",
    "                     gridcolor='gainsboro',\n",
    "                     gridwidth=1,\n",
    "                     layer='above traces',\n",
    "                     row=i, col=1)\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "#                   title = '',\n",
    "                  autosize=False,    width=1000,    height=725,\n",
    "                  legend= {'itemsizing': 'trace'},\n",
    "                  font=font_dict,\n",
    "                  plot_bgcolor='white', \n",
    "                 )\n",
    "# fig.update_annotations(font_size=14)  # Increase size of subplot title\n",
    "\n",
    "fig.show(#renderer=\"jpg\",\n",
    "         config=dict({\n",
    "            'displayModeBar': False,\n",
    "            'responsive': False,\n",
    "            'staticPlot': True,\n",
    "            'displaylogo': False,\n",
    "            'showTips': False,\n",
    "            }))\n",
    "\n",
    "#     if save_plot_flag:\n",
    "#         pio.write_image(fig, plot_dir+'Assessment_CDAvgAdj.jpg', scale=3)\n",
    "\n",
    "pio.write_image(fig, plot_dir+'Fig_Assessment_24h_scaled.jpg', scale=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d448b97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "109px",
    "width": "204.25px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "228.288px",
    "left": "1514.94px",
    "top": "152.125px",
    "width": "158.6px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
