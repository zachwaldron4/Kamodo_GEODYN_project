{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0821746f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:51:05.015412Z",
     "start_time": "2023-02-03T16:51:05.012504Z"
    }
   },
   "outputs": [],
   "source": [
    "#---+----1----+----2----+----3----+----4----+----5----+----6----+----7----+----8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf75f60",
   "metadata": {},
   "source": [
    "**Loop through the arcs in the month of november**\n",
    "  1. Stage 1\n",
    "     - for each day of interest, find the earliest epoch time in that day that matches the raw data\n",
    "        - set each epoch_start value to be that time for each day, respectively\n",
    "     - run GEODYN with the earliest time of day until the end of the day at midnight.\n",
    "     - Do for 1 week\n",
    "     - Collect the trajectory outputs into a file, saving just state vector of the starttime and endtime\n",
    "    \n",
    "  \n",
    "  2. Stage 2  \n",
    "     - Set the epoch start time to midnight\n",
    "     - Use the final state vector values from the previous day (should be within 1 minute of midnight) as the new initial condition\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef0bc85b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:51:06.118551Z",
     "start_time": "2023-02-03T16:51:05.017350Z"
    }
   },
   "outputs": [],
   "source": [
    "from  datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy  as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a2d2e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:51:06.123831Z",
     "start_time": "2023-02-03T16:51:06.120596Z"
    }
   },
   "outputs": [],
   "source": [
    "# days = np.arange(2,29+1)\n",
    "days = np.arange(2,5+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcec403",
   "metadata": {},
   "source": [
    "## Stage 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dac1d09",
   "metadata": {},
   "source": [
    "### find earliest daily start time to match data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cb2c21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-02T22:23:50.688683Z",
     "start_time": "2023-02-02T22:23:50.670314Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86359678",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:51:20.696657Z",
     "start_time": "2023-02-03T16:51:06.125521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-02 earliest time is: 2018-11-02 00:00:00\n",
      "2018-11-03 earliest time is: 2018-11-03 01:02:55\n",
      "2018-11-04 earliest time is: 2018-11-04 00:52:55\n",
      "2018-11-05 earliest time is: 2018-11-05 00:45:16\n"
     ]
    }
   ],
   "source": [
    "start_0ut = []\n",
    "end___0ut = []\n",
    "arcs      = []\n",
    "start_update = []\n",
    "#\n",
    "dt_1days = pd.Series(pd.to_timedelta(24,'h'))\n",
    "#\n",
    "for iday,dayval in enumerate(days):\n",
    "    \n",
    "    prms_arc={}\n",
    "    prms_arc['epoch_start'] = f\"2018-11-{dayval:02d} 00:00:00\"\n",
    "    prms_arc['epoch_startDT'] = pd.to_datetime(prms_arc['epoch_start'],\\\n",
    "                                                format='%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    start_0ut.append(f\"2018-11-{dayval:02d} 00:00:00\")\n",
    "    end___0ut.append(pd.to_datetime(prms_arc['epoch_startDT']+dt_1days).dt.strftime('%Y-%m-%d %H:%M:%S').values[0])\n",
    "    arcs.append(prms_arc['epoch_startDT'].strftime('%Y.%j'))\n",
    "    \n",
    "    epoch_startDT = prms_arc['epoch_startDT']\n",
    "    file_statevector_ICs = \"/data/SatDragModelValidation/data/inputs/\"\\\n",
    "                            +\"sat_spire83/setups/Spire83_initialconditions_Nov2018_v1.txt\"\n",
    "\n",
    "    datetype = 'datetime_string'\n",
    "    date_in_file_flag= False\n",
    "    import linecache\n",
    "\n",
    "    ### Only need to use accuracy to within 1 second (ignore the microseconds in the file)\n",
    "\n",
    "    if datetype == 'datetime_string':\n",
    "        date_str = str(epoch_startDT)\n",
    "    elif datetype == 'YYMMDDHHMMSS':\n",
    "        date_str = datetime.strftime(epoch_startDT, '%y%m%d%H%M%S')\n",
    "\n",
    "\n",
    "    with open(file_statevector_ICs, 'r') as f:\n",
    "        for line_no, line_text in enumerate(f):\n",
    "            if date_str in line_text:\n",
    "                date_in_file_flag= True\n",
    "#                 print('    ','xyzline',line_no,line_text)\n",
    "                break\n",
    "    if date_in_file_flag == False:\n",
    "#         print(date_str,'not found in file.')\n",
    "\n",
    "        ### Find the dates that have the same hour    \n",
    "        if datetype == 'datetime_string':\n",
    "            date_roundhour_str = str(epoch_startDT)[:10]\n",
    "        elif datetype == 'YYMMDDHHMMSS':\n",
    "            date_roundhour_str = datetime.strftime(epoch_startDT, '%y%m%d%H')\n",
    "\n",
    "#         print(date_roundhour_str)\n",
    "        ### Scan through IC file and append a list of dates within the same hour\n",
    "        line_no_list = []\n",
    "        line_list = []\n",
    "        with open(file_statevector_ICs, 'r') as f:\n",
    "            for line_no, line_text in enumerate(f):\n",
    "                if date_roundhour_str in line_text:\n",
    "                    line_no_list.append(line_no)\n",
    "\n",
    "\n",
    "        # print(line_no_list)\n",
    "        for i in np.arange(line_no_list[1], line_no_list[-1]):\n",
    "            line = linecache.getline(file_statevector_ICs,i)\n",
    "            line_list.append(line)\n",
    "        dates = []\n",
    "        for i ,val in enumerate(line_list):\n",
    "            if datetype == 'datetime_string':\n",
    "                dates.append(pd.to_datetime(line_list[i][:19],format='%Y-%m-%d %H:%M:%S'))\n",
    "            elif datetype == 'YYMMDDHHMMSS':\n",
    "                dates.append(pd.to_datetime(line_list[i][:19],format='%y%m%d%H%M%S.%f'))\n",
    "        \n",
    "        start_update.append(dates[1])\n",
    "        \n",
    "    else:\n",
    "#         print('Found date in IC file:', str(epoch_startDT))\n",
    "        xyzline = pd.read_csv(file_statevector_ICs, \n",
    "                    skiprows = line_no, \n",
    "                    nrows=1,           \n",
    "                    sep = '\\s+',\n",
    "                    dtype=str,\n",
    "                    names = [\n",
    "                        'DateYMD',\n",
    "                        'DateHMS',\n",
    "                        'X',\n",
    "                        'Y',\n",
    "                        'Z',\n",
    "                        'X_dot',\n",
    "                        'Y_dot',\n",
    "                        'Z_dot',\n",
    "                            ],)\n",
    "        start_update.append(pd.to_datetime(xyzline['DateYMD']+xyzline['DateHMS'], format='%Y-%m-%d%H:%M:%S')[0])\n",
    "\n",
    "    print(prms_arc['epoch_start'][:10], \"earliest time is:\", start_update[iday])\n",
    "\n",
    "#         X     =  float(xyzline['X'].values[0].ljust(20))     #'  -745933.8926940708'\n",
    "#         Y     =  float(xyzline['Y'].values[0].ljust(20))     #'  -4864983.834066438'\n",
    "#         Z     =  float(xyzline['Z'].values[0].ljust(20))     #'    4769954.60524261'\n",
    "#         X_dot =  float(xyzline['X_dot'].values[0].ljust(20)) #'  457.44564954037634'\n",
    "#         Y_dot =  float(xyzline['Y_dot'].values[0].ljust(20)) #'   5302.381564886811'\n",
    "#         Z_dot =  float(xyzline['Z_dot'].values[0].ljust(20)) #'    5463.55571622269'\n",
    "#     print(f\"   [X,Y,Z]:          [{X    :15.5f}, {Y    :15.5f}, {Z    :15.5f}]\")\n",
    "#     print(f\"   [Xdot,Ydot,Zdot]: [{X_dot:15.5f}, {Y_dot:15.5f}, {Z_dot:15.5f}]\")        \n",
    "#     print()        \n",
    "\n",
    "del date_roundhour_str\n",
    "del line_no_list\n",
    "del line_list\n",
    "del dates\n",
    "del xyzline\n",
    "\n",
    "start_update = [datetime.strftime(idate, '%Y-%m-%d %H:%M:%S') for idate in start_update]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0d0a4b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:51:20.704295Z",
     "start_time": "2023-02-03T16:51:20.699051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018-11-02 00:00:00', '2018-11-03 00:00:00', '2018-11-04 00:00:00', '2018-11-05 00:00:00']\n",
      "['2018-11-03 00:00:00', '2018-11-04 00:00:00', '2018-11-05 00:00:00', '2018-11-06 00:00:00']\n",
      "['2018-11-02 00:00:00', '2018-11-03 01:02:55', '2018-11-04 00:52:55', '2018-11-05 00:45:16']\n",
      "['2018.306', '2018.307', '2018.308', '2018.309']\n"
     ]
    }
   ],
   "source": [
    "print(start_0ut)\n",
    "print(end___0ut)\n",
    "print(start_update)\n",
    "print(arcs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821fbaad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-02T22:48:19.477367Z",
     "start_time": "2023-02-02T22:48:19.458906Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dde20de",
   "metadata": {},
   "source": [
    "### Run GEODYN with earliest start time to midnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d5e9c5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:51:20.867209Z",
     "start_time": "2023-02-03T16:51:20.707163Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pygeodyn.PYGEODYN import Pygeodyn\n",
    "from gc import collect as gc_collect\n",
    "\n",
    "# run_settings = Pygeodyn.print_input(options=False, info=False)\n",
    "\n",
    "\n",
    "settings_SPIRE= {# Basic input settings\n",
    "                 'satellite'      : {'input': 'spire83'},\n",
    "                 'den_model'      : {'input': 'jb2008'},\n",
    "                 'run_type'       : {'input': 'DataReduction_PCE'},\n",
    "                 'run_specifier'  : {'input': '_test_infrastruc'},\n",
    "                 'cd_model'       : {'input': 'BWDRAG'},\n",
    "                 'file_string'    : {'input': 'CD_2p3'},\n",
    "                 # Force Model settings\n",
    "                  'cd_type'               : {'input':\"Fixed_CD\"},\n",
    "                  'cd_value'              : {'input':2.300000},\n",
    "                  'scaling_factor'        : {'input':False},\n",
    "                  'cd_adjustment_boolean' : {'input':False },\n",
    "                  'hours_between_cd_adj'  : {'input':6 },\n",
    "                 # Run\n",
    "                  'step'           : {'input': 30.},\n",
    "                  'orbfil_step'    : {'input': 30.},    \n",
    "                   #\n",
    "                  'arc'            : {'input':arcs},\n",
    "                  'epoch_start'    : {'input':start_update},\n",
    "                   #\n",
    "                  'epoch_stop'     : {'input':end___0ut},       \n",
    "                   #\n",
    "                  'global_options' : {'input':'pso_2018'},\n",
    "                 # Request read on raw outputs\n",
    "                  'request_data'   : {'input': ['Trajectory_orbfil']},\n",
    "              #end dict\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "287c60ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:51:30.248902Z",
     "start_time": "2023-02-03T16:51:20.870392Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018.306,  loading jb2008\n",
      "  - convergence achieved\n",
      "     xyzline 30754 2018-11-02 00:00:00   -4520742.22058   -1301871.58945    4986886.37752       -394.47597      -7276.54789      -2244.24756\n",
      "\n",
      "Found date in IC file: 2018-11-02 00:00:00\n",
      "   [X,Y,Z]:          [ -4520742.22058,  -1301871.58945,   4986886.37752]\n",
      "   [Xdot,Ydot,Zdot]: [     -394.47597,     -7276.54789,     -2244.24756]\n",
      "\n",
      "\n",
      "2018.307,  loading jb2008\n",
      "  - convergence achieved\n",
      "     xyzline 64658 2018-11-03 01:02:55   -4242037.15803     740496.48895    5331691.84664      -2271.36157      -7237.31513       -792.19468\n",
      "\n",
      "Found date in IC file: 2018-11-03 01:02:55\n",
      "   [X,Y,Z]:          [ -4242037.15803,    740496.48895,   5331691.84664]\n",
      "   [Xdot,Ydot,Zdot]: [    -2271.36157,     -7237.31513,      -792.19468]\n",
      "\n",
      "\n",
      "2018.308,  loading jb2008\n",
      "  - convergence achieved\n",
      "     xyzline 97343 2018-11-04 00:52:55   -4004970.31658   -5385662.24386    1437820.04371       3129.31949      -3877.98799      -5766.28836\n",
      "\n",
      "Found date in IC file: 2018-11-04 00:52:55\n",
      "   [X,Y,Z]:          [ -4004970.31658,  -5385662.24386,   1437820.04371]\n",
      "   [Xdot,Ydot,Zdot]: [     3129.31949,     -3877.98799,     -5766.28836]\n",
      "\n",
      "\n",
      "2018.309,  loading jb2008\n",
      "  - convergence achieved\n",
      "     xyzline 130384 2018-11-05 00:45:16    1354306.66746   -4840299.33898   -4678543.38969       5459.98790       4399.82529      -2965.52809\n",
      "\n",
      "Found date in IC file: 2018-11-05 00:45:16\n",
      "   [X,Y,Z]:          [  1354306.66746,  -4840299.33898,  -4678543.38969]\n",
      "   [Xdot,Ydot,Zdot]: [     5459.98790,      4399.82529,     -2965.52809]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sat = Pygeodyn(settings_SPIRE, use_file=False)\n",
    "\n",
    "# sat.run_arcs()\n",
    "obj = sat.getData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4c109b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-01T18:27:27.494153Z",
     "start_time": "2023-02-01T18:27:27.472968Z"
    }
   },
   "source": [
    "### Load the data, grab the final trajectory point from the previous day, use this value as initial condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35a8d5c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:51:30.273822Z",
     "start_time": "2023-02-03T16:51:30.251756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing values for 2018.306\n",
      "Writing values for 2018.307\n",
      "Writing values for 2018.308\n",
      "Writing values for 2018.309\n"
     ]
    }
   ],
   "source": [
    "IC_update_0ut=[]\n",
    "\n",
    "for iarc, valarc in enumerate(obj.__dict__['global_params']['arc_input']):\n",
    "    print('Writing values for', valarc)\n",
    "    IC_update_0ut.append([\\\n",
    "            obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['X j2000'].values[-1],\n",
    "            obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['Y j2000'].values[-1],\n",
    "            obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['Z j2000'].values[-1],\n",
    "            obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['X_dot j2000'].values[-1],\n",
    "            obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['Y_dot j2000'].values[-1],\n",
    "            obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['Z_dot j2000'].values[-1]\n",
    "                        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05f0f243",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:51:30.292592Z",
     "start_time": "2023-02-03T16:51:30.277157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[523110.1443382325, -5930104.572804029, -3421833.1925745346, 5184.988481638479, 3125.362395719306, -4620.351856357143], [4725171.38309032, 3834594.807539863, -3161748.204033614, -1402.6360786755376, 5715.506672554241, 4849.866163957699], [-2121797.632386333, 4137298.3437206373, 5030508.754469125, -5154.27310355572, -5213.25900586897, 2117.2400239433664], [-4397963.726929919, -5242051.208765718, 558498.358406628, 3308.0804952364015, -3421.299515092137, -5950.286314239187]]\n"
     ]
    }
   ],
   "source": [
    "print(IC_update_0ut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7df8efc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:51:30.308837Z",
     "start_time": "2023-02-03T16:51:30.295168Z"
    }
   },
   "outputs": [],
   "source": [
    "# # update_0ut_sv=[]\n",
    "\n",
    "# # for iarc, valarc in enumerate(obj.__dict__['global_params']['arc_input']):\n",
    "# #     print()\n",
    "# # #     print(obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['Date_UTC'].values[-1])\n",
    "# # #     print('   ',obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['X j2000'].values[-1])\n",
    "# #     update_0ut_sv.append([\\\n",
    "# #             obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['X j2000'].values[-1],\n",
    "# #             obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['Y j2000'].values[-1],\n",
    "# #             obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['Z j2000'].values[-1],\n",
    "# #             obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['X_dot j2000'].values[-1],\n",
    "# #             obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['Y_dot j2000'].values[-1],\n",
    "# #             obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['Z_dot j2000'].values[-1]\n",
    "# #                         ])\n",
    "    \n",
    "# update_0ut_sv = [  [ 3928916.458133645 ,  #[3814035.3855300485,\n",
    "#                    -1872640.264047095 ,  # -2032967.592959765,\n",
    "#                    -5308435.441564657 ,  # -5332424.200973777,\n",
    "#                     4321.568196942277 ,  # 4445.699155052163,\n",
    "#                     6185.181504378663 ,  # 6122.880673353949,\n",
    "#                     1024.611110847065],  # 853.7335509694938],\n",
    "#                 [3338067.1976274904,\n",
    "#                 5588610.712440854,\n",
    "#                 2136698.256099367,\n",
    "#                 -5201.3580624253755,\n",
    "#                 996.740676696283,\n",
    "#                 5498.429266661564],\n",
    "#                 [-5426338.454433531,\n",
    "#                 -169513.06801732714,\n",
    "#                 4187973.912968636,\n",
    "#                 -2720.9192328067647,\n",
    "#                 -6055.799912547885,\n",
    "#                 -3750.909866748835],\n",
    "#                 [-1361128.728764797,\n",
    "#                 -5124562.117802262,\n",
    "#                 -4364950.955087397,\n",
    "#                 6647.617864337456,\n",
    "#                 1221.4949833863877,\n",
    "#                 -3502.5319366388662],\n",
    "#                 [6314428.287261461,\n",
    "#                 1998038.7321490748,\n",
    "#                 -1770479.5953752713,\n",
    "#                 -44.52103320599878,\n",
    "#                 5118.362538082618,\n",
    "#                 5657.972765270434],\n",
    "#                 [-1393576.3065223494,\n",
    "#                 4026748.015999339,\n",
    "#                 5361457.6461432865,\n",
    "#                 -7032.783574258777,\n",
    "#                 -2938.4411141419014,\n",
    "#                 385.7254176550402],\n",
    "#                 [-6010694.155270688,\n",
    "#                 -3132233.352653585,\n",
    "#                 -1096273.1800164438,\n",
    "#                 3044.0518607378153,\n",
    "#                 -3807.468037176313,\n",
    "#                 -5855.0109650008535],\n",
    "#                 ]\n",
    "\n",
    "# # [update_0ut_sv[0],\n",
    "# # update_0ut_sv[1],\n",
    "# # update_0ut_sv[2],\n",
    "# # update_0ut_sv[3],\n",
    "# # update_0ut_sv[4],\n",
    "# # update_0ut_sv[5],\n",
    "# # ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d234c9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:51:30.333422Z",
     "start_time": "2023-02-03T16:51:30.310858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2018.306', '2018.307', '2018.308', '2018.309']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad83e2de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:51:30.352371Z",
     "start_time": "2023-02-03T16:51:30.335798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2018.306', '2018.307', '2018.308']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcs[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0630af5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:51:30.375400Z",
     "start_time": "2023-02-03T16:51:30.354586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pygeodyn.PYGEODYN import Pygeodyn\n",
    "from gc import collect as gc_collect\n",
    "\n",
    "# run_settings = Pygeodyn.print_input(options=False, info=False)\n",
    "\n",
    "\n",
    "settings_SPIRE= {# Basic input settings\n",
    "                 'satellite'      : {'input': 'spire83'},\n",
    "                 'den_model'      : {'input': 'jb2008'},\n",
    "                 'run_type'       : {'input': 'DataReduction_PCE'},\n",
    "                 'run_specifier'  : {'input': '_test_ics'},\n",
    "                 'cd_model'       : {'input': 'BWDRAG'},\n",
    "                 'file_string'    : {'input': 'CD_2p3'},\n",
    "               # Force Model settings\n",
    "                  'cd_type'               : {'input':\"Fixed_CD\"},\n",
    "                  'cd_value'              : {'input':2.300000},\n",
    "                  'scaling_factor'        : {'input':False},\n",
    "                  'cd_adjustment_boolean' : {'input':False },\n",
    "                  'hours_between_cd_adj'  : {'input':6 },\n",
    "               # Run\n",
    "                  'step'           : {'input': 60.},\n",
    "                  'orbfil_step'    : {'input': 60.},    \n",
    "\n",
    "                  #\n",
    "                  'arc'            : {'input':arcs[1:]},\n",
    "                  'epoch_start'    : {'input':start_0ut[1:]},\n",
    "                  'epoch_stop'     : {'input':end___0ut[1:]},       \n",
    "                  'initial_conditions':{'input':IC_update_0ut[:-1]},\n",
    "\n",
    "                  'global_options' : {'input':'pso_2018'},\n",
    "               # Request read on raw outputs\n",
    "                  'request_data'   : {'input': ['Trajectory_orbfil', \n",
    "                                                'RunSummary']},\n",
    "              #end dict\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29fc7e39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:59:09.479108Z",
     "start_time": "2023-02-03T16:51:30.379000Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G2B file exists: /data/SatDragModelValidation/data/inputs/sat_spire83/g2b/g2b_pce_leoOrb_nov2018\n",
      "Run #1     Current Time =      09:51:31  GMT-7\n",
      "Run #1\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "| Run #1 Parameters\n",
      "| —————————————————\n",
      "|  Run Specs\n",
      "|  --------- \n",
      "|    Satellite    spire83\n",
      "|    Run Type     DataReduction_PCE\n",
      "|    CD Type      Fixed_CD\n",
      "|    CD Value     2.3\n",
      "|    Density      jb2008\n",
      "|\n",
      "|  Epoch Info \n",
      "|  ---------- \n",
      "|    Arc          2018.307\n",
      "|    Arc length   24.0 hours\n",
      "|    Epoch Start  2018-11-03 00:00:00\n",
      "|    Epoch End    2018-11-04 00:00:00\n",
      "|    Step Size    60.0 seconds\n",
      "|\n",
      "|  Files Info\n",
      "|  ---------- \n",
      "|    Arc Name    spire83_2018307.01_jb2008.CD_2p3\n",
      "|\n",
      "|    IISSET      .../data/inputs/sat_spire83/setups/iisset.2018.307\n",
      "|    EXAT        .../data/inputs/sat_spire83/external_attitude/EXAT01.2018.307.gz\n",
      "|    Output Raw  .../data/outputs_raw/spire83/jb2008/jb2008_BWDRAG_test_ics/\n",
      "|\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "\n",
      "Run #1          Running IIS\n",
      "Run #1          No errors in IIS\n",
      "Run #1 ---------End of IIS\n",
      "\n",
      "Run #1          Running IIE\n",
      "Run #1          Current Time = 09:52:07 GMT-7\n",
      " ------ Current DIR:  /data/SatDragModelValidation/data/tmp/jb2008_BWDRAG_test_ics/spire83_2018307.01_jb2008.CD_2p3\n",
      "Run #1          No errors in IIE\n",
      "Run #1 ---------End of IIE\n",
      "  - convergence achieved\n",
      "Run #1          Time of IIE:  137.9351875782013 secs ( 2.2989197929700214  mins)\n",
      "Run #1          Current Time = 16:54:25\n",
      "Saving fort.103 as drag_file\n",
      "Saving fort.104 as SatGeometry_file\n",
      "Run #1                Finished renaming files\n",
      "Run #1                Finished copying files to outputdir\n",
      "G2B file exists: /data/SatDragModelValidation/data/inputs/sat_spire83/g2b/g2b_pce_leoOrb_nov2018\n",
      "Run #2     Current Time =      09:54:28  GMT-7\n",
      "Run #2\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "| Run #2 Parameters\n",
      "| —————————————————\n",
      "|  Run Specs\n",
      "|  --------- \n",
      "|    Satellite    spire83\n",
      "|    Run Type     DataReduction_PCE\n",
      "|    CD Type      Fixed_CD\n",
      "|    CD Value     2.3\n",
      "|    Density      jb2008\n",
      "|\n",
      "|  Epoch Info \n",
      "|  ---------- \n",
      "|    Arc          2018.308\n",
      "|    Arc length   24.0 hours\n",
      "|    Epoch Start  2018-11-04 00:00:00\n",
      "|    Epoch End    2018-11-05 00:00:00\n",
      "|    Step Size    60.0 seconds\n",
      "|\n",
      "|  Files Info\n",
      "|  ---------- \n",
      "|    Arc Name    spire83_2018308.01_jb2008.CD_2p3\n",
      "|\n",
      "|    IISSET      .../data/inputs/sat_spire83/setups/iisset.2018.308\n",
      "|    EXAT        .../data/inputs/sat_spire83/external_attitude/EXAT01.2018.308.gz\n",
      "|    Output Raw  .../data/outputs_raw/spire83/jb2008/jb2008_BWDRAG_test_ics/\n",
      "|\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "\n",
      "Run #2          Running IIS\n",
      "Run #2          No errors in IIS\n",
      "Run #2 ---------End of IIS\n",
      "\n",
      "Run #2          Running IIE\n",
      "Run #2          Current Time = 09:54:56 GMT-7\n",
      " ------ Current DIR:  /data/SatDragModelValidation/data/tmp/jb2008_BWDRAG_test_ics/spire83_2018308.01_jb2008.CD_2p3\n",
      "Run #2          No errors in IIE\n",
      "Run #2 ---------End of IIE\n",
      "  - convergence achieved\n",
      "Run #2          Time of IIE:  108.6551718711853 secs ( 1.8109195311864217  mins)\n",
      "Run #2          Current Time = 16:56:45\n",
      "Saving fort.103 as drag_file\n",
      "Saving fort.104 as SatGeometry_file\n",
      "Run #2                Finished renaming files\n",
      "Run #2                Finished copying files to outputdir\n",
      "G2B file exists: /data/SatDragModelValidation/data/inputs/sat_spire83/g2b/g2b_pce_leoOrb_nov2018\n",
      "Run #3     Current Time =      09:56:47  GMT-7\n",
      "Run #3\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "| Run #3 Parameters\n",
      "| —————————————————\n",
      "|  Run Specs\n",
      "|  --------- \n",
      "|    Satellite    spire83\n",
      "|    Run Type     DataReduction_PCE\n",
      "|    CD Type      Fixed_CD\n",
      "|    CD Value     2.3\n",
      "|    Density      jb2008\n",
      "|\n",
      "|  Epoch Info \n",
      "|  ---------- \n",
      "|    Arc          2018.309\n",
      "|    Arc length   24.0 hours\n",
      "|    Epoch Start  2018-11-05 00:00:00\n",
      "|    Epoch End    2018-11-06 00:00:00\n",
      "|    Step Size    60.0 seconds\n",
      "|\n",
      "|  Files Info\n",
      "|  ---------- \n",
      "|    Arc Name    spire83_2018309.01_jb2008.CD_2p3\n",
      "|\n",
      "|    IISSET      .../data/inputs/sat_spire83/setups/iisset.2018.309\n",
      "|    EXAT        .../data/inputs/sat_spire83/external_attitude/EXAT01.2018.309.gz\n",
      "|    Output Raw  .../data/outputs_raw/spire83/jb2008/jb2008_BWDRAG_test_ics/\n",
      "|\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "\n",
      "Run #3          Running IIS\n",
      "Run #3          No errors in IIS\n",
      "Run #3 ---------End of IIS\n",
      "\n",
      "Run #3          Running IIE\n",
      "Run #3          Current Time = 09:57:15 GMT-7\n",
      " ------ Current DIR:  /data/SatDragModelValidation/data/tmp/jb2008_BWDRAG_test_ics/spire83_2018309.01_jb2008.CD_2p3\n",
      "Run #3          No errors in IIE\n",
      "Run #3 ---------End of IIE\n",
      "  - convergence achieved\n",
      "Run #3          Time of IIE:  105.68597483634949 secs ( 1.761432913939158  mins)\n",
      "Run #3          Current Time = 16:59:01\n",
      "Saving fort.103 as drag_file\n",
      "Saving fort.104 as SatGeometry_file\n",
      "Run #3                Finished renaming files\n",
      "Run #3                Finished copying files to outputdir\n",
      "\n",
      "2018.307,  loading jb2008\n",
      "  - convergence achieved\n",
      "\n",
      "2018.308,  loading jb2008\n",
      "  - convergence achieved\n",
      "\n",
      "2018.309,  loading jb2008\n",
      "  - convergence achieved\n"
     ]
    }
   ],
   "source": [
    "sat = Pygeodyn(settings_SPIRE, use_file=False)\n",
    "\n",
    "sat.run_arcs()\n",
    "obj = sat.getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c581fa61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-02T20:44:29.111267Z",
     "start_time": "2023-02-02T20:44:29.096133Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2da3b763",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:59:09.503053Z",
     "start_time": "2023-02-03T16:59:09.483794Z"
    }
   },
   "outputs": [],
   "source": [
    "# indx = 0\n",
    "# arc = settings_SPIRE['arc']['input'][indx]\n",
    "\n",
    "# # obj.__dict__['RunSummary'][arc]\n",
    "\n",
    "# # \n",
    "# print(obj.__dict__['Trajectory_orbfil'][arc]['data_record']['X j2000'].values[0],\n",
    "#       obj.__dict__['Trajectory_orbfil'][arc]['data_record']['Y j2000'].values[0],\n",
    "#       obj.__dict__['Trajectory_orbfil'][arc]['data_record']['Z j2000'].values[0],\n",
    "#       obj.__dict__['Trajectory_orbfil'][arc]['data_record']['X_dot j2000'].values[0],\n",
    "#       obj.__dict__['Trajectory_orbfil'][arc]['data_record']['Y_dot j2000'].values[0],\n",
    "#       obj.__dict__['Trajectory_orbfil'][arc]['data_record']['Z_dot j2000'].values[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b6c356",
   "metadata": {},
   "source": [
    "# Finally grab values along these orbits and make these the Initial Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9283dba1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:59:09.519233Z",
     "start_time": "2023-02-03T16:59:09.505273Z"
    }
   },
   "outputs": [],
   "source": [
    "# obj.__dict__['Trajectory_orbfil'][arc]['data_record'].columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8335971",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-02T21:07:37.264483Z",
     "start_time": "2023-02-02T21:07:36.914840Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "557cabfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:59:09.924518Z",
     "start_time": "2023-02-03T16:59:09.521283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing values for 2018.307\n",
      "Writing values for 2018.308\n",
      "Writing values for 2018.309\n"
     ]
    }
   ],
   "source": [
    "### Write to an ascii text file. \n",
    "file_save = '/data/SatDragModelValidation/data/inputs/sat_spire83/setups'\\\n",
    "                + '/Spire83_initialconditions_Nov2018_v2.txt'\n",
    "arc0 = settings_SPIRE['arc']['input'][0]\n",
    "with open(file_save, 'r+') as file:\n",
    "    #### Manually write the header units\n",
    "    header_units =\\\n",
    "                f\"{'UTC'.rjust(len(str(obj.__dict__['Trajectory_orbfil'][arc0]['data_record']['Date_UTC'][1]))-1,' ') }\"\\\n",
    "            +f\"  {'(m)'.rjust(15,' ')}\"\\\n",
    "            +f\"  {'(m)'.rjust(15,' ')}\"\\\n",
    "            +f\"  {'(m)'.rjust(15,' ')}\"\\\n",
    "            +f\"  {'(m/s)'.rjust(15,' ')}\"\\\n",
    "            +f\"  {'(m/s)'.rjust(15,' ')}\"\\\n",
    "            +f\"  {'(m/s)'.rjust(15,' ')}\"\\\n",
    "\n",
    "    #### Manually write the header field names\n",
    "    header_names =\\\n",
    "                f\"{'Date'.rjust(len(str(obj.__dict__['Trajectory_orbfil'][arc0]['data_record']['Date_UTC'][1]))-1,' ') }\"\\\n",
    "            +f\"  {'X'.rjust(15,' ')}\"\\\n",
    "            +f\"  {'Y'.rjust(15,' ')}\"\\\n",
    "            +f\"  {'Z'.rjust(15,' ')}\"\\\n",
    "            +f\"  {'X_dot'.rjust(15,' ')}\"\\\n",
    "            +f\"  {'Y_dot'.rjust(15,' ')}\"\\\n",
    "            +f\"  {'Z_dot'.rjust(15,' ')}\"\\\n",
    "\n",
    "\n",
    "#---+----1----+----2----+----3----+----4----+----5----+----6----+----7----+----8\n",
    "    #### Manually write the detailed header description\n",
    "    header_meta = \\\n",
    "    f'''### Initial conditions file\n",
    "### -----------------------\n",
    "###     Satellite: Spire_083 (1804607)\n",
    "###     Last modified: {datetime.now()-timedelta(hours=7)}\n",
    "###\n",
    "### Source\n",
    "### -------\n",
    "###     Initial conditions from Converged Solutions of GEODYN data reduction.\n",
    "###     Constructed as follows:\n",
    "###        Stage 1\n",
    "###           - for each day of interest, find the earliest epoch time in that\n",
    "###             day that matches the raw data (PCE)\n",
    "###           - set epoch_start value to be that time for each day, respectively\n",
    "###           - run GEODYN with the earliest time of day until midnight.\n",
    "###           - Collect the trajectory outputs into a file, saving just\n",
    "###             state vector of the starttime and endtime\n",
    "###        Stage 2  \n",
    "###           - Set the epoch start time to midnight\n",
    "###           - Use the final state vector values from the previous day\n",
    "###             (should be within 1 minute of midnight) as the new\n",
    "###             initial condition\n",
    "###           - Run geodyn for each daily arc from 0 UT to 0 UT\n",
    "###        Stage 3 \n",
    "###           - correct any failed convergences\n",
    "###           - use the output orbit solutions from the converged solutions\n",
    "###             as the updated initial conditions\n",
    "###      note-- Orbits were fit to PCE (SpireLeoOrb 'POD' from RTOrb) \n",
    "###             using Jb2008 density model.\n",
    "###\n",
    "### Contents\n",
    "### --------\n",
    "###     Date: (YYYY-MM-DD hh:mm:ss.ssssss) (UTC)\n",
    "###     pvi: Position and velocity (X, Y, Z, X_dot, Y_dot, Z_dot)\n",
    "###          coordinate: ECI-J2000\n",
    "###          unit: m and m/s\n",
    "###\n",
    "#{header_units}\n",
    "#{header_names}\n",
    "### %eoh\n",
    "'''\n",
    "    file.write(header_meta)\n",
    "\n",
    "\n",
    "    for iarc, valarc in enumerate(obj.__dict__['global_params']['arc_input']):\n",
    "        print('Writing values for', valarc)\n",
    "    #     update_0ut_sv.append([\\\n",
    "    #             obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['X j2000'].values[-1],\n",
    "    #             obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['Y j2000'].values[-1],\n",
    "    #             obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['Z j2000'].values[-1],\n",
    "    #             obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['X_dot j2000'].values[-1],\n",
    "    #             obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['Y_dot j2000'].values[-1],\n",
    "    #             obj.__dict__['Trajectory_orbfil'][valarc]['data_record']['Z_dot j2000'].values[-1]\n",
    "    #                         ])\n",
    "\n",
    "        # \n",
    "        #\n",
    "        orbit_data = obj.__dict__['Trajectory_orbfil'][valarc]['data_record']\n",
    "\n",
    "\n",
    "\n",
    "        for ii, val in enumerate(orbit_data['Date_UTC']):\n",
    "            ### Only print the hourly values (when the minute value is 0)\n",
    "#             if orbit_data['Date_UTC'][ii].minute==0:\n",
    "            row =   f\"{orbit_data['Date_UTC'][ii]}\"         \\\n",
    "                   +f\"  {orbit_data['X j2000'][ii]:15.5f}\"    \\\n",
    "                   +f\"  {orbit_data['Y j2000'][ii]:15.5f}\"    \\\n",
    "                   +f\"  {orbit_data['Z j2000'][ii]:15.5f}\"    \\\n",
    "                   +f\"  {orbit_data['X_dot j2000'][ii]:15.5f}\"\\\n",
    "                   +f\"  {orbit_data['Y_dot j2000'][ii]:15.5f}\"\\\n",
    "                   +f\"  {orbit_data['Z_dot j2000'][ii]:15.5f}\"\\\n",
    "                   + f\"\\n\"\n",
    "        #     print(row)\n",
    "            file.write(row)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45311fff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:59:09.945631Z",
     "start_time": "2023-02-03T16:59:09.926708Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# X_prop = obj.__dict__['Trajectory_orbfil'][arc]['data_record']['X j2000']\n",
    "# Y_prop = obj.__dict__['Trajectory_orbfil'][arc]['data_record']['Y j2000']\n",
    "# Z_prop = obj.__dict__['Trajectory_orbfil'][arc]['data_record']['Z j2000']\n",
    "# #\n",
    "# Xdot_prop = obj.__dict__['Trajectory_orbfil'][arc]['data_record']['X_dot j2000']\n",
    "# Ydot_prop = obj.__dict__['Trajectory_orbfil'][arc]['data_record']['Y_dot j2000']\n",
    "# Zdot_prop = obj.__dict__['Trajectory_orbfil'][arc]['data_record']['Z_dot j2000']\n",
    "\n",
    "# date_prop = obj.__dict__['Trajectory_orbfil'][arc]['data_record']['Date_UTC']\n",
    "\n",
    "# print(X_prop.values[0],\n",
    "# Y_prop.values[0],\n",
    "# Z_prop.values[0],\n",
    "# Xdot_prop.values[0],\n",
    "# Ydot_prop.values[0],\n",
    "# Zdot_prop.values[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ae63d77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:59:09.961161Z",
     "start_time": "2023-02-03T16:59:09.947615Z"
    }
   },
   "outputs": [],
   "source": [
    "#  'X POS': 3928931.51724803,\n",
    "#  'Y POS': -1872620.338460264,\n",
    "#  'Z POS': -5308433.202954784,\n",
    "#  'X VEL': 4321.552827772032,\n",
    "#  'Y VEL': 6185.186740784374,\n",
    "#  'Z VEL': 1024.630175475583,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ece7238",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:59:09.977738Z",
     "start_time": "2023-02-03T16:59:09.963183Z"
    }
   },
   "outputs": [],
   "source": [
    "# epoch_start = settings_SPIRE['epoch_start']['input'][indx]\n",
    "\n",
    "\n",
    "# prms_arc={}\n",
    "# prms_arc['epoch_start'] = epoch_start\n",
    "# prms_arc['epoch_startDT'] = pd.to_datetime(prms_arc['epoch_start'],\\\n",
    "#                                             format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# epoch_startDT = prms_arc['epoch_startDT']\n",
    "# file_statevector_ICs = \"/data/SatDragModelValidation/data/inputs/\"\\\n",
    "#                         +\"sat_spire83/setups/Spire83_initialconditions_Nov2018_v1.txt\"\n",
    "\n",
    "# datetype = 'datetime_string'\n",
    "\n",
    "# date_in_file_flag= False\n",
    "# import linecache\n",
    "\n",
    "# ### Only need to use accuracy to within 1 second (ignore the microseconds in the file)\n",
    "\n",
    "# if datetype == 'datetime_string':\n",
    "#     date_str = str(epoch_startDT)\n",
    "# elif datetype == 'YYMMDDHHMMSS':\n",
    "#     date_str = datetime.strftime(epoch_startDT, '%y%m%d%H%M%S')\n",
    "\n",
    "\n",
    "# with open(file_statevector_ICs, 'r') as f:\n",
    "#     ### Find the dates that have the same hour    \n",
    "#     if datetype == 'datetime_string':\n",
    "#         date_roundhour_str = str(epoch_startDT)[:10]\n",
    "#     elif datetype == 'YYMMDDHHMMSS':\n",
    "#         date_roundhour_str = datetime.strftime(epoch_startDT, '%y%m%d%H%M%S')\n",
    "\n",
    "#     ### Scan through IC file and append a list of dates within the same hour\n",
    "#     line_no_list = []\n",
    "#     line_list = []\n",
    "#     with open(file_statevector_ICs, 'r') as f:\n",
    "#         for line_no, line_text in enumerate(f):\n",
    "#             if date_roundhour_str in line_text:\n",
    "#                 line_no_list.append(line_no)\n",
    "#     for i in np.arange(line_no_list[0]-10, line_no_list[-1]+10):\n",
    "#         line = linecache.getline(file_statevector_ICs,i)\n",
    "#         line_list.append(line)\n",
    "#     dates = []\n",
    "#     for i ,val in enumerate(line_list):\n",
    "#         if datetype == 'datetime_string':\n",
    "#             dates.append(pd.to_datetime(line_list[i][:19],format='%Y-%m-%d %H:%M:%S'))\n",
    "#         elif datetype == 'YYMMDDHHMMSS':\n",
    "#             dates.append(pd.to_datetime(line_list[i][:19],format='%y%m%d%H%M%S.%f'))\n",
    "            \n",
    "            \n",
    "            \n",
    "# xyzline = pd.read_csv(file_statevector_ICs, \n",
    "#             skiprows = line_no_list[0], \n",
    "#             nrows=line_no_list[-1]- line_no_list[0],           \n",
    "#             sep = '\\s+',\n",
    "#             dtype=object,\n",
    "#             names = [\n",
    "#                 'DateYMD',\n",
    "#                 'DateHMS',\n",
    "#                 'X',\n",
    "#                 'Y',\n",
    "#                 'Z',\n",
    "#                 'X_dot',\n",
    "#                 'Y_dot',\n",
    "#                 'Z_dot',\n",
    "#                     ],)\n",
    "\n",
    "# xyzline['Date'] =  pd.to_datetime(xyzline['DateYMD']+xyzline['DateHMS'], format='%Y-%m-%d%H:%M:%S')\n",
    "# del xyzline['DateYMD'], xyzline['DateHMS']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75e0d3fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:59:09.993485Z",
     "start_time": "2023-02-03T16:59:09.979764Z"
    }
   },
   "outputs": [],
   "source": [
    "# line_no_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac133de8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T16:59:10.015673Z",
     "start_time": "2023-02-03T16:59:09.995686Z"
    }
   },
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "# from plotly.offline import plot, iplot\n",
    "# from plotly.subplots import make_subplots\n",
    "# import plotly.express as px\n",
    "\n",
    "# config = dict({\n",
    "#                 'displayModeBar': True,\n",
    "#                 'responsive': False,\n",
    "#                 'staticPlot': True,\n",
    "#                 'displaylogo': False,\n",
    "#                 'showTips': False,\n",
    "#                 })\n",
    "\n",
    "\n",
    "# fig = make_subplots(rows=3, cols=1)\n",
    "\n",
    "\n",
    "\n",
    "# fig.add_trace(go.Scattergl(\n",
    "#             x=pd.to_datetime(xyzline['Date']),\n",
    "#             y=xyzline['X'].values.astype(float),\n",
    "#                 mode='markers',\n",
    "#                 opacity=1,\n",
    "#                 marker=dict(size=3, color=\"blue\"),\n",
    "#                 showlegend=False),\n",
    "#                 secondary_y=False, row=1, col=1,)\n",
    "\n",
    "# fig.add_trace(go.Scattergl(\n",
    "#             x=pd.to_datetime(xyzline['Date']),\n",
    "#             y=xyzline['Y'].values.astype(float),\n",
    "#                 mode='markers',\n",
    "#                 opacity=1,\n",
    "#                 marker=dict(size=3, color=\"blue\"),\n",
    "#                 showlegend=False),\n",
    "#                 secondary_y=False, row=2, col=1,)\n",
    "\n",
    "# fig.add_trace(go.Scattergl(\n",
    "#             x=pd.to_datetime(xyzline['Date']),\n",
    "#             y=xyzline['Z'].values.astype(float),\n",
    "#                 mode='markers',\n",
    "#                 opacity=1,\n",
    "#                 marker=dict(size=3, color=\"blue\"),     \n",
    "#                 showlegend=False),\n",
    "#                 secondary_y=False, row=3, col=1,)\n",
    "\n",
    "# ### ==============================================================\n",
    "\n",
    "\n",
    "# fig.add_trace(go.Scattergl(\n",
    "#             x=pd.to_datetime(date_prop),\n",
    "#             y=X_prop.values.astype(float),\n",
    "#                 mode='markers',\n",
    "#                 opacity=1,\n",
    "#                 marker=dict(size=3, color='red'),\n",
    "#                 showlegend=False),\n",
    "#                 secondary_y=False, row=1, col=1,)\n",
    "\n",
    "# fig.add_trace(go.Scattergl(\n",
    "#             x=pd.to_datetime(date_prop),\n",
    "#             y=Y_prop.values.astype(float),\n",
    "#                 mode='markers',\n",
    "#                 opacity=1,\n",
    "#                 marker=dict(size=3, color='red'),\n",
    "#                 showlegend=False),\n",
    "#                 secondary_y=False, row=2, col=1,)\n",
    "\n",
    "# fig.add_trace(go.Scattergl(\n",
    "#             x=pd.to_datetime(date_prop),\n",
    "#             y=Z_prop.values.astype(float),\n",
    "#                 mode='markers',\n",
    "#                 opacity=1,\n",
    "#                 marker=dict(size=3, color='red'),     \n",
    "#                 showlegend=False),\n",
    "#                 secondary_y=False, row=3, col=1,)\n",
    "\n",
    "# fig.update_yaxes( title=\"X\",  exponentformat= 'power',row=1, col=1)\n",
    "# fig.update_yaxes( title=\"Y\",  exponentformat= 'power',row=2, col=1)\n",
    "# fig.update_yaxes( title=\"Z\",  exponentformat= 'power',row=3, col=1)\n",
    "\n",
    "\n",
    "# fig.update_layout(title='PCE (blue, Spire LeoOrb POD); Orbit Fit (red, data reduction with PCE)',\n",
    "#         autosize=True\n",
    "# #         width=800,height=900,\n",
    "#                 )\n",
    "# fig.show(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5093c563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
