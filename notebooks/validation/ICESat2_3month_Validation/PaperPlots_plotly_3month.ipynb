{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f3c46f1",
   "metadata": {},
   "source": [
    "# Codes for constructing the Plots/Figures\n",
    "## Three Month Span"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1583b744",
   "metadata": {},
   "source": [
    "The goal is to have this notebook contain all codes that construct the plots  found in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1778b71",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd076359",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T19:00:24.133650Z",
     "start_time": "2022-06-28T19:00:24.130370Z"
    }
   },
   "outputs": [],
   "source": [
    "run_list = [  # 'msis2'       ,\n",
    "#                'tiegcm_oc'   ,\n",
    "#                'dtm2020'     ,\n",
    "#                'jb2008'      ,\n",
    "               'hasdm_oc',\n",
    "#                'ctipe_oc',\n",
    "           ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2206ae",
   "metadata": {},
   "source": [
    "###  Input/Read GEODYN Runs and dump to pickle, or load the pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88906d7d",
   "metadata": {},
   "source": [
    "#### Three month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "891251fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T19:00:25.949502Z",
     "start_time": "2022-06-28T19:00:24.135282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hasdm_oc_p1  Pickle created -- will load in next step\n",
      "hasdm_oc_p2  Pickle created -- will load in next step\n",
      "\n",
      "\n",
      "Loaded data...  hasdm_oc_p1\n",
      "Loaded data...  hasdm_oc_p2\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys  \n",
    "import os\n",
    "import pickle \n",
    "import gc\n",
    "\n",
    "sys.path.insert(0, '/data/geodyn_proj/pygeodyn/pygeodyn_develop/')\n",
    "from PYGEODYN import Pygeodyn\n",
    "\n",
    "\n",
    "\n",
    "for i,val in enumerate(run_list): \n",
    "    for ii in ['_p1', '_p2']:\n",
    "        \n",
    "        dir_save = '/data/zach_work/output_from_runs/icesat2_3monthrun_pickles/'\n",
    "        pickle_file = dir_save+'Fulltime_valid_'+val+ii+'.pkl'\n",
    "\n",
    "        if not os.path.exists(pickle_file):\n",
    "\n",
    "            print('Must create pickle file...')\n",
    "            print('   ',  pickle_file)\n",
    "            print('   ', 'Reading Geodyn Data')\n",
    "\n",
    "            run_settings = '/data/zach_work/validation/ICESat2_3month_Validation/runsettings_3month_bwdrag_'+ val +ii+'.yaml'\\\n",
    "            ### Load the data into an object\n",
    "            Obj_Geodyn = Pygeodyn(run_settings)\n",
    "            Obj_Geodyn.getData_BigData_lowmemory()\n",
    "\n",
    "            gc.collect()\n",
    "\n",
    "            #### Pickle the object to save it\n",
    "            print('   ', 'Saving pickle')\n",
    "            filehandler = open(pickle_file, 'wb') \n",
    "            pickle.dump(Obj_Geodyn, filehandler)\n",
    "            filehandler.close()\n",
    "            Obj_Geodyn = 0\n",
    "            print('   ', 'Saved pickle')\n",
    "\n",
    "\n",
    "        else:\n",
    "            print(val,ii,'  Pickle created -- will load in next step', sep='')\n",
    "            \n",
    "\n",
    "### Load the data if the pickles exist\n",
    "print()\n",
    "print()\n",
    "gc.collect()\n",
    "\n",
    "Obj_3months = {}\n",
    "for i,val in enumerate(run_list): #,'jb2008','msis2'\n",
    "    for ii in ['_p1', '_p2']:\n",
    "        \n",
    "        \n",
    "        dir_save = '/data/zach_work/output_from_runs/icesat2_3monthrun_pickles/'\n",
    "        pickle_file = dir_save+'Fulltime_valid_'+val+ii+'.pkl'\n",
    "        filehandler = open(pickle_file, 'rb') \n",
    "        Obj_3months[val+ii] = pickle.load(filehandler)\n",
    "        filehandler.close()\n",
    "        print('Loaded data... ', val+ii)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dc31a5",
   "metadata": {},
   "source": [
    "### Plot Settings and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b96f9fc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T19:00:25.964570Z",
     "start_time": "2022-06-28T19:00:25.951942Z"
    }
   },
   "outputs": [],
   "source": [
    "plots_dir = '/data/zach_work/validation/ICESat2_3month_Validation/final_plots/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f578c56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T19:00:26.755443Z",
     "start_time": "2022-06-28T19:00:25.966728Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot, iplot\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.io as pio   ### Allows you to save plotly figs\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "config = dict({\n",
    "                'displayModeBar': False,\n",
    "                'responsive': False,\n",
    "                'staticPlot': True,\n",
    "                'displaylogo': False,\n",
    "                'showTips': False,\n",
    "                })\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# px.colors.colorscale_to_colors()\n",
    "# plotly.colors.PLOTLY_SCALES[\"Viridis\"]\n",
    "\n",
    "def get_color(colorscale_name, loc):\n",
    "    from _plotly_utils.basevalidators import ColorscaleValidator\n",
    "    # first parameter: Name of the property being validated\n",
    "    # second parameter: a string, doesn't really matter in our use case\n",
    "    cv = ColorscaleValidator(\"colorscale\", \"\")\n",
    "    # colorscale will be a list of lists: [[loc1, \"rgb1\"], [loc2, \"rgb2\"], ...] \n",
    "    colorscale = cv.validate_coerce(colorscale_name)\n",
    "    \n",
    "    if hasattr(loc, \"__iter__\"):\n",
    "        return [get_continuous_color(colorscale, x) for x in loc]\n",
    "    return get_continuous_color(colorscale, loc)\n",
    "        \n",
    "\n",
    "# Identical to Adam's answer\n",
    "import plotly.colors\n",
    "from PIL import ImageColor\n",
    "def get_continuous_color(colorscale, intermed):\n",
    "    \"\"\"\n",
    "    Plotly continuous colorscales assign colors to the range [0, 1]. This function computes the intermediate\n",
    "    color for any value in that range.\n",
    "\n",
    "    Plotly doesn't make the colorscales directly accessible in a common format.\n",
    "    Some are ready to use:\n",
    "    \n",
    "        colorscale = plotly.colors.PLOTLY_SCALES[\"Greens\"]\n",
    "\n",
    "    Others are just swatches that need to be constructed into a colorscale:\n",
    "\n",
    "        viridis_colors, scale = plotly.colors.convert_colors_to_same_type(plotly.colors.sequential.Viridis)\n",
    "        colorscale = plotly.colors.make_colorscale(viridis_colors, scale=scale)\n",
    "\n",
    "    :param colorscale: A plotly continuous colorscale defined with RGB string colors.\n",
    "    :param intermed: value in the range [0, 1]\n",
    "    :return: color in rgb string format\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    if len(colorscale) < 1:\n",
    "        raise ValueError(\"colorscale must have at least one color\")\n",
    "\n",
    "    hex_to_rgb = lambda c: \"rgb\" + str(ImageColor.getcolor(c, \"RGB\"))\n",
    "\n",
    "    if intermed <= 0 or len(colorscale) == 1:\n",
    "        c = colorscale[0][1]\n",
    "        return c if c[0] != \"#\" else hex_to_rgb(c)\n",
    "    if intermed >= 1:\n",
    "        c = colorscale[-1][1]\n",
    "        return c if c[0] != \"#\" else hex_to_rgb(c)\n",
    "\n",
    "    for cutoff, color in colorscale:\n",
    "        if intermed > cutoff:\n",
    "            low_cutoff, low_color = cutoff, color\n",
    "        else:\n",
    "            high_cutoff, high_color = cutoff, color\n",
    "            break\n",
    "\n",
    "    if (low_color[0] == \"#\") or (high_color[0] == \"#\"):\n",
    "        # some color scale names (such as cividis) returns:\n",
    "        # [[loc1, \"hex1\"], [loc2, \"hex2\"], ...]\n",
    "        low_color = hex_to_rgb(low_color)\n",
    "        high_color = hex_to_rgb(high_color)\n",
    "\n",
    "    return plotly.colors.find_intermediate_color(\n",
    "        lowcolor=low_color,\n",
    "        highcolor=high_color,\n",
    "        intermed=((intermed - low_cutoff) / (high_cutoff - low_cutoff)),\n",
    "        colortype=\"rgb\",\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cols = get_color(\"Viridis\", np.linspace(0, 1, 5))\n",
    "map_cols = np.linspace(0, 1, 5)\n",
    "colorscale=[]\n",
    "for i,val in enumerate(map_cols):\n",
    "    colorscale.append([val, cols[i]])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Simplify Plotting Schemes:\n",
    "col1 =  px.colors.qualitative.Plotly[2]\n",
    "col2 =  px.colors.qualitative.Plotly[4]\n",
    "col3 =  px.colors.qualitative.Plotly[1]\n",
    "col4 =  px.colors.qualitative.Plotly[3]\n",
    "col5 =  px.colors.qualitative.Plotly[4]\n",
    "col6 =  px.colors.qualitative.Plotly[5]\n",
    "\n",
    "\n",
    "\n",
    "# Simplify Plotting Schemes:\n",
    "col_msis2 =  px.colors.qualitative.Plotly[2]\n",
    "col_jb2008 =  px.colors.qualitative.Plotly[4]\n",
    "col_dtm2020 =  px.colors.qualitative.Plotly[1]\n",
    "col_tiegcm_oc =  px.colors.qualitative.Plotly[5]\n",
    "col_hasdm_oc =  px.colors.qualitative.Plotly[0]\n",
    "col_ctipe_oc =  px.colors.qualitative.Plotly[7]\n",
    "\n",
    "x_annot_val = 1.1\n",
    "\n",
    "\n",
    "\n",
    "def get_plot_params(plot_num, model_name_string):\n",
    "    '''\n",
    "    INPUT:   \n",
    "        Plot number, model_name string, x_annot_val\n",
    "    \n",
    "    RETURN:\n",
    "        col, x_annot, y_annot1, y_annot2, m_size,   \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    if plot_num == 0:\n",
    "        col = col1\n",
    "        x_annot = x_annot_val\n",
    "        y_annot1 = 1\n",
    "        y_annot2 = .9\n",
    "        m_size = 3.5\n",
    "    elif plot_num == 1:\n",
    "        x_annot = x_annot_val\n",
    "        y_annot1 = .8\n",
    "        y_annot2 = .8\n",
    "        col = col2\n",
    "        m_size = 3.5\n",
    "    elif plot_num == 2:\n",
    "        x_annot = x_annot_val\n",
    "        y_annot1 = .5\n",
    "        y_annot2 = .7\n",
    "        col = col3\n",
    "        m_size = 3.5\n",
    "    elif plot_num == 3:\n",
    "        x_annot = x_annot_val\n",
    "        y_annot1 = .2\n",
    "        y_annot2 = .55\n",
    "        col = col4\n",
    "        m_size = 3.5\n",
    "    elif plot_num == 4:\n",
    "        x_annot = x_annot_val\n",
    "        y_annot1 =  0 \n",
    "        y_annot2 = .45\n",
    "        col = col5\n",
    "        m_size = 3.5\n",
    "        \n",
    "    elif plot_num == 5:\n",
    "        x_annot = x_annot_val\n",
    "        y_annot1 =  0 \n",
    "        y_annot2 = .35\n",
    "        col = col6\n",
    "        m_size = 3.5\n",
    "        \n",
    "    if model_name_string == 'msis2':\n",
    "        col=col_msis2\n",
    "    elif model_name_string == 'dtm2020':\n",
    "        col=col_dtm2020\n",
    "    elif model_name_string == 'jb2008':\n",
    "        col=col_jb2008\n",
    "    elif model_name_string == 'tiegcm_oc':\n",
    "        col=col_tiegcm_oc\n",
    "    elif model_name_string == 'hasdm_oc':\n",
    "        col=col_hasdm_oc\n",
    "    elif model_name_string == 'ctipe_oc':\n",
    "        col=col_ctipe_oc\n",
    "        \n",
    "    ### Old Models\n",
    "    elif model_name_string == 'dtm87':\n",
    "        col='grey'\n",
    "    elif model_name_string == 'jaachia71':\n",
    "        col='grey'\n",
    "    elif model_name_string == 'msis86':\n",
    "        col='grey'\n",
    "    elif model_name_string == 'msis00':\n",
    "        col='tan'\n",
    "        \n",
    "    return(col,x_annot,y_annot1,y_annot2,m_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4bec213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T19:00:26.775691Z",
     "start_time": "2022-06-28T19:00:26.757365Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_named_plotly_colours():\n",
    "    \"\"\"\n",
    "    function to display to user the colours to match plotly's named\n",
    "    css colours.\n",
    "\n",
    "    Reference:\n",
    "        #https://community.plotly.com/t/plotly-colours-list/11730/3\n",
    "\n",
    "    Returns:\n",
    "        plotly dataframe with cell colour to match named colour name\n",
    "\n",
    "    \"\"\"\n",
    "    s='''\n",
    "        aliceblue, antiquewhite, aqua, aquamarine, azure,\n",
    "        beige, bisque, black, blanchedalmond, blue,\n",
    "        blueviolet, brown, burlywood, cadetblue,\n",
    "        chartreuse, chocolate, coral, cornflowerblue,\n",
    "        cornsilk, crimson, cyan, darkblue, darkcyan,\n",
    "        darkgoldenrod, darkgray, darkgrey, darkgreen,\n",
    "        darkkhaki, darkmagenta, darkolivegreen, darkorange,\n",
    "        darkorchid, darkred, darksalmon, darkseagreen,\n",
    "        darkslateblue, darkslategray, darkslategrey,\n",
    "        darkturquoise, darkviolet, deeppink, deepskyblue,\n",
    "        dimgray, dimgrey, dodgerblue, firebrick,\n",
    "        floralwhite, forestgreen, fuchsia, gainsboro,\n",
    "        ghostwhite, gold, goldenrod, gray, grey, green,\n",
    "        greenyellow, honeydew, hotpink, indianred, indigo,\n",
    "        ivory, khaki, lavender, lavenderblush, lawngreen,\n",
    "        lemonchiffon, lightblue, lightcoral, lightcyan,\n",
    "        lightgoldenrodyellow, lightgray, lightgrey,\n",
    "        lightgreen, lightpink, lightsalmon, lightseagreen,\n",
    "        lightskyblue, lightslategray, lightslategrey,\n",
    "        lightsteelblue, lightyellow, lime, limegreen,\n",
    "        linen, magenta, maroon, mediumaquamarine,\n",
    "        mediumblue, mediumorchid, mediumpurple,\n",
    "        mediumseagreen, mediumslateblue, mediumspringgreen,\n",
    "        mediumturquoise, mediumvioletred, midnightblue,\n",
    "        mintcream, mistyrose, moccasin, navajowhite, navy,\n",
    "        oldlace, olive, olivedrab, orange, orangered,\n",
    "        orchid, palegoldenrod, palegreen, paleturquoise,\n",
    "        palevioletred, papayawhip, peachpuff, peru, pink,\n",
    "        plum, powderblue, purple, red, rosybrown,\n",
    "        royalblue, saddlebrown, salmon, sandybrown,\n",
    "        seagreen, seashell, sienna, silver, skyblue,\n",
    "        slateblue, slategray, slategrey, snow, springgreen,\n",
    "        steelblue, tan, teal, thistle, tomato, turquoise,\n",
    "        violet, wheat, white, whitesmoke, yellow,\n",
    "        yellowgreen\n",
    "        '''\n",
    "    li=s.split(',')\n",
    "    li=[l.replace('\\n','') for l in li]\n",
    "    li=[l.replace(' ','') for l in li]\n",
    "\n",
    "    import pandas as pd\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    df=pd.DataFrame.from_dict({'colour': li})\n",
    "    fig = go.Figure(data=[go.Table(\n",
    "      header=dict(\n",
    "        values=[\"Plotly Named CSS colours\"],\n",
    "        line_color='black', fill_color='white',\n",
    "        align='center', font=dict(color='black', size=14)\n",
    "      ),\n",
    "      cells=dict(\n",
    "        values=[df.colour],\n",
    "        line_color=[df.colour], fill_color=[df.colour],\n",
    "        align='center', font=dict(color='black', size=11)\n",
    "      ))\n",
    "    ])\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# show_named_plotly_colours() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a416451",
   "metadata": {},
   "source": [
    "### Some plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87e57710",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T19:00:26.817562Z",
     "start_time": "2022-06-28T19:00:26.777756Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def orb_avg(den_df, arc):\n",
    "    \n",
    "    \n",
    "    #### Find the index for the correct date\n",
    "    vals  = np.arange(den_df[arc].index[0],den_df[arc].index[-1]+1)\n",
    "    df = den_df[arc].set_index('Date',drop=False ) \n",
    "    df['i_vals'] = vals\n",
    "    index_date = df.loc[df.index.max()]['i_vals'].min()\n",
    "    \n",
    "#     print('index_date', index_date)\n",
    "    lat = np.asarray(den_df[arc]['Lat'][:index_date])\n",
    "    time_pd = pd.to_datetime(den_df[arc]['Date'][:index_date])\n",
    "    i = np.nonzero( lat[1:]*lat[0:-1]  <  np.logical_and(0 , lat[1:] > lat[0:-1] )  )\n",
    "    i = i[0]\n",
    "\n",
    "    d_avg = np.zeros(np.size(i))\n",
    "    height_avg = np.zeros(np.size(i))\n",
    "    \n",
    "#     print('time_pd',time_pd)\n",
    "\n",
    "    time_avg = []\n",
    "    d_avg_rolling = []\n",
    "    \n",
    "    roll_avg_count = 0\n",
    "    for j in range(np.size(i)-1):\n",
    "        d_avg[j]      = np.mean(den_df[arc]['rho (kg/m**3)'  ][i[j] : i[j+1]-1  ]  )\n",
    "        height_avg[j] = np.mean(den_df[arc]['Height (meters)'][i[j] : i[j+1]-1  ]  )\n",
    "#         mean_time      = np.mean(time_pd[   i[j] : i[j+1]-1  ])\n",
    "        t1 = pd.to_datetime(time_pd[ i[j]    ])\n",
    "        t2 = pd.to_datetime(time_pd[ i[j+1]-1])\n",
    "        datemiddle = pd.Timestamp(t1) + (pd.Timestamp(t2) - pd.Timestamp(t1)) / 2\n",
    "\n",
    "        time_avg.append(datemiddle)\n",
    "\n",
    "        if roll_avg_count ==1:\n",
    "            d_avg_rolling.append(np.mean([ d_avg[j],  d_avg[j-1]]))\n",
    "            roll_avg_count =0\n",
    "            \n",
    "        roll_avg_count+=1 \n",
    "    d_avg_rolling.append(np.mean([ d_avg[j],  d_avg[j-1]]))\n",
    "        \n",
    "    return(time_avg, d_avg, d_avg_rolling )\n",
    "    \n",
    "\n",
    "def plot_density_orbit_avg(fig, obj_m1, plot_num ):\n",
    "    \n",
    "\n",
    "    ####  Get plot Parameters for this model\n",
    "    model_m1 = obj_m1.__dict__['global_params']['den_model']\n",
    "    col,x_annot,y_annot1,y_annot2,m_size = get_plot_params(plot_num, model_m1)\n",
    "    \n",
    "    for ii,arc in enumerate(obj_m1.__dict__['global_params']['arc_input']):\n",
    "        \n",
    "        vals  = np.arange(obj_m1.__dict__['Density'][arc].index[0],obj_m1.__dict__['Density'][arc].index[-1]+1)\n",
    "        df = obj_m1.__dict__['Density'][arc].set_index('Date',drop=False ) \n",
    "        df['i_vals'] = vals\n",
    "        index_date = df.loc[df.index.max()]['i_vals'].min()\n",
    "\n",
    "        \n",
    "        time_avg,d_avg, d_avg_rolling = orb_avg(obj_m1.Density, arc)\n",
    "        \n",
    "        \n",
    "        fig.add_trace(go.Scattergl(x=time_avg,\n",
    "                                 y=d_avg_rolling,\n",
    "#                                  y=d_avg,\n",
    "                                name= model_m1 ,\n",
    "                                mode='markers',\n",
    "                                marker=dict(\n",
    "                                color=col,\n",
    "                                size=7,),\n",
    "                                showlegend=False,\n",
    "                                   ),\n",
    "                                   row=1, col=1,\n",
    "                                   )\n",
    "        \n",
    "\n",
    "        fig.update_yaxes(type=\"log\", exponentformat= 'power',row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"kg/m^3\", row=1, col=1)\n",
    "#     fig.update_yaxes(title_text=\"nT\", row=2, col=1)\n",
    "#     fig.update_yaxes(title_text=\"sfu\", row=3, col=1)\n",
    "    fig.update_layout(legend= {'itemsizing': 'constant'})\n",
    "#     fig.update_layout(\n",
    "#         font=dict(          size=18, ),\n",
    "#         autosize=False,\n",
    "#         width=900,\n",
    "#         height=1000,)\n",
    "    \n",
    "    return(fig)\n",
    "\n",
    "\n",
    "\n",
    "def Plot_Densitycomparison(fig, obj_m1, plot_num):\n",
    "\n",
    "\n",
    "    ####  Get plot Parameters for this model\n",
    "    model_m1 = obj_m1.__dict__['global_params']['den_model']\n",
    "    col,x_annot,y_annot1,y_annot2,m_size = get_plot_params(plot_num, model_m1)\n",
    "    \n",
    "    \n",
    "    for ii,arc in enumerate(obj_m1.__dict__['global_params']['arc_input'][:]):\n",
    "        \n",
    "        \n",
    "        #### INDEX THE DENSITY DF correctly\n",
    "        vals  = np.arange(obj_m1.__dict__['Density'][arc].index[0],obj_m1.__dict__['Density'][arc].index[-1]+1)\n",
    "        df = obj_m1.__dict__['Density'][arc].set_index('Date',drop=False ) \n",
    "        df['i_vals'] = vals\n",
    "        index_date = df.loc[df.index.max()]['i_vals'].min()\n",
    "\n",
    "        \n",
    "        str_run_param = 'run_parameters'+ arc\n",
    "        final_iter = obj_m1.__dict__[str_run_param]['str_iteration']\n",
    "        i_arc = ii+1\n",
    "        \n",
    "        \n",
    "        \n",
    "        vals  = np.arange(obj_m1.__dict__['Density'][arc].index[0],obj_m1.__dict__['Density'][arc].index[-1]+1)\n",
    "        df = obj_m1.__dict__['Density'][arc].set_index('Date',drop=False ) \n",
    "        df['i_vals'] = vals\n",
    "        index_date = df.loc[df.index.max()]['i_vals'].min()       \n",
    "        time_avg,d_avg, d_avg_rolling = orb_avg(obj_m1.Density, arc)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print('----',model_m1,'----')\n",
    "        print('     mean:    ',np.mean(obj_m1.Density[arc]['rho (kg/m**3)']),'----')\n",
    "        print('     variance:',np.std(obj_m1.Density[arc]['rho (kg/m**3)']),'----')\n",
    "        print()\n",
    "#         if ii ==0:\n",
    "#             fig.add_trace(go.Scattergl(  x=obj_m1.Density[arc]['Date'][:index_date][:],\n",
    "#                                      y=obj_m1.Density[arc]['rho (kg/m**3)'][:index_date][:],\n",
    "#                                      name= model_m1,\n",
    "#                                      mode='markers',\n",
    "#                                      opacity=1,\n",
    "#                                      marker=dict(\n",
    "#                                         color=col, \n",
    "#                                         size=m_size,),\n",
    "#                                      showlegend=True,),\n",
    "#                                       secondary_y=False,\n",
    "#                                        row=1, col=1,)\n",
    "\n",
    "#         else:\n",
    "#             fig.add_trace(go.Scattergl(  x=obj_m1.Density[arc]['Date'][:index_date][:],\n",
    "#                          y=obj_m1.Density[arc]['rho (kg/m**3)'][:index_date][:],\n",
    "#                          name= model_m1,\n",
    "#                          mode='markers',\n",
    "#                          opacity=1,\n",
    "#                          marker=dict(\n",
    "#                             color=col, \n",
    "#                             size=m_size,),\n",
    "#                          showlegend=False,),\n",
    "#                           secondary_y=False,\n",
    "#                            row=1, col=1,)\n",
    "        fig.add_trace(go.Scattergl(x=time_avg,\n",
    "                     y=d_avg_rolling,\n",
    "                    name= model_m1 ,\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                    color='black',\n",
    "                    size=5,),\n",
    "                    showlegend=False,),\n",
    "                       row=1, col=1,)\n",
    "\n",
    "\n",
    "#         (mean,rms,rms_about_zero) = STATS_residuals(data_resids['T'], 'in-track')\n",
    "\n",
    "#         fig = add_stats_annotation(fig, model_m1+'<br>Mean='+ str(np.round(mean,4))+'<br>RMS='+ str(np.round(rms_about_zero,4)), col , x_annot, y_annot1)\n",
    "\n",
    "\n",
    "    fig.update_yaxes( title=r\"$\\frac{kg}{m^3}$\", type='log', exponentformat= 'power',row=1, col=1)\n",
    "    fig.update_xaxes( title=\"Date\", row=1, col=1)\n",
    "\n",
    "    return(fig)\n",
    "\n",
    "\n",
    "def legend_as_annotation(fig, den_model_string, color_it, x_annot, y_annot):\n",
    "    fig.add_annotation(\n",
    "            x=x_annot,\n",
    "            y=y_annot,\n",
    "            xref=\"paper\",\n",
    "            yref=\"paper\",\n",
    "            showarrow=False,\n",
    "            text=den_model_string,\n",
    "            font=dict(\n",
    "                size=16,\n",
    "                color=\"#ffffff\"\n",
    "                ),\n",
    "            align=\"center\",\n",
    "            bordercolor=\"#c7c7c7\",\n",
    "            borderwidth=2,\n",
    "            borderpad=4,\n",
    "            bgcolor=color_it,\n",
    "            opacity=0.9\n",
    "            )\n",
    "\n",
    "    return(fig)\n",
    "\n",
    "def add_stats_annotation(fig, text_in, col, x_annot, y_annot):\n",
    "    fig.add_annotation(\n",
    "            x=x_annot,\n",
    "            y=y_annot,\n",
    "            xref=\"x domain\",\n",
    "            yref=\"y domain\",\n",
    "            showarrow=False,\n",
    "            text=text_in,\n",
    "            font=dict(\n",
    "                size=13,\n",
    "                color=\"#ffffff\"\n",
    "                ),\n",
    "            align=\"center\",\n",
    "            bordercolor=\"#c7c7c7\",\n",
    "            borderwidth=2,\n",
    "            borderpad=4,\n",
    "            bgcolor=col,\n",
    "            opacity=0.9\n",
    "            )\n",
    "    return(fig)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def STATS_residuals(residuals,measurement_type):\n",
    "    import numpy as np\n",
    "    n = np.size(residuals)\n",
    "    mean = (1/n)*(np.sum(residuals))\n",
    "    variance = (1/n)*(np.sum(np.square(residuals)))\n",
    "    rms = np.sqrt(variance)\n",
    "    rms_about_zero = np.sqrt((n/(n-1))*variance)\n",
    "    \n",
    "                \n",
    "#     print('mean            ',measurement_type ,':',mean)\n",
    "#     print('rms             ',measurement_type ,':',rms)\n",
    "#     print('rms about zero  ',measurement_type ,':',rms_about_zero)\n",
    "#     print()\n",
    "    \n",
    "    return(mean,rms,rms_about_zero)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd4021c",
   "metadata": {},
   "source": [
    "### Load GPI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c78b9c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T19:00:27.031076Z",
     "start_time": "2022-06-28T19:00:26.821213Z"
    }
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "def read_nc_file( filename, variables):\n",
    "    ''' This function reads the TIEGCM .nc files and saves the given input variables to a dictionary.\n",
    "        The breakloop feature is here so that if the file doesn't exist the code can still continue.  '''\n",
    "    status = os.path.exists(filename)\n",
    "    \n",
    "    if status == True:\n",
    "        data = {}\n",
    "        for i, var_names in enumerate(variables):\n",
    "            ncid =  Dataset(filename,\"r+\", format=\"NETCDF4\")# filename must be a string\n",
    "            varData = ncid.variables\n",
    "            data[var_names] = np.array(varData[var_names])  \n",
    "    elif status == False:\n",
    "        print('No File Found', filename )\n",
    "        breakloop = True\n",
    "        data = 0\n",
    "        return( data , breakloop)\n",
    "    breakloop = False\n",
    "    return(data,breakloop )\n",
    "\n",
    "\n",
    "arc_list = []\n",
    "\n",
    "arc_list_18 = np.arange(292,366)\n",
    "for i in arc_list_18:\n",
    "    val = '2018'+str(i)\n",
    "    arc_list.append(int(val))\n",
    "    \n",
    "    #     print(val)\n",
    "    \n",
    "arc_list_19 = np.arange(1,10)\n",
    "for i in arc_list_19:\n",
    "    val = '201900'+str(i)\n",
    "    arc_list.append(int(val))\n",
    "\n",
    "\n",
    "path_to_f107 = '/data/data_geodyn/gpi_1960001-2021243_f107aDaily.nc'\n",
    "variables = ['year_day', 'f107d', 'f107a', 'kp']\n",
    "f107_data = read_nc_file(path_to_f107, variables)\n",
    "\n",
    "date = []\n",
    "kp_list = []\n",
    "f107d_list = []\n",
    "f107a_list  = []\n",
    "date_3hr = []\n",
    "\n",
    "\n",
    "for i,val in enumerate(arc_list):\n",
    "    \n",
    "    index = f107_data[0]['year_day']==val\n",
    "    kp_list.append(f107_data[0]['kp'][index][0])\n",
    "    f107d_list.append(f107_data[0]['f107d'][index][0])\n",
    "    f107a_list.append(f107_data[0]['f107a'][index][0])\n",
    "    \n",
    "    date.append(pd.to_datetime( str(val), format='%Y%j'))\n",
    "\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=0))\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=3))\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=6))\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=9))\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=12))\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=15))\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=18))\n",
    "    date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=21))\n",
    "#     date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=24))\n",
    "    \n",
    "kp_expand = []\n",
    "for i in kp_list:\n",
    "    for ii in i:\n",
    "        kp_expand.append(ii)\n",
    "        \n",
    "        \n",
    "        \n",
    "solar_fluxes = {}\n",
    "solar_fluxes['f107d_list'] = f107d_list\n",
    "solar_fluxes['f107a_list'] = f107a_list\n",
    "solar_fluxes['date']       = date\n",
    "solar_fluxes['date_3hr']   = date_3hr\n",
    "solar_fluxes['kp_expand']  = kp_expand\n",
    "\n",
    "\n",
    "### Prepare RMS total Plot arrays\n",
    "\n",
    "arc_listlist=[  ['2018.292', '2018.293', '2018.294', '2018.295', '2018.296', \n",
    "                 '2018.297', '2018.298', '2018.299' ],                  \n",
    "                #\n",
    "                ['2018.304', '2018.305', '2018.306', '2018.307', '2018.308' ],  \n",
    "                #\n",
    "                ['2018.313', '2018.314', '2018.315', '2018.316', '2018.317',\n",
    "                 '2018.318', '2018.319', '2018.320', '2018.321', '2018.322',\n",
    "                 '2018.323', '2018.324', '2018.325', '2018.326', '2018.327' ],  \n",
    "                #\n",
    "                ['2018.335', '2018.336', '2018.337' ],  \n",
    "                #\n",
    "                ['2018.349', '2018.350', '2018.351', '2018.352' ],  \n",
    "                #\n",
    "                ['2018.356', '2018.357', '2018.358' ],  \n",
    "                #\n",
    "                ['2018.365', '2019.001', '2019.002', '2019.003', '2019.004', \n",
    "                 '2019.005', '2019.006', '2019.007', '2019.008',\n",
    "                '2019.009'],  \n",
    "                ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22570eb1",
   "metadata": {},
   "source": [
    "# Plot Full Time Period\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb9cbb7",
   "metadata": {},
   "source": [
    "## Solar Flux and Kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2afb5bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T19:00:27.052760Z",
     "start_time": "2022-06-28T19:00:27.035403Z"
    }
   },
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "    \n",
    "# fig = make_subplots(\n",
    "#     rows=2, cols=1,\n",
    "# #     subplot_titles=([ 'Kp','F10.7']),\n",
    "#     shared_xaxes=True,\n",
    "#     vertical_spacing = 0.1,\n",
    "#     )\n",
    "\n",
    "# fig.add_trace(go.Scatter(  x=date,\n",
    "#                              y=f107d_list,\n",
    "#                              name= 'F107d',\n",
    "#                              mode='markers+lines',\n",
    "#                              opacity=1,\n",
    "#                              marker=dict( color='grey', size=2, ),\n",
    "#                              line = dict(shape = 'hv', color = 'grey', width=2),\n",
    "#                              showlegend=False,\n",
    "#                           ),\n",
    "#                               secondary_y=False,\n",
    "#                                row=1, col=1,\n",
    "#                           )\n",
    "\n",
    "# fig.add_trace(go.Scatter(  x=date,\n",
    "#                              y=f107a_list,\n",
    "#                              name= 'F107a',\n",
    "#                              mode='markers+lines',\n",
    "# #                              opacity=1,\n",
    "#                              marker=dict(color='black',size=2),\n",
    "#                              line = dict(shape = 'hv', color = 'black', width=2),\n",
    "#                              showlegend=False,\n",
    "#                           ),\n",
    "#                               secondary_y=False,\n",
    "#                                row=1, col=1,\n",
    "#                           )\n",
    "\n",
    "# fig.add_trace(go.Scatter(  x=date_3hr,\n",
    "#                              y=kp_expand,\n",
    "#                              name= 'Kp',\n",
    "#                              mode='markers+lines',\n",
    "# #                              opacity=1,\n",
    "#                              marker=dict(color='cornflowerblue',size=2,),\n",
    "#                              line = dict(shape = 'hv', color = 'cornflowerblue', width=2),\n",
    "#                              showlegend=False,\n",
    "#                           ),\n",
    "#                               secondary_y=False,\n",
    "#                                row=2, col=1,\n",
    "#                           )\n",
    "\n",
    "#     #### Arc Background \n",
    "# fig.add_vrect(x0=pd.to_datetime( str(2018292), format='%Y%j'),\n",
    "#               x1=pd.to_datetime( str(2018299), format='%Y%j'),\n",
    "#               fillcolor='LightSkyBlue',\n",
    "#               opacity=.5,\n",
    "#               layer=\"below\",\n",
    "#               line_width=0)\n",
    "# fig.add_vrect(x0=pd.to_datetime( str(2018304), format='%Y%j'),\n",
    "#               x1=pd.to_datetime( str(2018308), format='%Y%j'),\n",
    "#               fillcolor='LightSkyBlue',\n",
    "#               opacity=.5,\n",
    "#               layer=\"below\",\n",
    "#               line_width=0)\n",
    "# fig.add_vrect(x0=pd.to_datetime( str(2018313), format='%Y%j'),\n",
    "#               x1=pd.to_datetime( str(2018327), format='%Y%j'),\n",
    "#               fillcolor='LightSkyBlue',\n",
    "#               opacity=.5,\n",
    "#               layer=\"below\",\n",
    "#               line_width=0)\n",
    "# fig.add_vrect(x0=pd.to_datetime( str(2018335), format='%Y%j'),\n",
    "#               x1=pd.to_datetime( str(2018337), format='%Y%j'),\n",
    "#               fillcolor='LightSkyBlue',\n",
    "#               opacity=.5,\n",
    "#               layer=\"below\",\n",
    "#               line_width=0)\n",
    "# fig.add_vrect(x0=pd.to_datetime( str(2018349), format='%Y%j'),\n",
    "#               x1=pd.to_datetime( str(2018352), format='%Y%j'),\n",
    "#               fillcolor='LightSkyBlue',\n",
    "#               opacity=.5,\n",
    "#               layer=\"below\",\n",
    "#               line_width=0)\n",
    "# fig.add_vrect(x0=pd.to_datetime( str(2018356), format='%Y%j'),\n",
    "#               x1=pd.to_datetime( str(2018358), format='%Y%j'),\n",
    "#               fillcolor='LightSkyBlue',\n",
    "#               opacity=.5,\n",
    "#               layer=\"below\",\n",
    "#               line_width=0)\n",
    "# fig.add_vrect(x0=pd.to_datetime( str(2018365), format='%Y%j'),\n",
    "#               x1=pd.to_datetime( str(2019008), format='%Y%j'),\n",
    "#               fillcolor='LightSkyBlue',\n",
    "#               opacity=.5,\n",
    "#               layer=\"below\",\n",
    "#               line_width=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # fig.update_layout(\n",
    "# #         #     title= 'NGDC Geophysical Indices --  Kp and F10.7',\n",
    "# #                 autosize=False, ,\n",
    "# #                 font=dict(size=14),\n",
    "# #                 legend= {'itemsizing': 'constant'})\n",
    "\n",
    "# fig.update_yaxes( title=r\"$\\text{F}_{\\text{10.7}}\\text{ Solar Flux (sfu)}$\", row=1, col=1)\n",
    "# fig.update_yaxes( title=r\"$\\text{K}_\\text{p}\\text{ Index}$\", row=2, col=1)\n",
    "# fig.update_xaxes( title=r\"$\\text{Date}$\", row=2, col=1)\n",
    "\n",
    "# font_dict=dict(family='Arial',size=16,color='black')\n",
    "# fig.update_xaxes(showline=True,\n",
    "#                  showticklabels=False,\n",
    "#                  linecolor='black',\n",
    "#                  linewidth=1,\n",
    "#                  ticks='inside',\n",
    "#                  tickfont=font_dict,\n",
    "#                  mirror='allticks',\n",
    "#                  tickwidth=1.4,\n",
    "#                  tickcolor='black',\n",
    "#                  gridcolor='lightgray',\n",
    "#                  row=1, col=1\n",
    "#                 )\n",
    "\n",
    "# fig.update_xaxes(showline=True,\n",
    "#                  showticklabels=True,\n",
    "#                  linecolor='black',\n",
    "#                  linewidth=1,\n",
    "#                  ticks='inside',\n",
    "#                  tickfont=font_dict,\n",
    "#                  mirror='allticks',\n",
    "#                  tickwidth=1.4,\n",
    "#                  tickcolor='black',\n",
    "#                  gridcolor='lightgray',\n",
    "#                  row=2, col=1)\n",
    "\n",
    "\n",
    "# # fig.update_yaxes(range=[1.15, 1.35], row=1,col=1)\n",
    "# # fig.update_yaxes(range=[1.15, 1.35], row=1,col=2)\n",
    "# fig.update_yaxes(showline=True,      # add line at x=0\n",
    "#                  linecolor='black',  # line color\n",
    "#                  linewidth=1,      # line size\n",
    "#                  ticks='inside',    # ticks outside axis\n",
    "#                  tickfont=font_dict, # tick label font\n",
    "#                  mirror='allticks',  # add ticks to top/right axes\n",
    "#                  tickwidth=1.4,      # tick width\n",
    "#                  tickcolor='black',  # tick color\n",
    "#                   gridcolor='lightgray')\n",
    "\n",
    "# fig.update_annotations(font_size=18)  # Increase size of subplot title\n",
    "# fig.update_layout(\n",
    "# #                   title = '',\n",
    "#                   autosize=False,    width=700,    height=500,\n",
    "# #                   legend= {'itemsizing': 'constant'},\n",
    "#                   font=font_dict,\n",
    "#                   plot_bgcolor='white', \n",
    "#                  )\n",
    "# fig.show(config=config)\n",
    "# pio.write_image(fig, plots_dir+'geophysical_indices.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d1c86b",
   "metadata": {},
   "source": [
    "## Model Validation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fde3848b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T19:00:29.405131Z",
     "start_time": "2022-06-28T19:00:27.054869Z"
    }
   },
   "outputs": [],
   "source": [
    "# solar_fluxes_shaded = {}\n",
    "# solar_fluxes_shaded['f107d_list'] = f107d_list\n",
    "# solar_fluxes_shaded['f107a_list'] = f107a_list\n",
    "# solar_fluxes_shaded['date']       = date\n",
    "# solar_fluxes_shaded['date_3hr']   = date_3hr\n",
    "# solar_fluxes_shaded['kp_expand']  = kp_expand\n",
    "\n",
    "\n",
    "### Prepare RMS total Plot arrays\n",
    "arc_list={}\n",
    "arc_list['1']=  ['2018.292', '2018.293', '2018.294', '2018.295', '2018.296', \n",
    "                 '2018.297', '2018.298', '2018.299' ]                  \n",
    "                #\n",
    "arc_list['2']=  ['2018.304', '2018.305', '2018.306', '2018.307', '2018.308' ]  \n",
    "                #\n",
    "arc_list['3']=  ['2018.313', '2018.314', '2018.315', '2018.316', '2018.317',\n",
    "                 '2018.318', '2018.319', '2018.320', '2018.321', '2018.322',\n",
    "                 '2018.323', '2018.324', '2018.325', '2018.326', '2018.327' ]  \n",
    "                #\n",
    "arc_list['4']=  ['2018.335', '2018.336', '2018.337' ]  \n",
    "                #\n",
    "arc_list['5']=  ['2018.349', '2018.350', '2018.351', '2018.352' ]  \n",
    "                #\n",
    "arc_list['6']=  ['2018.356', '2018.357', '2018.358' ]  \n",
    "                #\n",
    "arc_list['7']=  ['2018.365', '2019.001', '2019.002', '2019.003', '2019.004', \n",
    "                '2019.005', '2019.006', '2019.007', '2019.008',\n",
    "                '2019.009' ]  \n",
    "\n",
    "\n",
    "\n",
    "# for arclist in arc_listlist:\n",
    "#     for arc in arclist:\n",
    "#         print(pd.to_datetime( str(arc), format='%Y.%j'))\n",
    "shadezone_i = {} \n",
    "shadezone_f = {}\n",
    "shadezone_i['1'] = '2018.299'\n",
    "shadezone_f['1'] = '2018.304'\n",
    "shadezone_i['2'] = '2018.308'\n",
    "shadezone_f['2'] = '2018.313'\n",
    "shadezone_i['3'] = '2018.327'\n",
    "shadezone_f['3'] = '2018.335'\n",
    "shadezone_i['4'] = '2018.337'\n",
    "shadezone_f['4'] = '2018.349'\n",
    "shadezone_i['5'] = '2018.352'\n",
    "shadezone_f['5'] = '2018.356'\n",
    "shadezone_i['6'] = '2018.358'\n",
    "shadezone_f['6'] = '2018.365'\n",
    "\n",
    "SF = {}\n",
    "for iii in np.arange(1,8):\n",
    "#     print(iii)\n",
    "    SF[str(iii)+'_shade_f107d'] = []\n",
    "    SF[str(iii)+'_shade_date']  = []\n",
    "    SF[str(iii)+'_f107d']       = []\n",
    "    SF[str(iii)+'_date']        = []\n",
    "    #     \n",
    "    SF[str(iii)+'_shade_date_3hr'] = []\n",
    "    SF[str(iii)+'_shade_kp_expand']  = []\n",
    "    SF[str(iii)+'_date_3hr']       = []\n",
    "    SF[str(iii)+'_kp_expand']        = []\n",
    "    # \n",
    "#     shadezone_i[str(iii)] = \n",
    "#     shadezone_f[str(iii)] = \n",
    "    \n",
    "    \n",
    "    \n",
    "for i, val in enumerate(solar_fluxes['date']):\n",
    "    for iii in np.arange(1,8):\n",
    "\n",
    "        if iii == 7:\n",
    "            pass\n",
    "        else:\n",
    "            if val >= pd.to_datetime(shadezone_i[str(iii)], format='%Y.%j') and val <= pd.to_datetime(shadezone_f[str(iii)], format='%Y.%j'):    \n",
    "                SF[str(iii)+'_shade_f107d'].append(solar_fluxes['f107d_list'][i])\n",
    "                SF[str(iii)+'_shade_date'].append(val)\n",
    "\n",
    "        if val >= pd.to_datetime(arc_list[str(iii)][0], format='%Y.%j') and val <= pd.to_datetime(arc_list[str(iii)][-1], format='%Y.%j'):    \n",
    "            SF[str(iii)+'_f107d'].append(solar_fluxes['f107d_list'][i])\n",
    "            SF[str(iii)+'_date'].append(val)\n",
    "\n",
    "for i, val in enumerate(solar_fluxes['date_3hr']):\n",
    "    for iii in np.arange(1,8):\n",
    "\n",
    "        if iii == 7:\n",
    "            pass\n",
    "        else:\n",
    "            if val >= pd.to_datetime(shadezone_i[str(iii)], format='%Y.%j') and val <= pd.to_datetime(shadezone_f[str(iii)], format='%Y.%j'):    \n",
    "                SF[str(iii)+'_shade_date_3hr'].append(val)\n",
    "                SF[str(iii)+'_shade_kp_expand'].append(solar_fluxes['kp_expand'][i])\n",
    "\n",
    "        if val >= pd.to_datetime(arc_list[str(iii)][0], format='%Y.%j') and val <= pd.to_datetime(arc_list[str(iii)][-1], format='%Y.%j'):    \n",
    "#             print(val)\n",
    "            SF[str(iii)+'_date_3hr'].append(val)\n",
    "            SF[str(iii)+'_kp_expand'].append(solar_fluxes['kp_expand'][i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52d305cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T19:00:29.422277Z",
     "start_time": "2022-06-28T19:00:29.407045Z"
    }
   },
   "outputs": [],
   "source": [
    "# SF[str(iii)+'_date_3hr']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7071162c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T19:00:29.439022Z",
     "start_time": "2022-06-28T19:00:29.424494Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig = make_subplots(rows=1, cols=1,\n",
    "# #                     subplot_titles=([ ' ', ]),\n",
    "#                     #                     \n",
    "#                     specs=[[ {\"secondary_y\": True} ]],\n",
    "#                     #\n",
    "#                     vertical_spacing = 0.05,\n",
    "#                     shared_xaxes=True)\n",
    "# for iii in np.arange(1,8):\n",
    "#     fig.add_trace(go.Scatter(x=SF[str(iii)+'_shade_date'],\n",
    "#                                y=SF[str(iii)+'_shade_f107d'],\n",
    "#                                mode='lines',\n",
    "#                                opacity=0.5,\n",
    "# #                                        marker=dict(color='cornflowerblue',size=3),\n",
    "#                                    line = dict(dash='dot',shape = 'hv', color = 'cornflowerblue', width=2),\n",
    "#                                showlegend=False),\n",
    "#                                secondary_y=True,row=1, col=1)\n",
    "#     fig.add_trace(go.Scatter(x=SF[str(iii)+'_date'],\n",
    "#                                y=SF[str(iii)+'_f107d'],\n",
    "#                                mode='lines',\n",
    "#                                opacity=1,\n",
    "#                                    line = dict(shape = 'hv', color = 'cornflowerblue', width=2),\n",
    "#                                showlegend=False),\n",
    "#                                secondary_y=True,row=1, col=1)\n",
    "#     fig.add_trace(go.Scatter(x=SF[str(iii)+'_shade_date_3hr'],\n",
    "#                                y=SF[str(iii)+'_shade_kp_expand'],\n",
    "#                                mode='lines',\n",
    "#                                opacity=0.5,\n",
    "# #                                        marker=dict(color='cornflowerblue',size=3),\n",
    "#                                    line = dict(dash='dot',shape = 'hv', color = 'grey', width=1),\n",
    "#                                showlegend=False),\n",
    "#                                secondary_y=False,row=1, col=1)\n",
    "#     fig.add_trace(go.Scatter(x=SF[str(iii)+'_date_3hr'],\n",
    "#                                y=SF[str(iii)+'_kp_expand'],\n",
    "#                                mode='lines',\n",
    "#                                opacity=1,\n",
    "#                                    line = dict(shape = 'hv', color = 'black', width=1),\n",
    "#                                showlegend=False),\n",
    "#                                    secondary_y=False,row=1, col=1)\n",
    "# fig.show(config=dict({\n",
    "#                 'displayModeBar': True,\n",
    "#                 'responsive': False,\n",
    "#                 'staticPlot': False,\n",
    "#                 'displaylogo': False,\n",
    "#                 'showTips': False,\n",
    "#                 }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1c42c9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-28T19:00:24.197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-450aa9a5b051>\", line 371, in <module>\n",
      "    fig.show(renderer=\"jpg\",\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3398, in show\n",
      "    return pio.show(self, *args, **kwargs)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/plotly/io/_renderers.py\", line 388, in show\n",
      "    bundle = renderers._build_mime_bundle(fig_dict, renderers_string=renderer, **kwargs)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/plotly/io/_renderers.py\", line 296, in _build_mime_bundle\n",
      "    bundle.update(renderer.to_mimebundle(fig_dict))\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/plotly/io/_base_renderers.py\", line 127, in to_mimebundle\n",
      "    image_bytes = to_image(\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 144, in to_image\n",
      "    img_bytes = scope.transform(\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/kaleido/scopes/plotly.py\", line 103, in transform\n",
      "    response = self._perform_transform(\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/kaleido/scopes/base.py\", line 297, in _perform_transform\n",
      "    response = self._proc.stdout.readline()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-450aa9a5b051>\", line 371, in <module>\n",
      "    fig.show(renderer=\"jpg\",\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3398, in show\n",
      "    return pio.show(self, *args, **kwargs)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/plotly/io/_renderers.py\", line 388, in show\n",
      "    bundle = renderers._build_mime_bundle(fig_dict, renderers_string=renderer, **kwargs)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/plotly/io/_renderers.py\", line 296, in _build_mime_bundle\n",
      "    bundle.update(renderer.to_mimebundle(fig_dict))\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/plotly/io/_base_renderers.py\", line 127, in to_mimebundle\n",
      "    image_bytes = to_image(\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 144, in to_image\n",
      "    img_bytes = scope.transform(\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/kaleido/scopes/plotly.py\", line 103, in transform\n",
      "    response = self._perform_transform(\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/kaleido/scopes/base.py\", line 297, in _perform_transform\n",
      "    response = self._proc.stdout.readline()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3357, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3454, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2063, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-450aa9a5b051>\", line 371, in <module>\n",
      "    fig.show(renderer=\"jpg\",\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3398, in show\n",
      "    return pio.show(self, *args, **kwargs)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/plotly/io/_renderers.py\", line 388, in show\n",
      "    bundle = renderers._build_mime_bundle(fig_dict, renderers_string=renderer, **kwargs)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/plotly/io/_renderers.py\", line 296, in _build_mime_bundle\n",
      "    bundle.update(renderer.to_mimebundle(fig_dict))\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/plotly/io/_base_renderers.py\", line 127, in to_mimebundle\n",
      "    image_bytes = to_image(\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 144, in to_image\n",
      "    img_bytes = scope.transform(\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/kaleido/scopes/plotly.py\", line 103, in transform\n",
      "    response = self._perform_transform(\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/kaleido/scopes/base.py\", line 297, in _perform_transform\n",
      "    response = self._proc.stdout.readline()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3357, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3454, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2063, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3165, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3376, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2063, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/posixpath.py\", line 391, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/posixpath.py\", line 425, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/data/miniconda3/envs/pygeodyn/lib/python3.8/posixpath.py\", line 167, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "index1 = 0\n",
    "index2 = -1\n",
    "index3h_1 = 0\n",
    "index3h_2 = -1\n",
    "\n",
    "def plot_all_full(fig, obj_m1, plot_num, SF,    arc_listlist ):\n",
    "    \n",
    "\n",
    "    ####  Get plot Parameters for this model\n",
    "    model_m1 = obj_m1.__dict__['global_params']['den_model']\n",
    "    col,x_annot,y_annot1,y_annot2,m_size = get_plot_params(plot_num, model_m1)\n",
    "        \n",
    "    #### -----------------------------------------------------------------------------------------------------\n",
    "    if plot_num == 2 or plot_num == 0:\n",
    "        #### Solar Flux Plot\n",
    "        for iii in np.arange(1,8):\n",
    "            fig.add_trace(go.Scattergl(x=SF[str(iii)+'_shade_date'],\n",
    "                                       y=SF[str(iii)+'_shade_f107d'],\n",
    "                                       mode='lines',\n",
    "                                       opacity=0.5,\n",
    "    #                                        marker=dict(color='cornflowerblue',size=3),\n",
    "                                           line = dict(dash='dot',shape = 'hvh', color = 'cornflowerblue', width=2),\n",
    "                                       showlegend=False),\n",
    "                                       secondary_y=True,row=1, col=1)\n",
    "            fig.add_trace(go.Scattergl(x=SF[str(iii)+'_date'],\n",
    "                                       y=SF[str(iii)+'_f107d'],\n",
    "                                       mode='lines',\n",
    "                                       opacity=1,\n",
    "                                           line = dict(shape = 'hvh', color = 'cornflowerblue', width=2),\n",
    "                                       showlegend=False),\n",
    "                                       secondary_y=True,row=1, col=1)\n",
    "            fig.add_trace(go.Scattergl(x=SF[str(iii)+'_shade_date_3hr'],\n",
    "                                       y=SF[str(iii)+'_shade_kp_expand'],\n",
    "                                       mode='lines',\n",
    "                                       opacity=0.5,\n",
    "    #                                        marker=dict(color='cornflowerblue',size=3),\n",
    "                                           line = dict(dash='dot',shape = 'hvh', color = 'grey', width=1),\n",
    "                                       showlegend=False),\n",
    "                                       secondary_y=False,row=1, col=1)\n",
    "            fig.add_trace(go.Scattergl(x=SF[str(iii)+'_date_3hr'],\n",
    "                                       y=SF[str(iii)+'_kp_expand'],\n",
    "                                       mode='lines',\n",
    "                                       opacity=1,\n",
    "                                           line = dict(shape = 'hvh', color = 'black', width=1),\n",
    "                                       showlegend=False),\n",
    "                                       secondary_y=False,row=1, col=1)\n",
    "        #### Background data gaps\n",
    "        fig.add_vrect(x0=pd.to_datetime( str(2018290), format='%Y%j'),\n",
    "                      x1=pd.to_datetime( str(2018292), format='%Y%j'),\n",
    "                      fillcolor='gainsboro',\n",
    "                      opacity=.6,\n",
    "                      layer=\"below\",\n",
    "                      line_width=0,\n",
    "                     row=1,col=1)\n",
    "        fig.add_vrect(x0=pd.to_datetime( str(2018300), format='%Y%j'),\n",
    "                      x1=pd.to_datetime( str(2018304), format='%Y%j'),\n",
    "                      fillcolor='gainsboro',\n",
    "                      opacity=.6,\n",
    "                      layer=\"below\",\n",
    "                      line_width=0,\n",
    "                     row=1,col=1)\n",
    "        fig.add_vrect(x0=pd.to_datetime( str(2018309), format='%Y%j'),\n",
    "                      x1=pd.to_datetime( str(2018313), format='%Y%j'),\n",
    "                      fillcolor='gainsboro',\n",
    "                      opacity=.6,\n",
    "                      layer=\"below\",\n",
    "                      line_width=0,\n",
    "                     row=1,col=1)\n",
    "        fig.add_vrect(x0=pd.to_datetime( str(2018329), format='%Y%j'),\n",
    "                      x1=pd.to_datetime( str(2018335), format='%Y%j'),\n",
    "                      fillcolor='gainsboro',\n",
    "                      opacity=.6,\n",
    "                      layer=\"below\",\n",
    "                      line_width=0,\n",
    "                     row=1,col=1)\n",
    "        fig.add_vrect(x0=pd.to_datetime( str(2018338), format='%Y%j'),\n",
    "                      x1=pd.to_datetime( str(2018349), format='%Y%j'),\n",
    "                      fillcolor='gainsboro',\n",
    "                      opacity=.6,\n",
    "                      layer=\"below\",\n",
    "                      line_width=0,\n",
    "                     row=1,col=1)\n",
    "        fig.add_vrect(x0=pd.to_datetime( str(2018353), format='%Y%j'),\n",
    "                      x1=pd.to_datetime( str(2018356), format='%Y%j'),\n",
    "                      fillcolor='gainsboro',\n",
    "                      opacity=.6,\n",
    "                      layer=\"below\",\n",
    "                      line_width=0,\n",
    "                     row=1,col=1)\n",
    "        fig.add_vrect(x0=pd.to_datetime( str(2018359), format='%Y%j'),\n",
    "                      x1=pd.to_datetime( str(2018365), format='%Y%j'),\n",
    "                      fillcolor='gainsboro',\n",
    "                      opacity=.6,\n",
    "                      layer=\"below\",\n",
    "                      line_width=0,\n",
    "                     row=1,col=1)\n",
    "        fig.add_vrect(x0=pd.to_datetime( str(2019009), format='%Y%j'),\n",
    "                      x1=pd.to_datetime( str(2019010), format='%Y%j'),\n",
    "                      fillcolor='gainsboro',\n",
    "                      opacity=.6,\n",
    "                      layer=\"below\",\n",
    "                      line_width=0,\n",
    "                     row=1,col=1)\n",
    "\n",
    "    \n",
    "    for i1,arc1 in enumerate(arc_listlist):#obj_m1.__dict__['global_params']['arc_input']):\n",
    "        dateplot = []\n",
    "        rms_totals = []\n",
    "        \n",
    "        for ii,arc in enumerate(arc1):#obj_m1.__dict__['global_params']['arc_input']):\n",
    "            if arc not in obj_m1.__dict__['global_params']['arc_input']:\n",
    "                continue\n",
    "            else:\n",
    "                arc =arc+'.01'\n",
    "\n",
    "                dateplot.append(pd.to_datetime(datetime.datetime(int(arc.split('.')[0]), 1, 1) + datetime.timedelta(int(arc.split('.')[1]))- datetime.timedelta(hours=12) ))\n",
    "                rms_totals.append(obj_m1.__dict__['Statistics'][arc]['T_RMS'].values[0])\n",
    "                ### -----------------------------------------------------------------------------------------------------\n",
    "                ###     DENSITY\n",
    "                ###\n",
    "                ## Remove the denisty file duplication\n",
    "                vals  = np.arange(obj_m1.__dict__['Density'][arc].index[0],obj_m1.__dict__['Density'][arc].index[-1]+1)\n",
    "                df = obj_m1.__dict__['Density'][arc].set_index('Date',drop=False ) \n",
    "                df['i_vals'] = vals\n",
    "                index_date = df.loc[df.index.max()]['i_vals'].min()\n",
    "                time_avg,d_avg, d_avg_rolling = orb_avg(obj_m1.Density, arc)\n",
    "                #\n",
    "                \n",
    "                ### -----------------------------------------------------------------------------------------------------\n",
    "                ###     Orbit Averaged Density\n",
    "                fig.add_trace(go.Scattergl(x=time_avg,\n",
    "                                           y=d_avg_rolling,\n",
    "                                           ### name= model_m1,\n",
    "                                           mode='markers+lines',\n",
    "                                           opacity=1,\n",
    "                                               marker=dict(color=col,size=2),\n",
    "                                           ###     line = dict( color = col, width=2),\n",
    "                                               line = dict(shape='hvh', dash ='solid', color = col, width=2),\n",
    "                                           showlegend=False), row=2, col=1)\n",
    "                ### -----------------------------------------------------------------------------------------------------\n",
    "                ###     In Track Residuals\n",
    "                data_resids = obj_m1.__dict__['OrbitResids'][arc]['resids']\n",
    "                fig.add_trace(go.Scattergl(x=data_resids['Date'][::75],\n",
    "                                           y=data_resids['T'][::75],\n",
    "                                           ###   name= model_m1,\n",
    "                                             mode='markers+lines',\n",
    "                                             opacity=1,\n",
    "                                                 marker=dict(color=col,size=2),\n",
    "                                                 line = dict( color = col, width=2),\n",
    "                                             showlegend=False),\n",
    "                                             secondary_y=False, row=3, col=1)\n",
    "            ### -----------------------------------------------------------------------------------------------------\n",
    "            ###     TOTAL RMS\n",
    "            fig.add_trace(go.Scattergl(x=dateplot,\n",
    "                                       y=rms_totals,\n",
    "                                           ###e= 'NTW '+model_m1,\n",
    "                                       mode='markers+lines',\n",
    "                                             opacity=1,\n",
    "                                             marker=dict(color=col,size=6),\n",
    "                                             line = dict(shape='hvh', dash ='solid', color = col, width=2),\n",
    "                                       showlegend=False),row=4, col=1)\n",
    "    \n",
    "    if plot_num == 2 or plot_num == 0:\n",
    "        ###\n",
    "        ### DENSITY AXIS\n",
    "        fig.update_yaxes(title_text=r\"$\\text{Orbit Averaged Density } (\\frac{kg}{m^3})$\", \n",
    "                         type=\"log\", exponentformat= 'power',row=2, col=1)\n",
    "        ###\n",
    "        ### InTrack Residual Axis\n",
    "        fig.update_yaxes( title=r\"$\\text{In-Track Residuals (m)}$\",\n",
    "    #                      range=[-100,55],\n",
    "                         exponentformat= 'power',row=3, col=1)\n",
    "        ###\n",
    "        ### RMS AXIS\n",
    "        fig.update_yaxes( title=r\"$\\text{In-Track RMSe (m)}$\" ,type=\"linear\" , exponentformat= 'power', row=4, col=1)\n",
    "        ###\n",
    "        ###  DATE on Final x-Axis only\n",
    "        fig.update_xaxes(title=r\"$\\text{Date}$\", \n",
    "                         range=[pd.to_datetime( \"181018-000000\", format='%y%m%d-%H%M%S'),\n",
    "                                pd.to_datetime( \"190109-120000\", format='%y%m%d-%H%M%S')],\n",
    "                         row=4, col=1)\n",
    "\n",
    "    return(fig)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### -----------------------------------------------------------------------------------------------------\n",
    "    ### -----------------------------------------------------------------------------------------------------\n",
    "    ### -----------------------------------------------------------------------------------------------------\n",
    "    ### -----------------------------------------------------------------------------------------------------\n",
    "    ### -----------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=4, cols=1,\n",
    "#                     subplot_titles=([ ' ', ]),\n",
    "                    #                     \n",
    "                    specs=[[ {\"secondary_y\": True} ],\n",
    "                           [ {\"secondary_y\": False} ],\n",
    "                           [ {\"secondary_y\": False} ],\n",
    "                           [ {\"secondary_y\": False} ]],\n",
    "                    #\n",
    "                    vertical_spacing = 0.05,\n",
    "                    shared_xaxes=True)\n",
    "\n",
    "\n",
    "\n",
    "# fig = plot_all_full(fig, Obj_3months['msis2_p1'],        0, SF, arc_listlist)\n",
    "# fig = plot_all_full(fig, Obj_3months['msis2_p2'],        0, SF, arc_listlist)\n",
    "# fig = plot_all_full(fig, Obj_3months['tiegcm_oc_p1'],    3, SF, arc_listlist)\n",
    "# fig = plot_all_full(fig, Obj_3months['tiegcm_oc_p2'],    3, SF, arc_listlist)\n",
    "# fig = plot_all_full(fig, Obj_3months['dtm2020_p1'],   1, SF, arc_listlist)\n",
    "# fig = plot_all_full(fig, Obj_3months['dtm2020_p2'],   1, SF, arc_listlist)\n",
    "# fig = plot_all_full(fig, Obj_3months['jb2008_p1'],    2, SF, arc_listlist)\n",
    "# fig = plot_all_full(fig, Obj_3months['jb2008_p2'],    2, SF, arc_listlist)\n",
    "fig = plot_all_full(fig, Obj_3months['hasdm_oc_p1'],  2, SF, arc_listlist)\n",
    "fig = plot_all_full(fig, Obj_3months['hasdm_oc_p2'],  2, SF, arc_listlist)\n",
    "\n",
    "\n",
    "\n",
    "# fig = plot_all_full(fig, Obj_3months['hasdm_oc'],  4, solar_fluxes, arc_listlist)\n",
    "# fig = plot_all_full(fig, Obj_3months['ctipe_oc'],  5, solar_fluxes, arc_listlist)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################################################\n",
    "font_dict=dict(family='Arial',size=14,color='black')\n",
    "#######################################################\n",
    "\n",
    "fig.update_xaxes(showline=True,\n",
    "             showticklabels=True,\n",
    "             linecolor='black',\n",
    "             linewidth=1,\n",
    "             ### Major ticks\n",
    "                 ticks='inside',\n",
    "                 tickfont=font_dict,\n",
    "                 mirror=True,\n",
    "                 tickwidth=2,\n",
    "                 ticklen=9,\n",
    "                 tickcolor='grey',\n",
    "                 tick0=\"2018-10-20\" ,\n",
    "                 dtick=86400000.0*7,    # milliseconds in a day, every 7 days\n",
    "                 #### Minor Ticks\n",
    "                 minor=dict(dtick=86400000.0, # milliseconds in a day\n",
    "                       tickwidth=1,\n",
    "                       ticklen=4,\n",
    "                       tickcolor='grey',\n",
    "                       ticks='inside'),             \n",
    "                 gridcolor='gainsboro',\n",
    "                 showgrid=False,\n",
    "                 layer='above traces',\n",
    "                 tickangle=0,\n",
    "                 row=1, col=1)\n",
    "fig.update_yaxes(title_text=r\"$\\text{F}_{\\text{10.7}}\\text{ Solar Flux (sfu)}$\", \n",
    "                 color='cornflowerblue',\n",
    "                 range=[64, 86],\n",
    "                 showline=True,      # add line at x=0\n",
    "                 linecolor='cornflowerblue',  # line color\n",
    "                 linewidth=1,        # line size\n",
    "                 ticks='inside',     # ticks outside axis\n",
    "                 tickfont=dict(family='sans-serif',size=14,color='cornflowerblue'), # tick label font\n",
    "                 mirror=False,  # add ticks to top/right axes\n",
    "                 tickwidth=1,      # tick width\n",
    "                 tickcolor='cornflowerblue',   # tick color\n",
    "                 gridcolor='gainsboro',\n",
    "                 showgrid=False,\n",
    "                 anchor=\"x\", overlaying=\"y\", side=\"right\",\n",
    "                 layer='above traces',\n",
    "                 secondary_y=True, row=1, col=1,)\n",
    "fig.update_yaxes(title_text=r\"$\\text{K}_\\text{p}\\text{ Index}$\",\n",
    "                 secondary_y=False,\n",
    "                 showline=True,      # add line at x=0\n",
    "                 linecolor='black',  # line color\n",
    "                 linewidth=1,        # line size\n",
    "                 ticks='inside',     # ticks outside axis\n",
    "                 tickfont=dict(family='sans-serif',size=14,color='black'), # tick label font\n",
    "                 mirror=False,  # add ticks to top/right axes\n",
    "                 tickwidth=1,      # tick width\n",
    "                 tickcolor='black',   # tick color\n",
    "                 gridcolor='gainsboro',\n",
    "                 showgrid=False,\n",
    "                 layer='above traces',\n",
    "                 row=1, col=1,)\n",
    "    \n",
    "\n",
    "for i in [2,3,4]:\n",
    "    fig.update_xaxes(### LINE at axis border\n",
    "                      showline=True,\n",
    "                      showticklabels=True,\n",
    "                      linecolor='black',\n",
    "                      linewidth=1,\n",
    "                     ### Major ticks\n",
    "                      ticks='inside',\n",
    "                      tickfont=font_dict,\n",
    "                      mirror=True,\n",
    "                      tickwidth=2,\n",
    "                      ticklen=9,\n",
    "                      tickcolor='grey',\n",
    "                      tick0=\"2018-10-20\" ,\n",
    "                      dtick=86400000.0*7,    # milliseconds in a day, every 7 days\n",
    "                      #### Minor Ticks\n",
    "                       minor=dict(\n",
    "                         dtick=86400000.0, # milliseconds in a day\n",
    "                         tickwidth=1,\n",
    "                         ticklen=4,\n",
    "                         tickcolor='grey',\n",
    "                         ticks='inside'),\n",
    "                      ### GRID\n",
    "                       gridcolor='gainsboro',\n",
    "                       gridwidth=0.5,\n",
    "                       layer='above traces',\n",
    "                       tickangle=0,\n",
    "                       row=i, col=1)\n",
    "    fig.update_yaxes(showline=True,      # add line at x=0\n",
    "                         showticklabels=True,\n",
    "                         linecolor='black',  # line color\n",
    "                         linewidth=1,        # line size\n",
    "                     ticks='inside',     # ticks outside axis\n",
    "                     tickfont=font_dict, # tick label font\n",
    "                     mirror='allticks',  # add ticks to top/right axes\n",
    "                     tickwidth=1,      # tick width\n",
    "                     tickcolor='black',  # tick color\n",
    "                     gridcolor='gainsboro',\n",
    "                     gridwidth=0.5,\n",
    "                     layer='above traces',\n",
    "                     row=i, col=1)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#### LEGEND ####\n",
    "modelnames = [  \"MSISe2\",  \"DTM2020\",  \"JB2008\",  \"TIEGCM\",  \"HASDM\",  \"CTIPe\"]\n",
    "df = pd.DataFrame({\"starts_colors\": [col_msis2, col_dtm2020, col_jb2008, \n",
    "                                     col_tiegcm_oc, col_hasdm_oc, col_ctipe_oc]})\n",
    "fig.update_traces(showlegend=False).add_traces(\n",
    "    [   go.Scattergl(name=modelnames[i], \n",
    "               x=[pd.to_datetime( \"181107-000000\", format='%y%m%d-%H%M%S')],\n",
    "               mode='lines',\n",
    "               line = dict(shape = 'hvh',  width=25),\n",
    "               marker_color=c, \n",
    "               showlegend=True)\n",
    "        for i,c in enumerate((df.loc[:,[\"starts_colors\"]].values.ravel()))])\n",
    "fig.update_layout(legend=dict(\n",
    "    yanchor=\"middle\",\n",
    "    y=0.63,\n",
    "    xanchor=\"center\",\n",
    "    x=1.015,\n",
    "        font=font_dict,\n",
    "        bgcolor=\"white\",\n",
    "        bordercolor=\"darkgrey\",\n",
    "        borderwidth=0.8,))\n",
    "\n",
    "fig.update_layout(\n",
    "#                   title = '',\n",
    "                  autosize=False,    width=1000,    height=1100,\n",
    "                  legend= {'itemsizing': 'trace'},\n",
    "                  font=font_dict,\n",
    "                  plot_bgcolor='white', \n",
    "                 )\n",
    "fig.update_annotations(font_size=14 )  # Increase size of subplot title\n",
    "\n",
    "fig.show(renderer=\"jpg\",\n",
    "            config=dict({\n",
    "                'displayModeBar': False,\n",
    "                'responsive': False,\n",
    "                'staticPlot': True,\n",
    "                'displaylogo': False,\n",
    "                'showTips': False,\n",
    "                }))\n",
    "\n",
    "# pio.write_image(fig, plots_dir+'threemonth_fullresult.jpg', scale=3)\n",
    "\n",
    "# x=0\n",
    "# fig=0\n",
    "# print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2120b362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "223.5px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
